## Simple Sentiment Analysis for Twitter
***
Using 16,000 tweets directed at or written by the top four 2016 presidential candidates post-Iowa Caucus: Hillary Clinton, Ted Cruz, Bernie Sanders, and Donald Trump, we will create plots to analyze the sentiment of Twitter users related to the four candidates.

***

### Global parameters 
***
Set working directory by pointing to the location on your computer where you have stored the files. Below, we have chosen to Save the folder "RAnalysis" on the Desktop on a Mac. It contains all the other R scripts, texts, notebooks, and results. If you have branched the Github, simply note where you have save the folder. If you are on a PC, you will need to use an absolute path such as "C:Users:XXX."

Hint: Can't figure out your syntax? Click Session > Set Working Directory > Choose Directory, then select the Text_Analysis directory in which you are working. This will set your working directory in the console below while you are working here, but make sure to copy the path into the "setwd" command below to keep the directory constant if you close this script and reopen later.
***
```{r}
setwd("~/Documents/IU/CyberDH/Text_Analysis/RNotebooks")
```

***
Include necessary packages for notebook

```{r}
library(knitr)
library(markdown)
library(rmarkdown)
library(devtools)
library(twitteR)
library(plyr)
library(ggplot2)
```

***

### Load data 
***
This each .RData object is a curated set of tweets grabbed from Twitter using the TwitteR package. The tweets orginially return as a list, which was then saved as the .RData object you see here. We load the .RData files into our environment using readRDS and save them into a variable we can use later. 

Hint 1: The names of the variables can be anything (happiness, rainbows, cats), but usually, you want to name them using terms to indicate what the variable holds. Here we use clinton.tweets to represent the tweets associated with @HillaryClinton on Twitter, and so on for the others. The period (.) between "clinton" and "tweets" does not serve any purpose other than to separate the two terms for ease of reading. 

Hint 2: Another popular naming convention is to list the type of object with the name, for example clinton.tweets.l since this object is a list. This convention helps when manipulating the data later.

***
```{r}
clinton.tweets <- readRDS("~/Documents/IU/CyberDH/Text_Analysis/data/twitter/tweetsclinton.RData")
cruz.tweets <- readRDS("~/Documents/IU/CyberDH/Text_Analysis/data/twitter/tweetscruz.RData")
sanders.tweets <- readRDS("~/Documents/IU/CyberDH/Text_Analysis/data/twitter/tweetssanders.RData")
trump.tweets <- readRDS("~/Documents/IU/CyberDH/Text_Analysis/data/twitter/tweetstrump.RData")
```
***   

#### Inspect Data
Before preparing the data for analysis, let us first see what we are working with. For tutorial purposes, we will look at the first: clinton.tweets, but feel free to use the same commands to inspect any of the variables we have created. This step is a good idea to ensure you know what you are ultimately analyzing. For example, if you find that the length is zero, you may have to go back and reload or re-grab the data.

***

Class describes the type of object. In this case, we grabbed tweets using the TwitteR package, which results in a list:
```{r}
class(clinton.tweets)
```
***
Length shows how many elements the object has. We grabbed 4,000 tweets (specified while using the TwitteR package), so our list is made up of 4,000 elements. An element here is a tweet!
```{r}
length(clinton.tweets)
```
***
We can also look at individual elements - Lets see what the first (most recent) tweet is...
```{r}
clinton.tweets[1]
```
***
Or perhaps you would like to see the first few elements:
```{r}
head(clinton.tweets)
```

There are many more ways to inspect parts of data (check out the CRAN), but these quick checks are helpful while manipulating and trimming the data pre-analysis.

***
#### Extract Text
Since we grabbed our data from Twitter, there is metadata included in the tweet list such as retweet, favorite, and reply information. For sentiment analysis, we just need the text. The following line extracts the text from each tweet in the list and saves the new list of just text as [candidate_name].text.

```{r}
clinton.text = laply(clinton.tweets, function(t) t$getText())
cruz.text = laply(cruz.tweets, function(t) t$getText())
sanders.text = laply(sanders.tweets, function(t) t$getText())
trump.text = laply(trump.tweets, function(t) t$getText())
```

Now we are all set! Let's load in some postivity (and negativity, I guess...)!

***
***   

### Loading the Opinion Lexicons to Determine Sentiment
***

This is an essential step for sentiment analysis. These text documents from Hu and Liu, 2004* are filled with positive and negative words, respectively. The algorithm we will write next will check these documents to score each word in the tweet. If the algorithm runs across the word "love" in a tweet, it will check the positive-words.txt file, find "love" is included, and score the word with a +1. More on that in a second...
```{r}
lex.pos = scan('~/Documents/IU/CyberDH/Text_Analysis/data/opinionLexicon/positive-words.txt', what='character', comment.char = ';')
lex.neg = scan('~/Documents/IU/CyberDH/Text_Analysis/data/opinionLexicon/negative-words.txt', what='character', comment.char = ';')
```

***

Add words relevant to our corpus using the combine c() function:
```{r}
pos.words = c(lex.pos, 'win', 'prove', 'beat', 'endorse', 'endorses', 'exciting', 'vote', 'wins', 'support', 'supports', 'help', 'winner')
neg.words = c(lex.neg, 'lose', 'losing', 'defeat', 'halt')
```

***
***

### Implement the sentiment scoring algorithm

***

Here is where the magic happens - let's create the algorithm! To begin a function which will iterate over all of the elements in the specified object, we need to give it a name - score.sentiment sounds good. First, we set the name of our function equal to function(). Then, we fill the parenthesis with our arguments. Here, we want an argument for the tweets (our data we gathered), our positive words, and our negative words. 

We will then require the plyr and stringr packages. The plyr package splits, combines, and applies data (the laply function used below comes with this package) and the stringr package which eases string operations (we will use str_split below, which is included with the stringr package).

This function takes in an argument (tweets for us), normalizes all of the text (including removing emojis which is important for tweets), splits the tweets into separate words to analyze, compares the tweet words to the positive and negative dictionaries, returns a TRUE if the word is in the dictionary and FALSE if it is not, the trues and falses are summed up for each tweet (this is the score of the tweet), and finally, the tweet's score and its text are returned as a data frame for ease of plotting.
```{r}
score.sentiment = function(tweets, pos.words, neg.words, .progress='none')
{
  require(plyr)
  require(stringr)
  
  #figure out the score for each tweet specifically
  scores = laply(tweets, function(tweet, pos.words, neg.words) {
    #normalize tweet text
    tweet = gsub('[[:punct:]]', '', tweet)
    tweet = gsub('[[:cntrl:]]', '', tweet)
    tweet = gsub('\\d+', '', tweet)
    
    #REMOVE EMOJIS!
    tweet = iconv(tweet, "ASCII", "UTF-8", sub="")
    
    tweet.lower = tolower(tweet)
    
    #split list into separate words
    word.list = str_split(tweet.lower, '\\s+')
    words = unlist(word.list)
    
    #compare our words to the dictionaries of positive and negative terms using match function
    pos.matches = match(words, pos.words)
    neg.matches = match(words, neg.words)
    
    #match returns a position of the matched term or NA, but we just want the TRUE/FALSE, not NA
    pos.matches = !is.na(pos.matches)
    neg.matches = !is.na(neg.matches)
    
    #the score of each tweet is the sum of the positive matches minus the sum of the negative matches
    score = sum(pos.matches) - sum(neg.matches)
    
    return(score)
  }, pos.words, neg.words, .progress = .progress)
  
  #compile the scores and text of tweets into a data frame for plotting
  scores.df = data.frame(score=scores, text = tweets)
  return(scores.df)
}

```

***
#### Algorithm Testing
Whenever you create a function (or algorithm), it is best to test it on some sample data to ensure it behaves as you expect. Let's create a sample list of emotional sentences and save it as "sample".
```{r}
sample = c("This ice cream is the best! I love this flavor!", 
           "I am so angry at the terrible weather today. Frustrated.", 
           "Wow, spectacular, I wish I could be as perfect as you.")

```
***

We already did the hard part by building our score.sentiment function earlier. Here, we just need to tell the algorithm what to use as arguments! We need to put our sample data in as the "tweets" argument, pos.words as the "pos.words"" argument, and neg.words as the "neg.words" argument! 

Lets also save the result of running the algorithm as an object called sample.result.

```{r}
sample.result = score.sentiment(sample, pos.words, neg.words)
```

***

Did it work?

```{r}
sample.result
```

It worked! Now we can be sure our algorithm is behaving as we would expect. Lets score our Twitter data since we are confident in our function-creating abilities...

***
***

### Scoring Twitter Data

***
Again, we have already created our function, we just need to tell it what to analyze. We will use our [candidate].text objects as the "tweets" argument and save each as an object called [candidate].result to plot a little later.
```{r}
clinton.result = score.sentiment(clinton.text, pos.words, neg.words)
cruz.result = score.sentiment(cruz.text, pos.words, neg.words)
sanders.result = score.sentiment(sanders.text, pos.words, neg.words)
trump.result = score.sentiment(trump.text, pos.words, neg.words)
```

***

Lets peek at the results to see if it is still working...

```{r}
head(clinton.result)
```
```{r}
head(cruz.result)
```
```{r}
head(sanders.result)
```
```{r}
head(trump.result)
```
***
***

### Plotting Twitter Data


***

To visualize the sentiment of these particular tweets, we will use the plotting system ggplot2 and its quick plot (qplot) functionality. The qplot function takes an object, which is the score from our tweets, then you can specify other parts of the plot. For example, we have titled our plots "Sentiment of [candidate's twitter handle] on Twitter," labeled the x-axis "Valence of Sentiment (Tweet Score)," and labeled the y-axis "Count (Tweets)." These were all saved as [candidate].plot objects to use later.

Below, we impose the "Black and White" theme on the plots

```{r}
clinton.plot = qplot(clinton.result$score, main = "Sentiment of @HillaryClinton on Twitter", xlab= "Valence of Sentiment (Tweet Score)", ylab="Count (Tweets)")
cruz.plot = qplot(cruz.result$score, main = "Sentiment of @tedcruz on Twitter", xlab= "Valence of Sentiment (Tweet Score)", ylab="Count (Tweets)")
sanders.plot = qplot(sanders.result$score, main = "Sentiment of @BernieSanders on Twitter", xlab= "Valence of Sentiment (Tweet Score)", ylab="Count (Tweets)")
trump.plot = qplot(trump.result$score, main = "Sentiment of @realDonaldTrump on Twitter", xlab= "Valence of Sentiment (Tweet Score)", ylab="Count (Tweets)")

clinton.plot = clinton.plot + theme_bw()
cruz.plot = cruz.plot + theme_bw()
sanders.plot = sanders.plot + theme_bw()
trump.plot = trump.plot + theme_bw()
```
***

Output each plot!

```{r}
clinton.plot
```
```{r}
cruz.plot
```
```{r}
sanders.plot
```
```{r}
trump.plot
```

***


#### Voila!

***

Acknowledgements: This algorithm was adapted from Jeffrey Breen's Mining Twitter for Airline Consumer Sentiment article. You can find it here: http://www.inside-r.org/howto/mining-twitter-airline-consumer-sentiment. 

* Liu, Minqing Hu and Junsheng Cheng. "Opinion Observer: Analyzing and Comparing Opinions on the Web." Proceedings of the 14th International World Wide Web conference (WWW-2005), May 10-14, 2005, Chiba, Japan.



