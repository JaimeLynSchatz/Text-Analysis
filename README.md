# Text_Analysis
For all kinds of textual analysis: literary, social media, surveys...

This git is a repository for R scripts, notebooks, and results generated by the [CyberDH]("http://researchtech.iu.edu/ci-digital-humanities.php") Team at Indiana University. 

For help, questions, or comments, email cyberdh_at_iu_dot_edu.
<div class="page" title="Page 1">
<div class="layoutArea">
<div class="column">

Our group has been developing an open instructional workflow for text analysis that aims to build understanding and basic coding skills before scaling up analyses. We have chosen to bootstrap in R because of its statistical and graphical capabilities and because of its wealth of domain-specific packages. Moreover, the open source and scripting nature of R allows for methods that are repeatable, extensible, scalable, and sustainable. The aim is to provide code templates that can be adapted, remixed, and scaled to fit a wide range of text analysis tasks.

<strong>What is in this repo?</strong>
<ol>
 	<li>RNotebooks: heavily annotated to explain each line of code.</li>
 	<li>RScripts: lightly annotated to allow the user to experiment.</li>
 	<li>Data: need to replicate our results.*</li>
</ol>
The suggested workflow is to fork the repository for your own use. Read the RNotebook as it explains how a given script works, line by line. Then load the lightly annotated script that goes along with the notebook and try it out for yourself in RStudio. Suggestions on alterations and basic parameter tweaking are provided in the script.

*So that you can replicate our work we have provided all the data we have used in our examples. For plain text notebooks and scripts, we use the Shakespearean corpus from the Visualizing English Print Project where speaker names and stage directions are removed; for twitter notebooks and scripts, we provide twitter data that has been harvested by the team.

</div>
</div>
</div>
<a href="https://github.com/cyberdh/Text-Analysis/blob/master/RNotebooks/textPrep.pdf">Text Preparation</a>
<p style="padding-left: 30px;"><span style="line-height: 1.5;">While the methods below offer new insights to corpora, cleaning and prepping your text is key to reliable results. This tutorial goes through the basics of getting your corpus ready for analysis.</span></p>
Word Clouds

Plain text: https://github.com/cyberdh/Text-Analysis/blob/master/RNotebooks/wordcloudPlainText.Rmd

Twitter:

https://github.com/cyberdh/Text-Analysis/blob/master/RNotebooks/wordcloudTwitter.Rmd
<p style="padding-left: 30px;">Word clouds may seem simplistic, they offer a wealth of information that is easily parseable at a glance.</p>
Word Co-ocurrence

https://github.com/cyberdh/Text-Analysis/blob/master/RNotebooks/cooccurrencePlainText.Rmd
<p style="padding-left: 30px;">The co-occurrence script aims to discover the semantic proximity of two words throughout the Shakespeare Drama Corpus. At the end, it will take in a word of the user's choice and find the top ten closest terms by proximity.</p>
&nbsp;

Sentiment Analysis

https://github.com/cyberdh/Text-Analysis/blob/master/RNotebooks/sentPolitical.Rmd

Sentiment determines whether a tweeter feels negatively or positively about a topic by comparing the words in a tweet to a lexicon of words that have positive valences or negative ones. By analyzing sentiment scores, we can determine how English-language twitter users feel about a topic.