{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with Latent Dirichlet Allocation (LDA) and MALLET\n",
    "\n",
    "The following notebook walks you through doing LDA topic modeling in Python using the Gensim package MALLET wrapper. We then create an interactive visualization that can be saved as an html file and can therefore be embedded in a website or simply opened in your browser. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: In order to view the final interactive graph on GitHub you need to open this notebook in nbviewer. You can do this by clicking the \"-\" button in the upper right corner of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Before we begin\n",
    "Before we start, you will need to have set up a [Carbonate account](https://kb.iu.edu/d/aolp) in order to access [Research Desktop (ReD)](https://kb.iu.edu/d/apum). You will also need to have access to ReD through the [thinlinc client](https://kb.iu.edu/d/aput). If you have not done any of this, or have only done some of this, but not all, you should go to our [textPrep-Py.ipynb](https://github.com/cyberdh/Text-Analysis/blob/drafts/textPrep-Py.ipynb) before you proceed further. The textPrep-Py notebook provides information and resources on how to get a Carbonate account, how to set up ReD, and how to get started using the Jupyter Notebook on ReD.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CyberDH environment\n",
    "The code in the cell below points to a Python environment specificaly for use with the Python Jupyter Notebooks created by Cyberinfrastructure for Digital Humanities. It allows for the use of the different pakcages in our notebooks and their subsequent data sets.\n",
    "\n",
    "##### Packages\n",
    "- **sys:** Provides access to some variables used or maintained by the interpreter and to functions that interact strongly with the interpreter. It is always available.\n",
    "- **os:** Provides a portable way of using operating system dependent functionality.\n",
    "\n",
    "#### NOTE: This cell is only for use with Research Desktop. You will get an error if you try to run this cell on your personal device!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,\"/N/u/cyberdh/Carbonate/dhPyEnviron/lib/python3.6/site-packages\")\n",
    "os.environ[\"NLTK_DATA\"] = \"/N/u/cyberdh/Carbonate/dhPyEnviron/nltk_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's extensibility comes in large part from packages. Packages are groups of functions, data, and algorithms that allow users to easily carry out processes without recreating the wheel. Some packages are included in the basic installation of Python, others created by Python users are available for download.\n",
    "\n",
    "In your terminal, packages can be installed by typing `pip install nameofpackage --user`. However, since you are using ReD and our Python environment, you will not need to install any of the packages below to use this notebook. Anytime you need to make use of a package, however, you need to import it so that Python knows to look in these packages for any functions or commands you use. Below is a brief description of the packages we are using in this notebook:  \n",
    "\n",
    "- **re:** Provides regular expression matching operations similar to those found in Perl.\n",
    "- **json:** Allows for handling of data in JSON format.\n",
    "- **os:** Provides a portable way of using operating system dependent functionality.\n",
    "- **string:** Contains a number of functions to process standard Python strings.\n",
    "- **csv:** Implements classes to read and write tabular data in CSV format.\n",
    "- **nltk:** A leading platform for building Python programs to work with human language data.\n",
    "- **glob:** Finds all the pathnames matching a specified pattern according to the rules used by the Unix shell.\n",
    "- **numpy:** a general-purpose array-processing package designed to efficiently manipulate large multi-dimensional arrays of arbitrary records without sacrificing too much speed for small multi-dimensional arrays. \n",
    "- **pandas:** An open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "- **pprint:** Provides a capability to “pretty-print” arbitrary Python data structures in a form which can be used as input to the interpreter.\n",
    "- **gzip:** Provides a simple interface to compress and decompress files\n",
    "- **collections:** implements specialized container datatypes providing alternatives to Python?s general purpose built-in containers, dict, list, set, and tuple.\n",
    "- **sklearn:**  Module for machine learning built on top of SciPy and distributed under the 3-Clause BSD license.\n",
    "- **gensim:** Python library for topic modelling, document indexing and similarity retrieval with large corpora.\n",
    "- **spacy:** A library for advanced Natural Language Processing in Python and Cython.\n",
    "- **pyldavis:** Python library for interactive topic model visualization.\n",
    "- **matplotlib:**  Produces publication quality 2D graphics for interactive graphing, scientific publishing, user interface development and web application servers targeting multiple user interfaces and hardcopy output formats.\n",
    "- **logging:** Defines functions and classes which implement a flexible event logging system for applications and libraries.\n",
    "- **warnings:** Allows for the manipulation of warning messages in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from os.path import join, isfile, splitext\n",
    "import string\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import gzip\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "# Import warning\n",
    "import logging\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will give more details regarding error messages and will also ignore deprecation and user warnings. All the deprecation and user warnings in this code are not concerning and will not break the code or cause errors in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File paths\n",
    "Here we are saving as variables different file paths that we need in our code. We do this so that they are easier to call later and so that you can make most of your changes now and not need to make as many changes later. \n",
    "\n",
    "First we use the `os` package above to find our `[HOME]` directory using the `environ` function. This will work for any operating system, so if you decide to try this out on your personal computer instead of ReD, the `homePath` variable will still be the path to your \"home\" directory, so no changes are needed.\n",
    "\n",
    "Next, we combine the `homePath` variable with the folder names that lead to where our data is stored. Note that we do not use any file names yet, just the path to the folder. This is because we may want to read in all the files in the directory, or just one file. There are options below for doing both. We save the path as a variable named `dataHome`.\n",
    "\n",
    "Now we add the `homePath` variable to other folder names that lead to a folder where we will want to save any output generated by this code. We will change the file names for our output in other cells as we need to down below. We save this file path as the variable `dataResults`.\n",
    "\n",
    "Lastly, since we are using MALLET to do our LDA, you need to [download](http://mallet.cs.umass.edu/download.php) the MALLET zipfile, unzip it and provide the path to the extracted folder. We recommend saving the extracted folder in your \"Carbonate\" directory which is also your \"home\" directory. This way you will not need to adjust anything in the last line as it should point to the folder needed to run MALLET. We save this file path as the variable `malletPath`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "homePath = os.environ[\"HOME\"]\n",
    "dataHome = os.path.join(homePath, \"Text-Analysis-master\", \"data\")\n",
    "dataResults = os.path.join(homePath, \"Text-Analysis-master\", \"Output\")\n",
    "malletPath = os.path.join(homePath, \"mallet-2.0.8\", \"bin\", \"mallet\") # update this path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set needed variables\n",
    "This is where you will make some decisions about your data and set the necessary variables. Much like the file path variables above, we do this so you do not need to make as many changes later.\n",
    "\n",
    "**source**<br>\n",
    "First, we need to decide if we want our code to read all the files in a directory or just a single file. If we want all the files in a directory then we set `source` equal to `\"*\"`. This means 'all' and will be added to the file type later in the code. If you want a single file change `\"*\"` to the file name without the \".txt\" or \".csv\" or \".json\" at the end. So if you have a file named \"myFile.txt\" you would set `source` equal to `\"myFile\"` without the \".txt\".\n",
    "\n",
    "**fileType**<br>\n",
    "Now we need to determine what file type our data is. You can find this by the file extension at the end of your file's name. Right now we can only read in plain text files which end in \".txt\" (minus the quotes), comma separated value files which end in \".csv\", and JSON files which end in \".json\". So where it says `fileType =` inside the double quotes you need to put either `\".txt\"`, `\".csv\"`, or `\".json\"` depending on what your data file type is.\n",
    "\n",
    "**docLevel**<br>\n",
    "The `docLevel` variable is only for file types of \".txt\" so if you have a \".csv\" or \".json\" you want to set it to **False** or it will cause problems in other parts of the code later since we do not keep track of file names for the \".csv\" and \".json\" files. If your data is in \".txt\" format, then you need to determine if you want to chunk your corpus by line or by document.\n",
    "\n",
    "We do this in case your data is a single \".txt\" file. The LDA algorithm needs to have multiple chunks to accurately weigh and order words into topics. If you have multiple documents then the documents themselves are the chunks. If you have a single document, then we need to create chunks, and we do this by spliting the document up by line and each line is a separate chunk.\n",
    "\n",
    "If you want to separate by document, then set docLevel equal to **True**. If you want to separate a line at a time and have each line be it's own entity or 'chunk' then set `docLevel` equal to **False**. If you set `source` equal to `\"*\"` then you will want to set `docLevel` equal to **True**. If you set `source` equal to a specific file name, then you will want to set `docLevel` equal to **False**.\n",
    "\n",
    "**nltkStop**<br>\n",
    "The `nltkStop` is where you determine if you want to use the built in stopword list provided by the NLTK package. They provide stopword lists in multiple languages. If you wish to use this then set `nltkStop` equal to **True**. If you do not, then set `nltkStop` equal to **False**.\n",
    "\n",
    "**customStop**<br>\n",
    "`customStop` is for if you have a .txt file that contains additional stopwords that you would like to read in and have added to the existing `stopWords` list. You do *NOT* need to use the NLTK stopwords list in order to add your own custom list of stopwords. **NOTE: Your custom stopwords file needs to have one word per line as it reads in a line at a time and the full contents of the line is read in and added to the existing stopWords list.** If you have a list of your own then set `customStop` equal to **True**. If you do not have your own custom stopwords list then set `customStop` equal to **False**.\n",
    "\n",
    "**spacyLem**<br>\n",
    "`spacyLem` is where we decide if we want to use the spaCy package lemmatization function. What is lemmatization? Lemmatization is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form. In computational linguistics, lemmatisation is the algorithmic process of determining the lemma of a word based on its intended meaning. Unlike stemming, lemmatisation depends on correctly identifying the intended part of speech and meaning of a word in a sentence, where as stemming does not take the context of the word into account. For example, if we lemmatize the word \"running\" or \"ran\" it will become the word \"run\". If we stem the word \"running\" most stemmers will convert it to \"runn\" only removing the \"ing\" and leaving the second \"n\". Stemming will also change \"police\" and \"policy\" both to \"polic\" and they will be considered the same word by the LDA script. The lemmatizer will leave both words as \"police\" and \"policy\". This is useful and recommended for topic modeling as it allows the algorithm to just consider \"walk\" instead of \"walking\", \"walked\", and \"walk\" and thereby can increase the accuracy of your results. To use the spacy lemmatizer set `spacyLem` equal to **True**. If you do not wish to use the lemmatizer set `spacyLem` equal to **False**.\n",
    "\n",
    "**stopLang**<br>\n",
    "Now we choose the language we will be using for the nltk stopwords list. If you need a different language, simply change `'english'` (keep the quotes) in the `stopLang` variable to the anglicized name of the language you wish to use (e.g. 'spanish' instead of 'espanol' or 'german' instead of 'deutsch'). If you need to see the list of available languages in nltk simply remove the `#` from in front of `#print(\" \".join(stopwords.fileids()))` on the last line and run the cell. A list of available languages will display below the cell.\n",
    "\n",
    "**lemLang**<br>\n",
    "Now we choose the language for our lemmatizer. The languages available for spacy include the list below and the abbreviation spacy uses for that language:\n",
    "\n",
    "- **English:** en\n",
    "- **Spanish:** es\n",
    "- **German:** de\n",
    "- **French:** fr\n",
    "- **Italian:** it\n",
    "- **Portuguese:** pt\n",
    "- **Dutch:** nl\n",
    "- **Multi-Language:** xx\n",
    "\n",
    "To choose a language simply type the two letter code following the angliscized language name in the list above. So for Spanish it would be `'es'` (with the quotes) and for German `'de'` and so on.\n",
    "\n",
    "**stopWords, docs, tweets**<br>\n",
    "The `stopWords =[]` variable is simply an empty list. This is where the words from the nltk stopword list or your custom stopword list or both combined or neither (depending on what you decide) will reside later on. You do not need to do anything to this line of code.\n",
    "\n",
    "The docs and tweets variables do not need to have anything done as they are also empty lists that have elements added to them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = \"*\"\n",
    "fileType = \".txt\"\n",
    "docLevel = True\n",
    "nltkStop = True\n",
    "customStop = True\n",
    "spacyLem = True\n",
    "stopLang = 'english'\n",
    "lemLang = 'en'\n",
    "stopWords = []\n",
    "docs = []\n",
    "tweets = []\n",
    "\n",
    "#print(\" \".join(stopwords.fileids()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "If you set `nltkStop` equal to **True** above then this will add the NLTK stopwords list to the empty list named `stopWords`.\n",
    "\n",
    "You already chose your desired language above, so you do not need to do that now. \n",
    "\n",
    "If you need to add a few more words to the `stopWords` list that are specific to your dataset (such as common names or phrases that may make your results inaccurate), then add those to the `stopWords.extend(['would', 'said', 'says', 'also'])` part of the code in the square brackets with single quotes around each word and separated by a comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "if nltkStop is True:\n",
    "    stopWords.extend(stopwords.words(stopLang))\n",
    "\n",
    "    stopWords.extend(['would', 'said', 'says', 'also'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add own stopword list\n",
    "\n",
    "Here is where your own stopwords list is added if you selected **True** in `customStop` above. Here you will need to change the folder names and file name to match your folders and file. Remember to put each folder name in quotes and in the correct order always putting the file name including the file extension (.txt) last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if customStop is True:\n",
    "    stopWordsFilepath = os.path.join(homePath, \"Text-Analysis-master\", \"data\", \"earlyModernStopword.txt\")\n",
    "\n",
    "    with open(stopWordsFilepath, \"r\",encoding = 'utf-8') as stopfile:\n",
    "        stopWordsCustom = [x.strip() for x in stopfile.readlines()]\n",
    "\n",
    "    stopWords.extend(stopWordsCustom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in .txt files\n",
    "The code below reads in text files if you chose fileType `\".txt\"` above. It can do this in two ways. We can read in an entire directory, or we can read in a single file and it will do those based on what you chose for `source` above. Then it will chunk your data, either by document or by line, and this will depend on what you chose for `docLevel` above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if fileType == \".txt\":\n",
    "    paths = glob.glob(os.path.join(dataHome, \"shakespeareDated\", source + fileType))\n",
    "    for path in paths:\n",
    "        with open(path, \"r\", encoding = 'ISO-8859-1') as file:\n",
    "             # skip hidden file\n",
    "            if path.startswith('.'):\n",
    "                continue\n",
    "            if docLevel is True:\n",
    "                docs.append(file.read().strip('\\n').splitlines())\n",
    "            else:\n",
    "                for line in file:\n",
    "                    stripLine = line.strip()\n",
    "                    if len(stripLine) == 0:\n",
    "                        continue\n",
    "                    docs.append(stripLine.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in .csv files\n",
    "\n",
    "If you chose `\".csv\"` as your `fileType` up above, then the code below reads in \".csv\" files and saves the contents to a dataframe using the Pandas package. It will read in either an entire directory or a single \".csv\" file depending on what you chose for `source` above. \n",
    "\n",
    "Once we have read in the \".csv\" file using the Pandas `read_csv` function, we need to concatenate the \".csv\" files if there are multiple. Because of this it is important that your \".csv\" files have and identical column count and each column has identical header names or you will get errors. If you have a single \".csv\" file then you should be fine for this step. We assign this process to the variable `cc_df` so we can use it later.\n",
    "\n",
    "Now we convert our `cc_df` to a pandas dataframe. This allows for easier manipulation of the data in the next step.\n",
    "\n",
    "The last line is where you will name the column you wish to convert to a list. In between the square brackets you can either put the column header name with quotes around the name, or you can put the column number counting from left to right and starting with 0 instead of 1. Here we are converting the column labeled `['text']` to a list. If you wished to convert the first column to a list the code would look like this: `tweets = cc_df[0].values.tolist()`. Notice the number is 0 and not 1. This is because Python begins counting at 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if fileType == \".csv\":\n",
    "    all_files = glob.glob(os.path.join(dataHome, \"twitter\", source + fileType))     \n",
    "    df_all = (pd.read_csv(f) for f in all_files)\n",
    "    cc_df = pd.concat(df_all, ignore_index=True)\n",
    "    cc_df = pd.DataFrame(cc_df, dtype = 'str')\n",
    "    tweets = cc_df['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in JSON files\n",
    "\n",
    "If you chose `\".json\"` as your `fileType` up above, then the code below reads in \".json\" files and saves the contents to a dataframe using the Pandas package. It will read in either an entire directory or a single \".json\" file depending on what you chose for `source` above. \n",
    "\n",
    "Once we have read in the \".json\" file we need to append the \".json\" files if there are multiple. Because of this it is important that your \".json\" files have identical keys or you will get errors. If you have a single \".json\" file then you should be fine for this step. \n",
    "\n",
    "Next we append the contents to our empty `tweets=[]` list we created above. Then we convert our tweets list to a dataframe so we can more easily manipulate the data. Each key from the \".json\" content is converted to a header in the dataframe and the values associated with that key now become rows in the corresponding column.\n",
    "\n",
    "In the last line we now convert one column in our dataframe to a list. In between the square brackets you can either put the column header name with quotes around the name, or you can put the column number counting from left to right and starting with 0 instead of 1. Here we are converting the column labeled `['text']` to a list. If you wished to convert the first column to a list the code would look like this: `tweets = df[0].tolist()`. Notice the number is 0 and not 1. This is because Python begins counting at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if fileType == \".json\":\n",
    "    for filename in glob.glob(os.path.join(dataHome, \"twitter\", \"JSON\", source + fileType)):\n",
    "        with open(filename, 'r', encoding = \"utf-8\") as jsonData:\n",
    "            for line in jsonData:\n",
    "                tweets.append(json.loads(line))\n",
    "    df = pd.DataFrame(tweets)\n",
    "    tweets = df['text'].tolist()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data variable\n",
    "\n",
    "Now we need to change our variable containing our data (either docs or tweets from above) to the variable `data` since this is the variable used going forward and it saves you from having to switch between `tweets` and `docs` later in the code. If you read in \".csv\" or \".json\" files then your data is saved in the `tweets` list and if you read in \".txt\" files then it is in the `docs` list. This code says if the length of the `docs` list is greater than 0 then assign `docs` to the variable data. If the length of `tweets` greater than 0 then assign `tweets` to the variable `data`.\n",
    "\n",
    "If your data was in `tweets` then it most likely needs some additional cleaning. So the next chunk of code removes URLS and new line characters from the `data` variable if the length of `tweets` is greater than 0.\n",
    "\n",
    "The last line prints out the first chunk of data in our collection, in this case the first few lines of the first item in our list of lists. If you are reading in a single document this will print the first line of your data. If you are reading in a line at a time this will print out each word for the entire text (either a single document or mutiple documents depending on your choices above) on it's own individual line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cease to persuade, my loving Proteus.\n",
      " I'll feeze you, in faith.\n",
      " Hung be the heavens with black, yield day to night!\n",
      " As by your high imperial Majesty\n",
      " I wonder how the King escaped our hands.\n",
      " Noble patricians, patrons of my right,\n",
      " Now is the winter of our discontent\n",
      " Proceed, Solinus, to procure my fall,\n",
      " Let fame, that all hunt after in their lives,\n",
      " Old John of Gaunt, time-honored Lancaster,\n",
      " Now, fair Hippolyta, our nuptial hour\n",
      " Two households, both alike in dignity\n",
      " So shaken as we are, so wan with care,\n",
      " Now say, Chatillion, what would France with us?\n",
      " In sooth I know not why I am so sad.\n",
      " Open your ears, for which of you will stop\n",
      " Sir Hugh, persuade me not. I will make a\n",
      " I learn in this letter that Don\n",
      " As I remember, Adam, it was upon this\n",
      " Who's there?\n",
      " Hence! Home, you idle creatures, get you home!\n",
      " O, for a muse of fire that would ascend\n",
      " In Troy there lies the scene. From isles of Greece\n",
      " If music be the food of love, play on.\n",
      " Escalus.\n",
      " Tush, never tell me! I take it much unkindly\n",
      " In delivering my son from me, I bury a second\n",
      " I thought the King had more affected the Duke\n",
      " Good day, sir.\n",
      " Nay, but this dotage of our general's\n",
      " When shall we three meet again?\n",
      " Before we proceed any further, hear me\n",
      " If you shall chance, Camillo, to visit Bohemia\n",
      " You do not meet a man but frowns. Our bloods\n",
      " Boatswain!\n",
      " I come no more to make you laugh. Things now\n"
     ]
    }
   ],
   "source": [
    "if len(docs) > 0:\n",
    "    data = docs\n",
    "else:\n",
    "    if len(tweets) > 0:\n",
    "        data = tweets\n",
    "        # Remove Urls\n",
    "        data = [re.sub(r'http\\S+', '', sent) for sent in data]\n",
    "        # Remove new line characters\n",
    "        data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "for i in data:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing\n",
    "\n",
    "This block of code separates each chunk of text into a list of individual words. In the process it also lower cases all the words and removes punctuation. If you wish to keep the punctuation change `deacc = True` to `deacc = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cease']\n",
      "['ll']\n",
      "['hung']\n",
      "['as']\n",
      "['wonder']\n",
      "['noble']\n",
      "['now']\n",
      "['proceed']\n",
      "['let']\n",
      "['old']\n",
      "['now']\n",
      "['two']\n",
      "['so']\n",
      "['now']\n",
      "['in']\n",
      "['open']\n",
      "['sir']\n",
      "['learn']\n",
      "['as']\n",
      "['who']\n",
      "['hence']\n",
      "['for']\n",
      "['in']\n",
      "['if']\n",
      "['escalus']\n",
      "['tush']\n",
      "['in']\n",
      "['thought']\n",
      "['good']\n",
      "['nay']\n",
      "['when']\n",
      "['before']\n",
      "['if']\n",
      "['you']\n",
      "['boatswain']\n",
      "['come']\n"
     ]
    }
   ],
   "source": [
    "def sentToWords(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "dataWords = list(sentToWords(data))\n",
    "\n",
    "for i in dataWords:\n",
    "    print(i[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Bigrams and Trigrams\n",
    "\n",
    "This code will most likely not need to be adjusted. It creates a model of bigrams and trigrams in your dataset that occur frequently and then connects them with an underscore so the LDA algorithm will later consider them as one word. This is a good idea for items like 'new york' or 'new zealand' or 'Ho Chi Minh'. If we do not combine these frequently occuring phrases then 'new' and 'york' will be considered independently and give us less accurate results. \n",
    "\n",
    "Right now we have a `min_count` of 5 and a `threshold` of 100. The `min_count` is simply the minimum number of times the bigram or trigram needs to occur in order to be combined with an underscore. The `threshold` is a score that the bigram or trigram needs to exceed in order to be combined with an underscore. The score is determined by using this formula: (bigram_count - min_count)\\*vocab_count/(wordA_count \\* wordB_count). So let's say we have the bigram \"good_lord\" and it appears 30 times in a text of 10,000 words where \"good\" appears 60 times total and \"lord\" appears 40. With our `min_count` set to 5 we get the following: (30 - 5)\\*10000/(60 \\* 40) = 104.167 which means since our `threshold` is set to 100 \"good_lord\" will be combined with an underscore and made into a bigram. If the resulting score is above your `threshold` then the ngram is considered important enough to combine with an underscore and will be viewed as one word for the LDA scoring later. Therefore, if you increase the `threshold`, you will get fewer bigrams and trigrams. If our threshold was set to 110, then \"good\" and \"lord\" would not be combined into \"good_lord\".\n",
    "\n",
    "The Phraser function takes the model you built with the Phrases function and cuts down memory consumption of Phrases, by discarding model state not strictly needed for the bigram detection task.\n",
    "\n",
    "Lastly, we take a look at the ngrams created from the first item in our dataset only, so the results are for only one chunk, not the whole dataset. We do this by counting the number of words that contain an underscore as this is used to connect the words in the ngram together. **NOTE:** The output is only to test if the ngrams work so you will probably see ngrams containing stopwords. We will create a few functions next and then apply them to remove stopwords, create bigrams, and lemmatize the chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'thousand_times': 4,\n",
      "         'good_morrow': 4,\n",
      "         'chamber_window': 3,\n",
      "         'fie_fie': 2,\n",
      "         'an_ass': 2,\n",
      "         'fast_asleep': 2,\n",
      "         'gav_st': 1,\n",
      "         'hard_favored': 1,\n",
      "         'twenty_thousand': 1,\n",
      "         'ill_favored': 1,\n",
      "         'stand_aside': 1,\n",
      "         'looking_glass': 1,\n",
      "         'amen_amen': 1})\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = Phrases(dataWords, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = Phrases(bigram[dataWords], threshold=100)  \n",
    "\n",
    "# Removes model state from Phrases thereby reducing memory use.\n",
    "bigramMod = Phraser(bigram)\n",
    "trigramMod = Phraser(trigram)\n",
    "\n",
    "# See bigram/trigram example\n",
    "testNgram = trigramMod[bigramMod[dataWords[0]]]\n",
    "char = \"_\"\n",
    "nGrams = [s for s in testNgram if char in s]\n",
    "            \n",
    "pprint(Counter(nGrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "We need to create a function in order to stem and tokenize our data. Any time you see `def` that means we are **DE**claring a **F**unction. The `def` is usually followed by the name of the function being created and then in parentheses are the parameters required by the function. After the parentheses is a colon, which closes the declaration, then a bunch of code below which is indented. The indented code is the program statement or statements to be executed. Once you have created your function all you need to do in order to run it is call the function by name and make sure you have included all the required parameters in the parentheses. This allows you to call the function without having to write out all the code in the function every time you wish to perform that task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some functions\n",
    "\n",
    "Below are functions we are creating that perform certain tasks. First we are creating a function to remove the stopwords that are in our stopword list we created previously. Then we create functions to apply our bigram and trigram code from above. \n",
    "\n",
    "Lastly, if you set `spacyLem` equal to **True** above then we will create the `lemmatization` function. If you set it equal to **False** then it will not create the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def removeStopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stopWords] for doc in texts]\n",
    "\n",
    "def makeBigrams(texts):\n",
    "    return [bigramMod[doc] for doc in texts]\n",
    "\n",
    "def makeTrigrams(texts):\n",
    "    return [trigramMod[bigramMod[doc]] for doc in texts]\n",
    "\n",
    "\n",
    "if spacyLem is True:\n",
    "    def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "        \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "        textsOut = []\n",
    "        lemmaPOS = []\n",
    "        for sent in texts:\n",
    "            doc = nlp(\" \".join(sent)) \n",
    "            textsOut.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "            lemmaPOS.append([token.text and token.lemma_ and token.pos_ for token in doc if token.pos_ in allowed_postags])\n",
    "        return textsOut\n",
    "        print(lemmaPOS[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the functions. There are really only two parts where you may need to make changes and they are in the lines `dataWordsNgrams = makeBigrams(dataWordsNostops)` and `nlp = spacy.load(lemLang, disable=\\['parser', 'ner'\\])`.\n",
    "\n",
    "The `dataWordsNgrams` variable is where you will change between either using the `makeBigrams` or `makeTrigrams` functions above. If you only want bigrams, then keep the code as it is. If you want both bigrams and trigrams to be considered in your topic modeling, then change the `makeBigrams` part to `makeTrigrams` and it will now calculate both bigrams and trigrams. \n",
    "\n",
    "\n",
    "Adjustments to the other line that might need changes mentioned above may only be necessary if you previously set `spacyLem` equal to **True**. Even if you set it to **True** you may still not need to make changes. The line of code you may want to change is `nlp = spacy.load('lemLang', disable=\\['parser', 'ner'\\])` and is where you can disable the parser and named entity recognizer (ner). \n",
    "\n",
    "If you wish for your words to be parsed simply remove `'parser'` from the `disable=` bracket. Same for `ner`. If you wish to use both the parser and ner then just remove the `, disable=\\['parser', 'ner'\\]` entirely (including the preceding comma), but leave the closing parantheses. The reason we disable to 'parser' and 'ner' is because they slow down the lemmatization process and are not necessary to lemmatize our dataset.\n",
    "\n",
    "Lastly, we print out the ngrams we find in the first chunk (document or line) of our data. Notice there are no trigrams included. This is because we applied only the `makeBigrams` function from above. If we had applied the `makeTrigrams` function we would have both bigrams and trigrams. Feel free to change this in the code as described above. If we set `spacyLem` equal to **True** then we will get the first 10 words, their lemmatized form (which sometimes is identical to the word being lemmatized), with their parts of speech tagging from the `lemmatization` function above. Below this is a list of the lemmatized bigrams from the first chunk of our data. If we set it to **false** then we will get bigrams from the first chunk that have not been lemmatized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cease', 'cease', 'VERB'], ['persuade', 'persuade', 'NOUN'], ['love', 'love', 'NOUN'], ['proteus', 'proteus', 'NOUN'], ['home', 'home', 'NOUN'], ['keep', 'keep', 'VERB'], ['youth', 'youth', 'NOUN'], ['homely', 'homely', 'ADV'], ['wit', 'wit', 'ADP'], ['affection', 'affection', 'NOUN']]\n",
      "Counter({'good_morrow': 4, 'chamber_window': 3, 'fast_asleep': 2, 'gav_st': 1, 'fie_fie': 1, 'ill_favor': 1, 'stand_aside': 1, 'looking_glass': 1, 'amen_amen': 1})\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "dataWordsNostops = removeStopwords(dataWords)\n",
    "\n",
    "# Form Bigrams\n",
    "dataWordsNgrams = makeBigrams(dataWordsNostops)\n",
    "\n",
    "if spacyLem is True:\n",
    "    # Initialize spacy language model, eliminating the parser and ner components\n",
    "    nlp = spacy.load(lemLang, disable=['parser', 'ner'])\n",
    "    \n",
    "    # Do lemmatization tagging only noun, adj, vb, adv\n",
    "    allowed_postags = ['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "    dataLemmatized = lemmatization(dataWordsNgrams, allowed_postags=allowed_postags)\n",
    "    lemmaPOS = []\n",
    "    for sent in dataLemmatized:\n",
    "        lemmaNLP = nlp(\" \".join(sent))\n",
    "        for token in lemmaNLP:\n",
    "            lemmaPOS.append([token.text, token.lemma_, token.pos_])\n",
    "    print(lemmaPOS[:10])\n",
    "    \n",
    "\n",
    "    # Find ngrams and count number of times they occur\n",
    "    dataNgrams = [s for s in dataLemmatized[0] if char in s]\n",
    "    \n",
    "else:\n",
    "    dataNgrams = [s for s in dataWordsNgrams[0] if char in s]\n",
    "print(Counter(dataNgrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Dictionary and Corpus needed for Topic Modeling\n",
    "\n",
    "The two main inputs to the LDA topic model are the dictionary(id2word) and the corpus. Let’s create them.\n",
    "\n",
    "First, we need to determine if we are using lemmatized data or not. To do this we are using another `if` statement. Here, `if` we set `spacyLem` equal to **True** then we create the id2word dictionary based off of the lemmatized version of the data. However, if we did not, (denoted by `else`) then we will create the id2word dictionary based on the non-lemmatized data.\n",
    "\n",
    "Gensim creates a unique id for each word in the document. For example, (0, 1) implies, word id 0 occurs once in the first document. Likewise, word id 1 occurs twice and so on.\n",
    "\n",
    "This is used as the input by the LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if spacyLem is True:\n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(dataLemmatized)\n",
    "\n",
    "    # Create Corpus\n",
    "    texts = dataLemmatized\n",
    "else:\n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(dataWordsNgrams)\n",
    "\n",
    "    # Create Corpus\n",
    "    texts = dataWordsNgrams\n",
    "    \n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see what word a given id corresponds to, pass the id as a key to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accord'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can see a human-readable form of the corpus itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('abbey', 1), ('abc', 1), ('abhor', 1), ('able', 1), ('abode', 1), ('abridge', 1), ('abroad', 1), ('absence', 1), ('access', 3), ('accomplish', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "hReadable = [[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]\n",
    "for i in hReadable:\n",
    "    print(i[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING MALLET\n",
    "\n",
    "Gensim provides a wrapper to implement Mallet’s LDA from within Gensim itself. As long as you have [downloaded](http://mallet.cs.umass.edu/download.php) the MALLET zipfile, extracted it and provided the path to the extracted mallet folder in the `malletPath` variable in the cell where we assign file paths to variables towards the top, then you should be good. \n",
    "\n",
    "In the line of code, the only parts you will possibly change is \"num_topics=20\", \"iterations=1000\", and \"random_seed = 42\". These numbers determine the number of topic bins you want to use, the number of times you want to iterate through and run the LDA algorithm over your data, and the seed or version you want to use, respectively. \n",
    "\n",
    "The seed helps with reproducability so if someone else runs the code on your dataset with these settings they should get the same answer. **Note:** the topics will be the same, but possibly in a different order even when you set the seed, so if you run it and get a set of words for topic 5, then if you run it again with the exact same settings on the exact same dataset what was topic 5 might now be topic 12, but the topic will contain the same words ordered by weight/importance. \n",
    "\n",
    "Adjustments should be made according to your specific data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldamallet = LdaMallet(malletPath, corpus=corpus, num_topics=20, id2word=id2word, workers = 1, iterations = 1000, random_seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we display the \"Top Ten\" topics and the coherence score of the MALLET topics. The results show the topic number, the ten highest weighted (or important) keywords, and the weight score of those words. Finally, you get the coherence score.\n",
    "\n",
    "The weight score may seem very low, however, when you consider that every word in your data makes up every topic then the words seem more important.\n",
    "\n",
    "The coherence score is an algorithm that determines how 'human understandable' or 'coherent' your collection of topics are. We will do more with the coherence score further down in the notebook. For now, you should not need to make any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(13,\n",
      "  [('duke', 0.024501300954032957),\n",
      "   ('cassio', 0.024284475281873375),\n",
      "   ('brother', 0.019080659150043366),\n",
      "   ('angelo', 0.016912402428447527),\n",
      "   ('wife', 0.013876843018213356),\n",
      "   ('moor', 0.013443191673894189),\n",
      "   ('monster', 0.012792714657415438),\n",
      "   ('soul', 0.011925411968777104),\n",
      "   ('husband', 0.009540329575021683),\n",
      "   ('dost', 0.009540329575021683)]),\n",
      " (0,\n",
      "  [('father', 0.03561253561253561),\n",
      "   ('master', 0.030626780626780627),\n",
      "   ('daughter', 0.024691358024691357),\n",
      "   ('love', 0.02184235517568851),\n",
      "   ('kate', 0.01899335232668566),\n",
      "   ('sister', 0.017331433998100665),\n",
      "   ('valentine', 0.014957264957264958),\n",
      "   ('sylvia', 0.01282051282051282),\n",
      "   ('proteus', 0.012108262108262107),\n",
      "   ('mad', 0.011870845204178538)]),\n",
      " (16,\n",
      "  [('master', 0.04090623033354311),\n",
      "   ('wife', 0.014317180616740088),\n",
      "   ('pray', 0.012271869100062933),\n",
      "   ('cousin', 0.010698552548772814),\n",
      "   ('harry', 0.01038388923851479),\n",
      "   ('john', 0.010069225928256766),\n",
      "   ('shallow', 0.009911894273127754),\n",
      "   ('money', 0.009754562617998742),\n",
      "   ('page', 0.009754562617998742),\n",
      "   ('woman', 0.009754562617998742)]),\n",
      " (15,\n",
      "  [('king', 0.04245008722620663),\n",
      "   ('good', 0.0391548749757705),\n",
      "   ('queen', 0.02539251792983136),\n",
      "   ('business', 0.01938360147315371),\n",
      "   ('father', 0.016669897266912193),\n",
      "   ('son', 0.010370226788137236),\n",
      "   ('purpose', 0.010370226788137236),\n",
      "   ('daughter', 0.010273308780771467),\n",
      "   ('command', 0.010273308780771467),\n",
      "   ('honour', 0.009982554758674161)]),\n",
      " (19,\n",
      "  [('love', 0.05309734513274336),\n",
      "   ('sweet', 0.02773995915588836),\n",
      "   ('eye', 0.01991150442477876),\n",
      "   ('fair', 0.019741320626276378),\n",
      "   ('man', 0.015486725663716814),\n",
      "   ('play', 0.013614703880190605),\n",
      "   ('lover', 0.012933968686181076),\n",
      "   ('wit', 0.01055139550714772),\n",
      "   ('rosalind', 0.009870660313138189),\n",
      "   ('shepherd', 0.009360108917631041)]),\n",
      " (18,\n",
      "  [('king', 0.05088772193048262),\n",
      "   ('france', 0.0398849712428107),\n",
      "   ('england', 0.023005751437859465),\n",
      "   ('majesty', 0.019129782445611403),\n",
      "   ('french', 0.018754688672168042),\n",
      "   ('great', 0.018129532383095774),\n",
      "   ('english', 0.016129032258064516),\n",
      "   ('war', 0.012628157039259815),\n",
      "   ('duke', 0.012378094523630907),\n",
      "   ('cardinal', 0.012003000750187547)]),\n",
      " (4,\n",
      "  [('love', 0.06418652359160486),\n",
      "   ('make', 0.025564147072747356),\n",
      "   ('lady', 0.02015938141076219),\n",
      "   ('madam', 0.01850244595234338),\n",
      "   ('good', 0.018186839198358846),\n",
      "   ('pray', 0.017397822313397506),\n",
      "   ('master', 0.01684551049392457),\n",
      "   ('woman', 0.0162142969859555),\n",
      "   ('gentleman', 0.013886697175319552),\n",
      "   ('speak', 0.013216032823102415)]),\n",
      " (3,\n",
      "  [('lord', 0.04481290611696168),\n",
      "   ('king', 0.018821420569123906),\n",
      "   ('hamlet', 0.017701097916199865),\n",
      "   ('father', 0.015012323549182164),\n",
      "   ('soul', 0.013667936365673313),\n",
      "   ('time', 0.01277167824333408),\n",
      "   ('nature', 0.012547613712749272),\n",
      "   ('night', 0.012323549182164464),\n",
      "   ('speak', 0.012099484651579655),\n",
      "   ('murder', 0.009634774815146763)]),\n",
      " (8,\n",
      "  [('lord', 0.07116184786087698),\n",
      "   ('man', 0.04548525907749209),\n",
      "   ('great', 0.02414737366193677),\n",
      "   ('god', 0.01781713432198869),\n",
      "   ('honour', 0.017354813471318325),\n",
      "   ('time', 0.01682136633592944),\n",
      "   ('show', 0.01468757779437391),\n",
      "   ('bring', 0.010348874426544329),\n",
      "   ('give', 0.010277748141825811),\n",
      "   ('poor', 0.010135495572388777)]),\n",
      " (11,\n",
      "  [('rome', 0.03610641891891892),\n",
      "   ('people', 0.026393581081081082),\n",
      "   ('noble', 0.023859797297297296),\n",
      "   ('hear', 0.02322635135135135),\n",
      "   ('roman', 0.021114864864864864),\n",
      "   ('good', 0.018369932432432432),\n",
      "   ('country', 0.016047297297297296),\n",
      "   ('martius', 0.015202702702702704),\n",
      "   ('voice', 0.01393581081081081),\n",
      "   ('worthy', 0.013302364864864864)])]\n",
      "\n",
      "Coherence Score:  0.32073606780791025\n"
     ]
    }
   ],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "if spacyLem is True:\n",
    "    # Compute Coherence Score\n",
    "    coherenceModelLdamallet = CoherenceModel(model=ldamallet, texts=dataLemmatized, dictionary=id2word, coherence='c_v')\n",
    "    coherenceLdamallet = coherenceModelLdamallet.get_coherence()\n",
    "else:\n",
    "    # Compute Coherence Score\n",
    "    coherenceModelLdamallet = CoherenceModel(model=ldamallet, texts=dataWordsNgrams, dictionary=id2word, coherence='c_v')\n",
    "    coherenceLdamallet = coherenceModelLdamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherenceLdamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIND OPTIMAL NUMBER OF TOPICS\n",
    "\n",
    "Next we will try and find the optimal number of topics. To do this we build many LDA models with different values of number of topics and pick the one that gives the highest coherence value. We do this by creating the function `computeCoherenceValues`. You will most likley not want to make changes to the function. Any possible changes will come in the next cell of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeCoherenceValues(dictionary, corpus, texts, limit, start=20, step=10):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    modelList : List of LDA topic models\n",
    "    coherenceValues : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherenceValues = []\n",
    "    modelList = []\n",
    "    for numTopics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(malletPath, corpus=corpus, num_topics=numTopics, id2word=id2word)\n",
    "        modelList.append(model)\n",
    "        coherenceModel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherenceValues.append(coherenceModel.get_coherence())\n",
    "\n",
    "    return modelList, coherenceValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `computeCoherenceValues()` trains multiple LDA models and their corresponding coherence scores. Right now we have it set to start with 20 topics and increase the number of topics by 10 every time and stopping at 80 topics. Notice that `limit` is set to 81, not 80. This is because the `limit` parameter is exclusive, meaning it includes everything before that number, but not the number itself. However, the `start` parameter is inclusive, so it includes the number we assign to that parameter. If we wanted to start at 30 topics and go up by 20 topics each time and stop at 90 topics as the max we would change the start, limit, and step numbers to `start=30, limit=91, step=20`. This is the only part of the code you may want to adjust depending on your needs.\n",
    "\n",
    "**NOTE:** If you set `spacyLem` equal to **True** then make changes in the first line that starts `modelList, coherenceValues`. If you set `spacyLem` equal to **False**, then make changes in the second line that starts `modelList, coherenceValues`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "if spacyLem is True:\n",
    "    modelList, coherenceValues = computeCoherenceValues(dictionary=id2word, corpus=corpus, texts=dataLemmatized, start=20, limit=81, step=10)\n",
    "else:\n",
    "    modelList, coherenceValues = computeCoherenceValues(dictionary=id2word, corpus=corpus, texts=dataWordsNgrams, start=20, limit=81, step=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to visualize the coherence scores for each number of topics to help us decide how many topics we should use going forward. Here we need to make sure the limit, start, and step are the same as what we have in the previous code cell so that we can accurately see the coherence scores for each topic.\n",
    "\n",
    "Choosing a number of topics that marks the end of a sharp increase in topic coherence scores usually offers meaningful and interpretable topics. Picking an even higher value can sometimes provide more granular sub-topics. If you see the same keywords being repeated in multiple topics, it’s probably a sign that the number of topics is too large. To choose the number of topics that might be best do not just use the highest coherence score. There are other factors that need to be considered. If the coherence score just seems to keep climbing higher and higher along with the number of topics, it might be best to find the number where it appears to stop and flatten out a bit before continuing to ascend. You do not want to run the risk of having too many or too few topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYYwxpkb/D8AR5J5cqGdpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "limit=81; start=20; step=10;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherenceValues)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherenceValues\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a visual, it may help to go back and look at the actuall numbers. The code below lists the coherence score for each number of topics we have selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 20  has Coherence Value of 0.3727\n",
      "Num Topics = 30  has Coherence Value of 0.38\n",
      "Num Topics = 40  has Coherence Value of 0.399\n",
      "Num Topics = 50  has Coherence Value of 0.4056\n",
      "Num Topics = 60  has Coherence Value of 0.421\n",
      "Num Topics = 70  has Coherence Value of 0.3883\n",
      "Num Topics = 80  has Coherence Value of 0.3797\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherenceValues):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we choose how many topics we want to work with going forward. To do this we count Pythonically (so starting with 0) and in the first line we choose the number of topics we want based on the order of where it falls in the list from the previous cell. So if we wish to keep using 20 topics, in the first line of code I would put `optimal_model = model_list[0]` which says I want to use the first item in the list called \"model_list\" which in this case is using 20 topics. If I wanted 60 topics I would change the [0] to a [4]. Pick whichever number of topics you think provides the best results for your data. We have it set to 20 (or number [0] in the list).\n",
    "\n",
    "The second line of code says we want to see the topics and the weighted words associated with them as well as the weight of each word.\n",
    "\n",
    "The final line of code says that we only want to see the top ten words based on their weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.017*\"pray\" + 0.015*\"man\" + 0.015*\"jew\" + 0.014*\"ring\" + 0.014*\"lady\" + '\n",
      "  '0.014*\"cardinal\" + 0.013*\"antonio\" + 0.013*\"choose\" + 0.012*\"fair\" + '\n",
      "  '0.012*\"lord\"'),\n",
      " (1,\n",
      "  '0.035*\"hector\" + 0.021*\"lord\" + 0.021*\"troilus\" + 0.018*\"troy\" + '\n",
      "  '0.018*\"achille\" + 0.017*\"sweet\" + 0.014*\"ajax\" + 0.014*\"great\" + '\n",
      "  '0.012*\"greek\" + 0.010*\"trojan\"'),\n",
      " (2,\n",
      "  '0.066*\"lord\" + 0.028*\"king\" + 0.021*\"york\" + 0.020*\"duke\" + 0.020*\"henry\" + '\n",
      "  '0.017*\"edward\" + 0.015*\"warwick\" + 0.013*\"god\" + 0.012*\"brother\" + '\n",
      "  '0.012*\"grace\"'),\n",
      " (3,\n",
      "  '0.028*\"lord\" + 0.016*\"love\" + 0.016*\"cassio\" + 0.014*\"die\" + 0.011*\"angelo\" '\n",
      "  '+ 0.010*\"wife\" + 0.010*\"madam\" + 0.010*\"husband\" + 0.009*\"death\" + '\n",
      "  '0.009*\"soul\"'),\n",
      " (4,\n",
      "  '0.020*\"good\" + 0.019*\"make\" + 0.018*\"great\" + 0.016*\"hear\" + 0.016*\"speak\" '\n",
      "  '+ 0.015*\"love\" + 0.013*\"time\" + 0.012*\"fear\" + 0.012*\"true\" + '\n",
      "  '0.011*\"stand\"'),\n",
      " (5,\n",
      "  '0.037*\"lord\" + 0.036*\"man\" + 0.022*\"god\" + 0.016*\"fool\" + 0.012*\"friend\" + '\n",
      "  '0.012*\"good\" + 0.012*\"fortune\" + 0.010*\"nature\" + 0.010*\"heart\" + '\n",
      "  '0.009*\"art\"'),\n",
      " (6,\n",
      "  '0.045*\"france\" + 0.021*\"french\" + 0.018*\"king\" + 0.018*\"talbot\" + '\n",
      "  '0.014*\"duke\" + 0.012*\"daughter\" + 0.011*\"father\" + 0.010*\"dauphin\" + '\n",
      "  '0.010*\"gloucester\" + 0.010*\"english\"'),\n",
      " (7,\n",
      "  '0.053*\"lord\" + 0.012*\"hold\" + 0.012*\"father\" + 0.011*\"play\" + 0.010*\"soul\" '\n",
      "  '+ 0.010*\"follow\" + 0.008*\"form\" + 0.008*\"light\" + 0.008*\"hamlet\" + '\n",
      "  '0.008*\"sweet\"'),\n",
      " (8,\n",
      "  '0.029*\"master\" + 0.023*\"love\" + 0.015*\"mistress\" + 0.012*\"father\" + '\n",
      "  '0.012*\"home\" + 0.011*\"wife\" + 0.011*\"gentleman\" + 0.010*\"sister\" + '\n",
      "  '0.010*\"kate\" + 0.010*\"chain\"'),\n",
      " (9,\n",
      "  '0.095*\"caesar\" + 0.036*\"antony\" + 0.036*\"brutus\" + 0.023*\"man\" + '\n",
      "  '0.018*\"cassius\" + 0.016*\"rome\" + 0.015*\"roman\" + 0.013*\"madam\" + '\n",
      "  '0.012*\"noble\" + 0.011*\"death\"'),\n",
      " (10,\n",
      "  '0.016*\"hand\" + 0.016*\"heart\" + 0.014*\"father\" + 0.013*\"make\" + 0.012*\"life\" '\n",
      "  '+ 0.012*\"live\" + 0.011*\"hast\" + 0.011*\"man\" + 0.008*\"tear\" + '\n",
      "  '0.008*\"friend\"'),\n",
      " (11,\n",
      "  '0.035*\"lord\" + 0.023*\"prince\" + 0.016*\"man\" + 0.014*\"god\" + 0.012*\"art\" + '\n",
      "  '0.012*\"good\" + 0.012*\"faith\" + 0.010*\"master\" + 0.010*\"yea\" + '\n",
      "  '0.010*\"cousin\"'),\n",
      " (12,\n",
      "  '0.014*\"night\" + 0.013*\"sleep\" + 0.012*\"speak\" + 0.010*\"spirit\" + '\n",
      "  '0.010*\"lie\" + 0.009*\"nature\" + 0.009*\"eye\" + 0.009*\"dear\" + 0.009*\"strange\" '\n",
      "  '+ 0.008*\"sea\"'),\n",
      " (13,\n",
      "  '0.037*\"love\" + 0.019*\"night\" + 0.014*\"good\" + 0.013*\"day\" + 0.012*\"death\" + '\n",
      "  '0.011*\"man\" + 0.009*\"dead\" + 0.009*\"lady\" + 0.009*\"lie\" + 0.009*\"fair\"'),\n",
      " (14,\n",
      "  '0.047*\"rome\" + 0.022*\"people\" + 0.016*\"son\" + 0.016*\"noble\" + 0.015*\"roman\" '\n",
      "  '+ 0.015*\"emperor\" + 0.015*\"mother\" + 0.014*\"martius\" + 0.011*\"lucius\" + '\n",
      "  '0.011*\"tribune\"'),\n",
      " (15,\n",
      "  '0.048*\"king\" + 0.018*\"england\" + 0.016*\"day\" + 0.014*\"majesty\" + '\n",
      "  '0.013*\"arm\" + 0.013*\"blood\" + 0.012*\"god\" + 0.012*\"land\" + 0.012*\"war\" + '\n",
      "  '0.010*\"uncle\"'),\n",
      " (16,\n",
      "  '0.058*\"love\" + 0.025*\"lady\" + 0.017*\"man\" + 0.016*\"sweet\" + 0.015*\"wit\" + '\n",
      "  '0.014*\"fair\" + 0.014*\"fool\" + 0.014*\"eye\" + 0.009*\"grace\" + 0.008*\"lover\"'),\n",
      " (17,\n",
      "  '0.033*\"king\" + 0.024*\"queen\" + 0.019*\"good\" + 0.018*\"lord\" + 0.015*\"son\" + '\n",
      "  '0.013*\"grace\" + 0.012*\"court\" + 0.010*\"woman\" + 0.010*\"business\" + '\n",
      "  '0.010*\"life\"'),\n",
      " (18,\n",
      "  '0.036*\"good\" + 0.022*\"man\" + 0.015*\"pray\" + 0.015*\"brother\" + 0.013*\"speak\" '\n",
      "  '+ 0.011*\"hear\" + 0.010*\"woman\" + 0.009*\"place\" + 0.009*\"make\" + '\n",
      "  '0.009*\"bring\"'),\n",
      " (19,\n",
      "  '0.033*\"master\" + 0.021*\"good\" + 0.019*\"page\" + 0.018*\"wife\" + 0.013*\"woman\" '\n",
      "  '+ 0.013*\"husband\" + 0.012*\"pray\" + 0.010*\"ford\" + 0.010*\"knight\" + '\n",
      "  '0.010*\"humour\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "optimalModel = modelList[0]\n",
    "modelTopics = optimalModel.show_topics(formatted=False)\n",
    "pprint(optimalModel.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the dominant topic in each chunk\n",
    "\n",
    "One of the practical applications of topic modeling is to take a chunk and determine what the dominant topic is for that chunk. To find that, we find the topic number that has the highest percentage contribution in that chunk. The `format_topics_sentences()` function below aggregates this information in a presentable table.\n",
    "\n",
    "The table created gives the file name (but only if you set `docLevel` to **True** above), topic number of the most dominant topic for the chunk, percent contribution of that topic to that chunk, the keywords of the topic, and the beginning text of the chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def formatTopicsSentences(ldamodel=ldamallet, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    \n",
    "    sentTopicsDf = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topicNum, propTopic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topicNum)\n",
    "                topicKeywords = \", \".join([word for word, prop in wp])\n",
    "                sentTopicsDf = sentTopicsDf.append(pd.Series([int(topicNum), round(propTopic,4), topicKeywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sentTopicsDf.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    if docLevel is True:\n",
    "        txtPaths = pd.Series(os.path.basename(pathName) for pathName in paths)\n",
    "\n",
    "        textPath = pd.Series(txtPaths)\n",
    "        contents = pd.Series(texts)\n",
    "        sentTopicsDf = pd.concat([textPath, sentTopicsDf, contents], axis=1)\n",
    "        return(sentTopicsDf)\n",
    "    else:\n",
    "        contents = pd.Series(texts)\n",
    "        sentTopicsDf = pd.concat([sentTopicsDf, contents], axis=1)\n",
    "        return(sentTopicsDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the function we just created. The only part of this you will need to change is the file name of the .csv file output of this table. This can be found in the beginning of the cell and is saved as the variable `domTopicPerChunkCSV`. Change the name of the file in quotes to whatever makes sense to you and fits your data.\n",
    "\n",
    "If `docLevel` was set to **True** above then the code will add a column to the data frame for the file names. If it was set to **False** then it will not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1589TwoGentlemenOfVerona.txt</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>master, love, mistress, father, home, wife, ge...</td>\n",
       "      <td>[ Cease to persuade, my loving Proteus.,  Home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1590TamingOfTheShrew.txt</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3242</td>\n",
       "      <td>master, love, mistress, father, home, wife, ge...</td>\n",
       "      <td>[ I'll feeze you, in faith.,  A pair of stocks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1591KingHenry6_1.txt</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>hand, heart, father, make, life, live, hast, m...</td>\n",
       "      <td>[ Hung be the heavens with black, yield day to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1591KingHenry6_2.txt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2514</td>\n",
       "      <td>lord, king, york, duke, henry, edward, warwick...</td>\n",
       "      <td>[ As by your high imperial Majesty,  I had in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1591KingHenry6_3.txt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2864</td>\n",
       "      <td>lord, king, york, duke, henry, edward, warwick...</td>\n",
       "      <td>[ I wonder how the King escaped our hands., , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1591TitusAndronicus.txt</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.3662</td>\n",
       "      <td>hand, heart, father, make, life, live, hast, m...</td>\n",
       "      <td>[ Noble patricians, patrons of my right,,  Def...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1592KingRichard3.txt</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>hand, heart, father, make, life, live, hast, m...</td>\n",
       "      <td>[ Now is the winter of our discontent,  Made g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1594ComedyOfErrors.txt</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.2767</td>\n",
       "      <td>master, love, mistress, father, home, wife, ge...</td>\n",
       "      <td>[ Proceed, Solinus, to procure my fall,,  And ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1594LovesLaboursLost.txt</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2805</td>\n",
       "      <td>love, lady, man, sweet, wit, fair, fool, eye, ...</td>\n",
       "      <td>[ Let fame, that all hunt after in their lives...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1595KingRichard2.txt</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.2675</td>\n",
       "      <td>king, england, day, majesty, arm, blood, god, ...</td>\n",
       "      <td>[ Old John of Gaunt, time-honored Lancaster,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1595MidsummerNightsDream.txt</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2557</td>\n",
       "      <td>love, lady, man, sweet, wit, fair, fool, eye, ...</td>\n",
       "      <td>[ Now, fair Hippolyta, our nuptial hour,  Draw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1595RomeoAndJuliet.txt</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>love, night, good, day, death, man, dead, lady...</td>\n",
       "      <td>[ Two households, both alike in dignity,  (In ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1596KingHenry4_1.txt</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.2856</td>\n",
       "      <td>lord, prince, man, god, art, good, faith, mast...</td>\n",
       "      <td>[ So shaken as we are, so wan with care,,  Fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1596KingJohn.txt</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.2823</td>\n",
       "      <td>king, england, day, majesty, arm, blood, god, ...</td>\n",
       "      <td>[ Now say, Chatillion, what would France with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1596MerchantOfVenice.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3217</td>\n",
       "      <td>pray, man, jew, ring, lady, cardinal, antonio,...</td>\n",
       "      <td>[ In sooth I know not why I am so sad.,  It we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1597KingHenry4_2.txt</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>lord, prince, man, god, art, good, faith, mast...</td>\n",
       "      <td>[ Open your ears, for which of you will stop, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1597MerryWivesOfWindsor.txt</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.4132</td>\n",
       "      <td>master, good, page, wife, woman, husband, pray...</td>\n",
       "      <td>[ Sir Hugh, persuade me not. I will make a,  S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1598MuchAdoAboutNothing.txt</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>good, man, pray, brother, speak, hear, woman, ...</td>\n",
       "      <td>[ I learn in this letter that Don,  Pedro of A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1599AsYouLikeIt.txt</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.2426</td>\n",
       "      <td>good, man, pray, brother, speak, hear, woman, ...</td>\n",
       "      <td>[ As I remember, Adam, it was upon this,  fash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1599Hamlet.txt</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2801</td>\n",
       "      <td>lord, hold, father, play, soul, follow, form, ...</td>\n",
       "      <td>[ Who's there?, ,  Nay, answer me. Stand and u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1599JuliusCaesar.txt</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3116</td>\n",
       "      <td>caesar, antony, brutus, man, cassius, rome, ro...</td>\n",
       "      <td>[ Hence! Home, you idle creatures, get you hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1599KingHenry5.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1904</td>\n",
       "      <td>good, make, great, hear, speak, love, time, fe...</td>\n",
       "      <td>[ O, for a muse of fire that would ascend,  Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1600TroilusAndCressida.txt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3220</td>\n",
       "      <td>hector, lord, troilus, troy, achille, sweet, a...</td>\n",
       "      <td>[ In Troy there lies the scene. From isles of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1601TwelfthNight.txt</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>love, lady, man, sweet, wit, fair, fool, eye, ...</td>\n",
       "      <td>[ If music be the food of love, play on.,  Giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1603MeasureForMeasure.txt</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>good, man, pray, brother, speak, hear, woman, ...</td>\n",
       "      <td>[ Escalus.,  My lord., ,  Of government the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1603Othello.txt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>lord, love, cassio, die, angelo, wife, madam, ...</td>\n",
       "      <td>[ Tush, never tell me! I take it much unkindly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1604AllsWellThatEndsWell.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2215</td>\n",
       "      <td>good, make, great, hear, speak, love, time, fe...</td>\n",
       "      <td>[ In delivering my son from me, I bury a secon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1605KingLear.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>good, make, great, hear, speak, love, time, fe...</td>\n",
       "      <td>[ I thought the King had more affected the Duk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1605TimonOfAthens.txt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>lord, man, god, fool, friend, good, fortune, n...</td>\n",
       "      <td>[ Good day, sir.,  I am glad you're well., ,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1606AnthonyAndCleopatra.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>good, make, great, hear, speak, love, time, fe...</td>\n",
       "      <td>[ Nay, but this dotage of our general's,  Over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1606Macbeth.txt</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.2729</td>\n",
       "      <td>night, sleep, speak, spirit, lie, nature, eye,...</td>\n",
       "      <td>[ When shall we three meet again?,  In thunder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1608Coriolanus.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>good, make, great, hear, speak, love, time, fe...</td>\n",
       "      <td>[ Before we proceed any further, hear me,  spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1609WintersTale.txt</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>king, queen, good, lord, son, grace, court, wo...</td>\n",
       "      <td>[ If you shall chance, Camillo, to visit Bohem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1610Cymbeline.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>good, make, great, hear, speak, love, time, fe...</td>\n",
       "      <td>[ You do not meet a man but frowns. Our bloods...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1610Tempest.txt</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.3117</td>\n",
       "      <td>night, sleep, speak, spirit, lie, nature, eye,...</td>\n",
       "      <td>[ Boatswain!,  Here, master. What cheer?,  Goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1612KingHenry8.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>good, make, great, hear, speak, love, time, fe...</td>\n",
       "      <td>[ I come no more to make you laugh. Things now...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Filename  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0   1589TwoGentlemenOfVerona.txt             8.0              0.2060   \n",
       "1       1590TamingOfTheShrew.txt             8.0              0.3242   \n",
       "2           1591KingHenry6_1.txt            10.0              0.1924   \n",
       "3           1591KingHenry6_2.txt             2.0              0.2514   \n",
       "4           1591KingHenry6_3.txt             2.0              0.2864   \n",
       "5        1591TitusAndronicus.txt            10.0              0.3662   \n",
       "6           1592KingRichard3.txt            10.0              0.2212   \n",
       "7         1594ComedyOfErrors.txt             8.0              0.2767   \n",
       "8       1594LovesLaboursLost.txt            16.0              0.2805   \n",
       "9           1595KingRichard2.txt            15.0              0.2675   \n",
       "10  1595MidsummerNightsDream.txt            16.0              0.2557   \n",
       "11        1595RomeoAndJuliet.txt            13.0              0.4500   \n",
       "12          1596KingHenry4_1.txt            11.0              0.2856   \n",
       "13              1596KingJohn.txt            15.0              0.2823   \n",
       "14      1596MerchantOfVenice.txt             0.0              0.3217   \n",
       "15          1597KingHenry4_2.txt            11.0              0.2136   \n",
       "16   1597MerryWivesOfWindsor.txt            19.0              0.4132   \n",
       "17   1598MuchAdoAboutNothing.txt            18.0              0.2488   \n",
       "18           1599AsYouLikeIt.txt            18.0              0.2426   \n",
       "19                1599Hamlet.txt             7.0              0.2801   \n",
       "20          1599JuliusCaesar.txt             9.0              0.3116   \n",
       "21            1599KingHenry5.txt             4.0              0.1904   \n",
       "22    1600TroilusAndCressida.txt             1.0              0.3220   \n",
       "23          1601TwelfthNight.txt            16.0              0.2040   \n",
       "24     1603MeasureForMeasure.txt            18.0              0.3467   \n",
       "25               1603Othello.txt             3.0              0.2527   \n",
       "26  1604AllsWellThatEndsWell.txt             4.0              0.2215   \n",
       "27              1605KingLear.txt             4.0              0.1982   \n",
       "28         1605TimonOfAthens.txt             5.0              0.4561   \n",
       "29   1606AnthonyAndCleopatra.txt             4.0              0.2324   \n",
       "30               1606Macbeth.txt            12.0              0.2729   \n",
       "31            1608Coriolanus.txt             4.0              0.3460   \n",
       "32           1609WintersTale.txt            17.0              0.2937   \n",
       "33             1610Cymbeline.txt             4.0              0.2416   \n",
       "34               1610Tempest.txt            12.0              0.3117   \n",
       "35            1612KingHenry8.txt             4.0              0.2416   \n",
       "\n",
       "                                             Keywords  \\\n",
       "0   master, love, mistress, father, home, wife, ge...   \n",
       "1   master, love, mistress, father, home, wife, ge...   \n",
       "2   hand, heart, father, make, life, live, hast, m...   \n",
       "3   lord, king, york, duke, henry, edward, warwick...   \n",
       "4   lord, king, york, duke, henry, edward, warwick...   \n",
       "5   hand, heart, father, make, life, live, hast, m...   \n",
       "6   hand, heart, father, make, life, live, hast, m...   \n",
       "7   master, love, mistress, father, home, wife, ge...   \n",
       "8   love, lady, man, sweet, wit, fair, fool, eye, ...   \n",
       "9   king, england, day, majesty, arm, blood, god, ...   \n",
       "10  love, lady, man, sweet, wit, fair, fool, eye, ...   \n",
       "11  love, night, good, day, death, man, dead, lady...   \n",
       "12  lord, prince, man, god, art, good, faith, mast...   \n",
       "13  king, england, day, majesty, arm, blood, god, ...   \n",
       "14  pray, man, jew, ring, lady, cardinal, antonio,...   \n",
       "15  lord, prince, man, god, art, good, faith, mast...   \n",
       "16  master, good, page, wife, woman, husband, pray...   \n",
       "17  good, man, pray, brother, speak, hear, woman, ...   \n",
       "18  good, man, pray, brother, speak, hear, woman, ...   \n",
       "19  lord, hold, father, play, soul, follow, form, ...   \n",
       "20  caesar, antony, brutus, man, cassius, rome, ro...   \n",
       "21  good, make, great, hear, speak, love, time, fe...   \n",
       "22  hector, lord, troilus, troy, achille, sweet, a...   \n",
       "23  love, lady, man, sweet, wit, fair, fool, eye, ...   \n",
       "24  good, man, pray, brother, speak, hear, woman, ...   \n",
       "25  lord, love, cassio, die, angelo, wife, madam, ...   \n",
       "26  good, make, great, hear, speak, love, time, fe...   \n",
       "27  good, make, great, hear, speak, love, time, fe...   \n",
       "28  lord, man, god, fool, friend, good, fortune, n...   \n",
       "29  good, make, great, hear, speak, love, time, fe...   \n",
       "30  night, sleep, speak, spirit, lie, nature, eye,...   \n",
       "31  good, make, great, hear, speak, love, time, fe...   \n",
       "32  king, queen, good, lord, son, grace, court, wo...   \n",
       "33  good, make, great, hear, speak, love, time, fe...   \n",
       "34  night, sleep, speak, spirit, lie, nature, eye,...   \n",
       "35  good, make, great, hear, speak, love, time, fe...   \n",
       "\n",
       "                                                 Text  \n",
       "0   [ Cease to persuade, my loving Proteus.,  Home...  \n",
       "1   [ I'll feeze you, in faith.,  A pair of stocks...  \n",
       "2   [ Hung be the heavens with black, yield day to...  \n",
       "3   [ As by your high imperial Majesty,  I had in ...  \n",
       "4   [ I wonder how the King escaped our hands., , ...  \n",
       "5   [ Noble patricians, patrons of my right,,  Def...  \n",
       "6   [ Now is the winter of our discontent,  Made g...  \n",
       "7   [ Proceed, Solinus, to procure my fall,,  And ...  \n",
       "8   [ Let fame, that all hunt after in their lives...  \n",
       "9   [ Old John of Gaunt, time-honored Lancaster,, ...  \n",
       "10  [ Now, fair Hippolyta, our nuptial hour,  Draw...  \n",
       "11  [ Two households, both alike in dignity,  (In ...  \n",
       "12  [ So shaken as we are, so wan with care,,  Fin...  \n",
       "13  [ Now say, Chatillion, what would France with ...  \n",
       "14  [ In sooth I know not why I am so sad.,  It we...  \n",
       "15  [ Open your ears, for which of you will stop, ...  \n",
       "16  [ Sir Hugh, persuade me not. I will make a,  S...  \n",
       "17  [ I learn in this letter that Don,  Pedro of A...  \n",
       "18  [ As I remember, Adam, it was upon this,  fash...  \n",
       "19  [ Who's there?, ,  Nay, answer me. Stand and u...  \n",
       "20  [ Hence! Home, you idle creatures, get you hom...  \n",
       "21  [ O, for a muse of fire that would ascend,  Th...  \n",
       "22  [ In Troy there lies the scene. From isles of ...  \n",
       "23  [ If music be the food of love, play on.,  Giv...  \n",
       "24  [ Escalus.,  My lord., ,  Of government the pr...  \n",
       "25  [ Tush, never tell me! I take it much unkindly...  \n",
       "26  [ In delivering my son from me, I bury a secon...  \n",
       "27  [ I thought the King had more affected the Duk...  \n",
       "28  [ Good day, sir.,  I am glad you're well., ,  ...  \n",
       "29  [ Nay, but this dotage of our general's,  Over...  \n",
       "30  [ When shall we three meet again?,  In thunder...  \n",
       "31  [ Before we proceed any further, hear me,  spe...  \n",
       "32  [ If you shall chance, Camillo, to visit Bohem...  \n",
       "33  [ You do not meet a man but frowns. Our bloods...  \n",
       "34  [ Boatswain!,  Here, master. What cheer?,  Goo...  \n",
       "35  [ I come no more to make you laugh. Things now...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domTopicPerChunkCSV = 'domTopicPerChunk.csv'\n",
    "\n",
    "dfTopicSentsKeywords = formatTopicsSentences(ldamodel=optimalModel, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "dfDominantTopic = dfTopicSentsKeywords.reset_index(drop=True)\n",
    "if docLevel is True:\n",
    "    dfDominantTopic.columns = ['Filename', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "else:\n",
    "    dfDominantTopic.columns = ['Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "    \n",
    "dfDominantTopic.to_csv(os.path.join(dataResults, domTopicPerChunkCSV))\n",
    "# Show\n",
    "dfDominantTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most representative chunk for each topic\n",
    "\n",
    "Sometimes just the topic keywords may not be enough to make sense of what a topic is about. So, to help with understanding the topic, you can find the chunk a given topic has contributed to the most and infer the topic by reading that chunk. The table created gives the chunk that is most representative of the topic, the topic number, percent contribution of that topic to that dchunk, the keywords of the topic, and the beginning text of the chunk.\n",
    "\n",
    "The only part of this you will need to change is the file path where the .csv file output of this table will be saved. This can be found in the beginning of the cell and is saved as the variable `chunkRepCSV`. Change the name of the file in quotes to whatever makes the most sense for you and your data.\n",
    "\n",
    "Again, if `docLevel` was set to **True** above then the code will add a column to the data frame for the file names. If it was set to **False** then it will not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1596MerchantOfVenice.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3217</td>\n",
       "      <td>pray, man, jew, ring, lady, cardinal, antonio,...</td>\n",
       "      <td>[ In sooth I know not why I am so sad.,  It we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600TroilusAndCressida.txt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3220</td>\n",
       "      <td>hector, lord, troilus, troy, achille, sweet, a...</td>\n",
       "      <td>[ In Troy there lies the scene. From isles of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1591KingHenry6_3.txt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2864</td>\n",
       "      <td>lord, king, york, duke, henry, edward, warwick...</td>\n",
       "      <td>[ I wonder how the King escaped our hands., , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1603Othello.txt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>lord, love, cassio, die, angelo, wife, madam, ...</td>\n",
       "      <td>[ Tush, never tell me! I take it much unkindly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1608Coriolanus.txt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>good, make, great, hear, speak, love, time, fe...</td>\n",
       "      <td>[ Before we proceed any further, hear me,  spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1605TimonOfAthens.txt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>lord, man, god, fool, friend, good, fortune, n...</td>\n",
       "      <td>[ Good day, sir.,  I am glad you're well., ,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1599Hamlet.txt</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2801</td>\n",
       "      <td>lord, hold, father, play, soul, follow, form, ...</td>\n",
       "      <td>[ Who's there?, ,  Nay, answer me. Stand and u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1590TamingOfTheShrew.txt</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3242</td>\n",
       "      <td>master, love, mistress, father, home, wife, ge...</td>\n",
       "      <td>[ I'll feeze you, in faith.,  A pair of stocks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1599JuliusCaesar.txt</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3116</td>\n",
       "      <td>caesar, antony, brutus, man, cassius, rome, ro...</td>\n",
       "      <td>[ Hence! Home, you idle creatures, get you hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1591TitusAndronicus.txt</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.3662</td>\n",
       "      <td>hand, heart, father, make, life, live, hast, m...</td>\n",
       "      <td>[ Noble patricians, patrons of my right,,  Def...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1596KingHenry4_1.txt</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.2856</td>\n",
       "      <td>lord, prince, man, god, art, good, faith, mast...</td>\n",
       "      <td>[ So shaken as we are, so wan with care,,  Fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1610Tempest.txt</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.3117</td>\n",
       "      <td>night, sleep, speak, spirit, lie, nature, eye,...</td>\n",
       "      <td>[ Boatswain!,  Here, master. What cheer?,  Goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1595RomeoAndJuliet.txt</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>love, night, good, day, death, man, dead, lady...</td>\n",
       "      <td>[ Two households, both alike in dignity,  (In ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1596KingJohn.txt</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.2823</td>\n",
       "      <td>king, england, day, majesty, arm, blood, god, ...</td>\n",
       "      <td>[ Now say, Chatillion, what would France with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1594LovesLaboursLost.txt</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2805</td>\n",
       "      <td>love, lady, man, sweet, wit, fair, fool, eye, ...</td>\n",
       "      <td>[ Let fame, that all hunt after in their lives...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1609WintersTale.txt</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>king, queen, good, lord, son, grace, court, wo...</td>\n",
       "      <td>[ If you shall chance, Camillo, to visit Bohem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1603MeasureForMeasure.txt</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>good, man, pray, brother, speak, hear, woman, ...</td>\n",
       "      <td>[ Escalus.,  My lord., ,  Of government the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1597MerryWivesOfWindsor.txt</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.4132</td>\n",
       "      <td>master, good, page, wife, woman, husband, pray...</td>\n",
       "      <td>[ Sir Hugh, persuade me not. I will make a,  S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Filename  Topic_Num  Topic_Perc_Contrib  \\\n",
       "0      1596MerchantOfVenice.txt        0.0              0.3217   \n",
       "1    1600TroilusAndCressida.txt        1.0              0.3220   \n",
       "2          1591KingHenry6_3.txt        2.0              0.2864   \n",
       "3               1603Othello.txt        3.0              0.2527   \n",
       "4            1608Coriolanus.txt        4.0              0.3460   \n",
       "5         1605TimonOfAthens.txt        5.0              0.4561   \n",
       "6                1599Hamlet.txt        7.0              0.2801   \n",
       "7      1590TamingOfTheShrew.txt        8.0              0.3242   \n",
       "8          1599JuliusCaesar.txt        9.0              0.3116   \n",
       "9       1591TitusAndronicus.txt       10.0              0.3662   \n",
       "10         1596KingHenry4_1.txt       11.0              0.2856   \n",
       "11              1610Tempest.txt       12.0              0.3117   \n",
       "12       1595RomeoAndJuliet.txt       13.0              0.4500   \n",
       "13             1596KingJohn.txt       15.0              0.2823   \n",
       "14     1594LovesLaboursLost.txt       16.0              0.2805   \n",
       "15          1609WintersTale.txt       17.0              0.2937   \n",
       "16    1603MeasureForMeasure.txt       18.0              0.3467   \n",
       "17  1597MerryWivesOfWindsor.txt       19.0              0.4132   \n",
       "\n",
       "                                             Keywords  \\\n",
       "0   pray, man, jew, ring, lady, cardinal, antonio,...   \n",
       "1   hector, lord, troilus, troy, achille, sweet, a...   \n",
       "2   lord, king, york, duke, henry, edward, warwick...   \n",
       "3   lord, love, cassio, die, angelo, wife, madam, ...   \n",
       "4   good, make, great, hear, speak, love, time, fe...   \n",
       "5   lord, man, god, fool, friend, good, fortune, n...   \n",
       "6   lord, hold, father, play, soul, follow, form, ...   \n",
       "7   master, love, mistress, father, home, wife, ge...   \n",
       "8   caesar, antony, brutus, man, cassius, rome, ro...   \n",
       "9   hand, heart, father, make, life, live, hast, m...   \n",
       "10  lord, prince, man, god, art, good, faith, mast...   \n",
       "11  night, sleep, speak, spirit, lie, nature, eye,...   \n",
       "12  love, night, good, day, death, man, dead, lady...   \n",
       "13  king, england, day, majesty, arm, blood, god, ...   \n",
       "14  love, lady, man, sweet, wit, fair, fool, eye, ...   \n",
       "15  king, queen, good, lord, son, grace, court, wo...   \n",
       "16  good, man, pray, brother, speak, hear, woman, ...   \n",
       "17  master, good, page, wife, woman, husband, pray...   \n",
       "\n",
       "                                                 Text  \n",
       "0   [ In sooth I know not why I am so sad.,  It we...  \n",
       "1   [ In Troy there lies the scene. From isles of ...  \n",
       "2   [ I wonder how the King escaped our hands., , ...  \n",
       "3   [ Tush, never tell me! I take it much unkindly...  \n",
       "4   [ Before we proceed any further, hear me,  spe...  \n",
       "5   [ Good day, sir.,  I am glad you're well., ,  ...  \n",
       "6   [ Who's there?, ,  Nay, answer me. Stand and u...  \n",
       "7   [ I'll feeze you, in faith.,  A pair of stocks...  \n",
       "8   [ Hence! Home, you idle creatures, get you hom...  \n",
       "9   [ Noble patricians, patrons of my right,,  Def...  \n",
       "10  [ So shaken as we are, so wan with care,,  Fin...  \n",
       "11  [ Boatswain!,  Here, master. What cheer?,  Goo...  \n",
       "12  [ Two households, both alike in dignity,  (In ...  \n",
       "13  [ Now say, Chatillion, what would France with ...  \n",
       "14  [ Let fame, that all hunt after in their lives...  \n",
       "15  [ If you shall chance, Camillo, to visit Bohem...  \n",
       "16  [ Escalus.,  My lord., ,  Of government the pr...  \n",
       "17  [ Sir Hugh, persuade me not. I will make a,  S...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkRepCSV = 'chunkRepPerTopic.csv'\n",
    "\n",
    "# Group top 5 sentences under each topic\n",
    "sentTopicsSorteddfMallet = pd.DataFrame()\n",
    "\n",
    "sentTopicsOutdfGrpd = dfTopicSentsKeywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sentTopicsOutdfGrpd:\n",
    "    sentTopicsSorteddfMallet = pd.concat([sentTopicsSorteddfMallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sentTopicsSorteddfMallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "if docLevel is True:\n",
    "    sentTopicsSorteddfMallet.columns = ['Filename','Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "else:\n",
    "    sentTopicsSorteddfMallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "    \n",
    "sentTopicsSorteddfMallet.to_csv(os.path.join(dataResults, chunkRepCSV))\n",
    "\n",
    "# Show\n",
    "sentTopicsSorteddfMallet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic distribution across chunks\n",
    "\n",
    "Next we want to understand the volume and distribution of topics in order to judge how widely it occurs in our data. The below table displays that information. \n",
    "\n",
    "This table tells the topic number, the topic keywords, the number of chunks that had this topic as its dominant topic, and what percent of the total number of chunks had this topic as the dominant topic.\n",
    "\n",
    "The only part of this you will need to change is the file path where the .csv file output of this table will be saved. This can be found in the beginning of the cell and is saved as the variable `topicDistCSV`. Change the name of the file in quotes to whatever makes sense for you and your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>pray, man, jew, ring, lady, cardinal, antonio,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>hector, lord, troilus, troy, achille, sweet, a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>lord, king, york, duke, henry, edward, warwick...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lord, love, cassio, die, angelo, wife, madam, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>good, make, great, hear, speak, love, time, fe...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>lord, man, god, fool, friend, good, fortune, n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>lord, hold, father, play, soul, follow, form, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>master, love, mistress, father, home, wife, ge...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>caesar, antony, brutus, man, cassius, rome, ro...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>hand, heart, father, make, life, live, hast, m...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>lord, prince, man, god, art, good, faith, mast...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>night, sleep, speak, spirit, lie, nature, eye,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>love, night, good, day, death, man, dead, lady...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.0</td>\n",
       "      <td>king, england, day, majesty, arm, blood, god, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16.0</td>\n",
       "      <td>love, lady, man, sweet, wit, fair, fool, eye, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17.0</td>\n",
       "      <td>king, queen, good, lord, son, grace, court, wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.0</td>\n",
       "      <td>good, man, pray, brother, speak, hear, woman, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19.0</td>\n",
       "      <td>master, good, page, wife, woman, husband, pray...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dominant_Topic                                     Topic_Keywords  \\\n",
       "0              0.0  pray, man, jew, ring, lady, cardinal, antonio,...   \n",
       "1              1.0  hector, lord, troilus, troy, achille, sweet, a...   \n",
       "2              2.0  lord, king, york, duke, henry, edward, warwick...   \n",
       "3              3.0  lord, love, cassio, die, angelo, wife, madam, ...   \n",
       "4              4.0  good, make, great, hear, speak, love, time, fe...   \n",
       "5              5.0  lord, man, god, fool, friend, good, fortune, n...   \n",
       "6              7.0  lord, hold, father, play, soul, follow, form, ...   \n",
       "7              8.0  master, love, mistress, father, home, wife, ge...   \n",
       "8              9.0  caesar, antony, brutus, man, cassius, rome, ro...   \n",
       "9             10.0  hand, heart, father, make, life, live, hast, m...   \n",
       "10            11.0  lord, prince, man, god, art, good, faith, mast...   \n",
       "11            12.0  night, sleep, speak, spirit, lie, nature, eye,...   \n",
       "12            13.0  love, night, good, day, death, man, dead, lady...   \n",
       "13            15.0  king, england, day, majesty, arm, blood, god, ...   \n",
       "14            16.0  love, lady, man, sweet, wit, fair, fool, eye, ...   \n",
       "15            17.0  king, queen, good, lord, son, grace, court, wo...   \n",
       "16            18.0  good, man, pray, brother, speak, hear, woman, ...   \n",
       "17            19.0  master, good, page, wife, woman, husband, pray...   \n",
       "\n",
       "    Num_Documents  Perc_Documents  \n",
       "0               1          0.0278  \n",
       "1               1          0.0278  \n",
       "2               2          0.0556  \n",
       "3               1          0.0278  \n",
       "4               7          0.1944  \n",
       "5               1          0.0278  \n",
       "6               1          0.0278  \n",
       "7               3          0.0833  \n",
       "8               1          0.0278  \n",
       "9               3          0.0833  \n",
       "10              2          0.0556  \n",
       "11              2          0.0556  \n",
       "12              1          0.0278  \n",
       "13              2          0.0556  \n",
       "14              3          0.0833  \n",
       "15              1          0.0278  \n",
       "16              3          0.0833  \n",
       "17              1          0.0278  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicDistCSV = 'domTopicCount.csv'\n",
    "\n",
    "# Number of Documents for Each Topic\n",
    "topicCounts = dfTopicSentsKeywords.groupby(['Dominant_Topic','Topic_Keywords']).size().to_frame('Num_Documents').reset_index()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topicContribution = round(topicCounts['Num_Documents']/topicCounts['Num_Documents'].sum(), 4)\n",
    "\n",
    "# Concatenate Column wise\n",
    "dfDominantTopics = pd.concat([topicCounts, topicContribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "dfDominantTopics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "dfDominantTopics.to_csv(os.path.join(dataResults, topicDistCSV))\n",
    "# Show\n",
    "dfDominantTopics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of each topic across each chunk\n",
    "\n",
    "This code creates a table that shows each document as well as the percentage of each topic within that document. This will only be implemented if `docLevel` was set to **True** above as it is really only useful at the document level.\n",
    "\n",
    "There are two lines where changes will need to be made. They both follow directly after the commented line `#Variables`. The first line determines the name of the output .csv file that this table will be saved as. This is saved as the variable `docTopicsCSV`. Change the name of the file in quotes to whatever makes sense for you and your data. \n",
    "\n",
    "In the `sortOrder` variable you will need to change the `'topic_x'` to match whatever topic you wish to have the table orderd by (replacing the 'x' with the number of the topic, so `'topic_12'` or `'topic_0'`). This will allow you to see which documents in descending order have the highest percentage of your topic of interest. The syntax for the topic will always be `'topic_x'` as it is going by the column header. If you want it ordered by file name then put the `'Filenames'` column header first. The primary order will be by which ever column header comes first, with the second column header being a secondary ordering option. This means if we order it by `'topic_5'` first and then by `'Filnames'` second, the data frame rows will be in descending order based on the numbers in the column labeled `'topic_5'`, but in any cases where the numbers in `'topic_5'` are identical it will order those identical numbers by the corresponding contents of the `'Filenames'` column.\n",
    "\n",
    "Again, this is only if you set `docLevel` to **True** above. The .csv file will contain the data based on the column you chose in the `sortOrder` variable. So the data will be sorted according to what topic (or the Filenames) you specified from the highest score to the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filenames</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1596MerchantOfVenice.txt</td>\n",
       "      <td>0.321740</td>\n",
       "      <td>0.005816</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.006217</td>\n",
       "      <td>0.163253</td>\n",
       "      <td>0.064608</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>0.011887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140159</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.083005</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.008874</td>\n",
       "      <td>0.016490</td>\n",
       "      <td>0.014173</td>\n",
       "      <td>0.123507</td>\n",
       "      <td>0.001151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1612KingHenry8.txt</td>\n",
       "      <td>0.131133</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.064507</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.242026</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.007650</td>\n",
       "      <td>0.014776</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086975</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.018741</td>\n",
       "      <td>0.021303</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>0.054534</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.158546</td>\n",
       "      <td>0.115178</td>\n",
       "      <td>0.000688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1596KingJohn.txt</td>\n",
       "      <td>0.020791</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.008053</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.180378</td>\n",
       "      <td>0.019071</td>\n",
       "      <td>0.019071</td>\n",
       "      <td>0.031325</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195432</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.032306</td>\n",
       "      <td>0.087861</td>\n",
       "      <td>0.007485</td>\n",
       "      <td>0.281538</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.022966</td>\n",
       "      <td>0.076958</td>\n",
       "      <td>0.001343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1601TwelfthNight.txt</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.022399</td>\n",
       "      <td>0.146285</td>\n",
       "      <td>0.117174</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.061846</td>\n",
       "      <td>0.023435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107400</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>0.045036</td>\n",
       "      <td>0.039245</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.203841</td>\n",
       "      <td>0.011590</td>\n",
       "      <td>0.169308</td>\n",
       "      <td>0.008203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1590TamingOfTheShrew.txt</td>\n",
       "      <td>0.015613</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.003032</td>\n",
       "      <td>0.126563</td>\n",
       "      <td>0.053453</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.019640</td>\n",
       "      <td>0.323024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128552</td>\n",
       "      <td>0.014821</td>\n",
       "      <td>0.017893</td>\n",
       "      <td>0.077661</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.016583</td>\n",
       "      <td>0.019074</td>\n",
       "      <td>0.156916</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1594ComedyOfErrors.txt</td>\n",
       "      <td>0.015162</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.005184</td>\n",
       "      <td>0.016352</td>\n",
       "      <td>0.107323</td>\n",
       "      <td>0.082973</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>0.016604</td>\n",
       "      <td>0.274253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197311</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.019991</td>\n",
       "      <td>0.087184</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.127875</td>\n",
       "      <td>0.016444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1604AllsWellThatEndsWell.txt</td>\n",
       "      <td>0.015009</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.132839</td>\n",
       "      <td>0.218412</td>\n",
       "      <td>0.133215</td>\n",
       "      <td>0.029243</td>\n",
       "      <td>0.020706</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088812</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.036549</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.014032</td>\n",
       "      <td>0.030190</td>\n",
       "      <td>0.085716</td>\n",
       "      <td>0.161308</td>\n",
       "      <td>0.004487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1589TwoGentlemenOfVerona.txt</td>\n",
       "      <td>0.012434</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.174720</td>\n",
       "      <td>0.064436</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>0.205968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199037</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.124392</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.083181</td>\n",
       "      <td>0.026454</td>\n",
       "      <td>0.064948</td>\n",
       "      <td>0.008142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1599Hamlet.txt</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.019402</td>\n",
       "      <td>0.170156</td>\n",
       "      <td>0.062152</td>\n",
       "      <td>0.004392</td>\n",
       "      <td>0.279310</td>\n",
       "      <td>0.009188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108138</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.069528</td>\n",
       "      <td>0.053066</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.053561</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.043046</td>\n",
       "      <td>0.100612</td>\n",
       "      <td>0.003564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1598MuchAdoAboutNothing.txt</td>\n",
       "      <td>0.009844</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.008526</td>\n",
       "      <td>0.122883</td>\n",
       "      <td>0.090772</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>0.011327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084396</td>\n",
       "      <td>0.045497</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>0.110246</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.005890</td>\n",
       "      <td>0.215904</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.246911</td>\n",
       "      <td>0.003995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1608Coriolanus.txt</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.006245</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>0.093254</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100184</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.042355</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>0.235558</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.025035</td>\n",
       "      <td>0.095057</td>\n",
       "      <td>0.002403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1599AsYouLikeIt.txt</td>\n",
       "      <td>0.009041</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.133859</td>\n",
       "      <td>0.095138</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.016068</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126706</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>0.016795</td>\n",
       "      <td>0.061075</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.008141</td>\n",
       "      <td>0.231974</td>\n",
       "      <td>0.022243</td>\n",
       "      <td>0.242665</td>\n",
       "      <td>0.011125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1595KingRichard2.txt</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.071415</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.199582</td>\n",
       "      <td>0.043611</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215473</td>\n",
       "      <td>0.014554</td>\n",
       "      <td>0.006967</td>\n",
       "      <td>0.092629</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>0.269775</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.034476</td>\n",
       "      <td>0.018572</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1596KingHenry4_1.txt</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.010564</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.202809</td>\n",
       "      <td>0.048230</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111296</td>\n",
       "      <td>0.286901</td>\n",
       "      <td>0.016608</td>\n",
       "      <td>0.068083</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.090614</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.089505</td>\n",
       "      <td>0.008371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1591KingHenry6_2.txt</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.250942</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.151654</td>\n",
       "      <td>0.032337</td>\n",
       "      <td>0.035720</td>\n",
       "      <td>0.006467</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215626</td>\n",
       "      <td>0.016043</td>\n",
       "      <td>0.018805</td>\n",
       "      <td>0.049275</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>0.091627</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.045904</td>\n",
       "      <td>0.050329</td>\n",
       "      <td>0.006140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1605TimonOfAthens.txt</td>\n",
       "      <td>0.007311</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.005227</td>\n",
       "      <td>0.186092</td>\n",
       "      <td>0.457634</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.028439</td>\n",
       "      <td>0.011868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106714</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.035775</td>\n",
       "      <td>0.037198</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.022339</td>\n",
       "      <td>0.077454</td>\n",
       "      <td>0.002550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1610Cymbeline.txt</td>\n",
       "      <td>0.007291</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.115752</td>\n",
       "      <td>0.241717</td>\n",
       "      <td>0.117499</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>0.020885</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113197</td>\n",
       "      <td>0.005710</td>\n",
       "      <td>0.045413</td>\n",
       "      <td>0.046138</td>\n",
       "      <td>0.023868</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.135847</td>\n",
       "      <td>0.077819</td>\n",
       "      <td>0.008610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1610Tempest.txt</td>\n",
       "      <td>0.006690</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.162946</td>\n",
       "      <td>0.062474</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>0.034915</td>\n",
       "      <td>0.018547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118791</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>0.315110</td>\n",
       "      <td>0.008041</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.008802</td>\n",
       "      <td>0.122521</td>\n",
       "      <td>0.099644</td>\n",
       "      <td>0.002883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1594LovesLaboursLost.txt</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.020032</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.171406</td>\n",
       "      <td>0.038039</td>\n",
       "      <td>0.012272</td>\n",
       "      <td>0.119404</td>\n",
       "      <td>0.012528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100004</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.071182</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.023770</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.026811</td>\n",
       "      <td>0.092159</td>\n",
       "      <td>0.013566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1603MeasureForMeasure.txt</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.177056</td>\n",
       "      <td>0.179555</td>\n",
       "      <td>0.036395</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.023491</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114420</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.020017</td>\n",
       "      <td>0.037103</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.031114</td>\n",
       "      <td>0.346733</td>\n",
       "      <td>0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1595MidsummerNightsDream.txt</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.098045</td>\n",
       "      <td>0.014890</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.038013</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115169</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.182623</td>\n",
       "      <td>0.145878</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.007158</td>\n",
       "      <td>0.255475</td>\n",
       "      <td>0.016093</td>\n",
       "      <td>0.091462</td>\n",
       "      <td>0.006702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1592KingRichard3.txt</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.214939</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.122755</td>\n",
       "      <td>0.037788</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221953</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.017163</td>\n",
       "      <td>0.140055</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.114532</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.050910</td>\n",
       "      <td>0.051469</td>\n",
       "      <td>0.000981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1595RomeoAndJuliet.txt</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.101918</td>\n",
       "      <td>0.050185</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.027728</td>\n",
       "      <td>0.011746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200783</td>\n",
       "      <td>0.008577</td>\n",
       "      <td>0.030170</td>\n",
       "      <td>0.448126</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.006172</td>\n",
       "      <td>0.016087</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>0.068905</td>\n",
       "      <td>0.003743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1599KingHenry5.txt</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.008778</td>\n",
       "      <td>0.018179</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.191347</td>\n",
       "      <td>0.056136</td>\n",
       "      <td>0.161083</td>\n",
       "      <td>0.029452</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080568</td>\n",
       "      <td>0.050233</td>\n",
       "      <td>0.018475</td>\n",
       "      <td>0.028184</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.190624</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>0.008588</td>\n",
       "      <td>0.115302</td>\n",
       "      <td>0.020478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1603Othello.txt</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.252074</td>\n",
       "      <td>0.210048</td>\n",
       "      <td>0.085260</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.064298</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118850</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.060208</td>\n",
       "      <td>0.055492</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>0.118250</td>\n",
       "      <td>0.003394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1605KingLear.txt</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.013707</td>\n",
       "      <td>0.196851</td>\n",
       "      <td>0.155304</td>\n",
       "      <td>0.114551</td>\n",
       "      <td>0.030878</td>\n",
       "      <td>0.017105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162606</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.070160</td>\n",
       "      <td>0.025299</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>0.074763</td>\n",
       "      <td>0.109635</td>\n",
       "      <td>0.003995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1597MerryWivesOfWindsor.txt</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.130211</td>\n",
       "      <td>0.041887</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.042902</td>\n",
       "      <td>0.012107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060551</td>\n",
       "      <td>0.021352</td>\n",
       "      <td>0.016420</td>\n",
       "      <td>0.048388</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>0.013534</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>0.171107</td>\n",
       "      <td>0.414324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1606Macbeth.txt</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.214211</td>\n",
       "      <td>0.071779</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.016522</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150026</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.273404</td>\n",
       "      <td>0.046246</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.064175</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.064665</td>\n",
       "      <td>0.058386</td>\n",
       "      <td>0.003529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1597KingHenry4_2.txt</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.020575</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.199548</td>\n",
       "      <td>0.090954</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.034724</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111976</td>\n",
       "      <td>0.211586</td>\n",
       "      <td>0.016136</td>\n",
       "      <td>0.043851</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.082101</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.113396</td>\n",
       "      <td>0.034068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1609WintersTale.txt</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.201476</td>\n",
       "      <td>0.061207</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.040867</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126844</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.051579</td>\n",
       "      <td>0.031472</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.014744</td>\n",
       "      <td>0.294156</td>\n",
       "      <td>0.131184</td>\n",
       "      <td>0.009539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1606AnthonyAndCleopatra.txt</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.014099</td>\n",
       "      <td>0.231038</td>\n",
       "      <td>0.097637</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.020722</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121176</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.065575</td>\n",
       "      <td>0.020071</td>\n",
       "      <td>0.008582</td>\n",
       "      <td>0.011509</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>0.080396</td>\n",
       "      <td>0.088763</td>\n",
       "      <td>0.002622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1591KingHenry6_1.txt</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.011384</td>\n",
       "      <td>0.182427</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.157956</td>\n",
       "      <td>0.027453</td>\n",
       "      <td>0.164241</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>0.008852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192196</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.018313</td>\n",
       "      <td>0.060085</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>0.083551</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.037142</td>\n",
       "      <td>0.024236</td>\n",
       "      <td>0.001454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1591TitusAndronicus.txt</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>0.026260</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.097509</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366730</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.025713</td>\n",
       "      <td>0.058655</td>\n",
       "      <td>0.267700</td>\n",
       "      <td>0.014612</td>\n",
       "      <td>0.008383</td>\n",
       "      <td>0.042393</td>\n",
       "      <td>0.040403</td>\n",
       "      <td>0.003871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1600TroilusAndCressida.txt</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.322083</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.212149</td>\n",
       "      <td>0.065726</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.044836</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085256</td>\n",
       "      <td>0.008028</td>\n",
       "      <td>0.045328</td>\n",
       "      <td>0.062126</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.024072</td>\n",
       "      <td>0.009993</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>0.096935</td>\n",
       "      <td>0.002440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1599JuliusCaesar.txt</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.244922</td>\n",
       "      <td>0.052227</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.023126</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179127</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.028274</td>\n",
       "      <td>0.039291</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.092084</td>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1591KingHenry6_3.txt</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.006049</td>\n",
       "      <td>0.285853</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.173143</td>\n",
       "      <td>0.008332</td>\n",
       "      <td>0.016828</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277271</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.047126</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.095101</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.029255</td>\n",
       "      <td>0.029865</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Filenames   topic_0   topic_1   topic_2   topic_3  \\\n",
       "14      1596MerchantOfVenice.txt  0.321740  0.005816  0.001305  0.006217   \n",
       "35            1612KingHenry8.txt  0.131133  0.000743  0.064507  0.004680   \n",
       "13              1596KingJohn.txt  0.020791  0.000931  0.008053  0.002395   \n",
       "23          1601TwelfthNight.txt  0.017451  0.007396  0.001097  0.022399   \n",
       "1       1590TamingOfTheShrew.txt  0.015613  0.003307  0.003517  0.003032   \n",
       "7         1594ComedyOfErrors.txt  0.015162  0.002552  0.005184  0.016352   \n",
       "26  1604AllsWellThatEndsWell.txt  0.015009  0.010244  0.002247  0.132839   \n",
       "0   1589TwoGentlemenOfVerona.txt  0.012434  0.000837  0.001368  0.001644   \n",
       "19                1599Hamlet.txt  0.010779  0.004596  0.001371  0.019402   \n",
       "17   1598MuchAdoAboutNothing.txt  0.009844  0.002793  0.002513  0.008526   \n",
       "31            1608Coriolanus.txt  0.009457  0.005195  0.000710  0.006245   \n",
       "18           1599AsYouLikeIt.txt  0.009041  0.003687  0.003024  0.001003   \n",
       "9           1595KingRichard2.txt  0.008451  0.001081  0.071415  0.000608   \n",
       "12          1596KingHenry4_1.txt  0.008447  0.000912  0.010564  0.002965   \n",
       "3           1591KingHenry6_2.txt  0.007591  0.003225  0.250942  0.001680   \n",
       "28         1605TimonOfAthens.txt  0.007311  0.001754  0.002702  0.005227   \n",
       "33             1610Cymbeline.txt  0.007291  0.002430  0.001610  0.115752   \n",
       "34               1610Tempest.txt  0.006690  0.016225  0.002655  0.002370   \n",
       "8       1594LovesLaboursLost.txt  0.006445  0.020032  0.002167  0.001840   \n",
       "24     1603MeasureForMeasure.txt  0.006154  0.002020  0.002004  0.177056   \n",
       "10  1595MidsummerNightsDream.txt  0.006027  0.001705  0.002854  0.001067   \n",
       "6           1592KingRichard3.txt  0.005535  0.000554  0.214939  0.004894   \n",
       "11        1595RomeoAndJuliet.txt  0.004248  0.001905  0.001005  0.005630   \n",
       "21            1599KingHenry5.txt  0.004108  0.008778  0.018179  0.003420   \n",
       "25               1603Othello.txt  0.003266  0.001412  0.000633  0.252074   \n",
       "27              1605KingLear.txt  0.003187  0.003043  0.001283  0.013707   \n",
       "16   1597MerryWivesOfWindsor.txt  0.003164  0.004052  0.001514  0.002545   \n",
       "30               1606Macbeth.txt  0.002858  0.002749  0.003402  0.012712   \n",
       "15          1597KingHenry4_2.txt  0.002607  0.004015  0.020575  0.001044   \n",
       "32           1609WintersTale.txt  0.002603  0.001449  0.000803  0.020979   \n",
       "29   1606AnthonyAndCleopatra.txt  0.002336  0.011080  0.001126  0.014099   \n",
       "2           1591KingHenry6_1.txt  0.001856  0.011384  0.182427  0.004885   \n",
       "5        1591TitusAndronicus.txt  0.001795  0.011872  0.026260  0.001348   \n",
       "22    1600TroilusAndCressida.txt  0.000988  0.322083  0.002600  0.002040   \n",
       "20          1599JuliusCaesar.txt  0.000976  0.003156  0.002549  0.001599   \n",
       "4           1591KingHenry6_3.txt  0.000897  0.006049  0.285853  0.002033   \n",
       "\n",
       "     topic_4   topic_5   topic_6   topic_7   topic_8  ...  topic_10  topic_11  \\\n",
       "14  0.163253  0.064608  0.001599  0.016104  0.011887  ...  0.140159  0.000981   \n",
       "35  0.242026  0.066987  0.007650  0.014776  0.003427  ...  0.086975  0.001778   \n",
       "13  0.180378  0.019071  0.019071  0.031325  0.002125  ...  0.195432  0.003874   \n",
       "23  0.146285  0.117174  0.001465  0.061846  0.023435  ...  0.107400  0.010011   \n",
       "1   0.126563  0.053453  0.001318  0.019640  0.323024  ...  0.128552  0.014821   \n",
       "7   0.107323  0.082973  0.004245  0.016604  0.274253  ...  0.197311  0.001522   \n",
       "26  0.218412  0.133215  0.029243  0.020706  0.001901  ...  0.088812  0.006020   \n",
       "0   0.174720  0.064436  0.000857  0.018440  0.205968  ...  0.199037  0.001211   \n",
       "19  0.170156  0.062152  0.004392  0.279310  0.009188  ...  0.108138  0.001661   \n",
       "17  0.122883  0.090772  0.002035  0.027473  0.011327  ...  0.084396  0.045497   \n",
       "31  0.346632  0.093254  0.001489  0.006974  0.004281  ...  0.100184  0.001637   \n",
       "18  0.133859  0.095138  0.000719  0.016068  0.005298  ...  0.126706  0.006830   \n",
       "9   0.199582  0.043611  0.002745  0.011036  0.003346  ...  0.215473  0.014554   \n",
       "12  0.202809  0.048230  0.001447  0.026872  0.010233  ...  0.111296  0.286901   \n",
       "3   0.151654  0.032337  0.035720  0.006467  0.012496  ...  0.215626  0.016043   \n",
       "28  0.186092  0.457634  0.002296  0.028439  0.011868  ...  0.106714  0.001906   \n",
       "33  0.241717  0.117499  0.005579  0.020885  0.006185  ...  0.113197  0.005710   \n",
       "34  0.162946  0.062474  0.002826  0.034915  0.018547  ...  0.118791  0.008212   \n",
       "8   0.171406  0.038039  0.012272  0.119404  0.012528  ...  0.100004  0.003233   \n",
       "24  0.179555  0.036395  0.001784  0.023491  0.002963  ...  0.114420  0.009219   \n",
       "10  0.098045  0.014890  0.004823  0.038013  0.004112  ...  0.115169  0.003620   \n",
       "6   0.122755  0.037788  0.001560  0.006683  0.001520  ...  0.221953  0.002851   \n",
       "11  0.101918  0.050185  0.001215  0.027728  0.011746  ...  0.200783  0.008577   \n",
       "21  0.191347  0.056136  0.161083  0.029452  0.001630  ...  0.080568  0.050233   \n",
       "25  0.210048  0.085260  0.000914  0.064298  0.004569  ...  0.118850  0.004045   \n",
       "27  0.196851  0.155304  0.114551  0.030878  0.017105  ...  0.162606  0.004971   \n",
       "16  0.130211  0.041887  0.003925  0.042902  0.012107  ...  0.060551  0.021352   \n",
       "30  0.214211  0.071779  0.002713  0.016522  0.001443  ...  0.150026  0.004854   \n",
       "15  0.199548  0.090954  0.001915  0.034724  0.007654  ...  0.111976  0.211586   \n",
       "32  0.201476  0.061207  0.000817  0.040867  0.003537  ...  0.126844  0.003317   \n",
       "29  0.231038  0.097637  0.000748  0.020722  0.002258  ...  0.121176  0.001191   \n",
       "2   0.157956  0.027453  0.164241  0.010326  0.008852  ...  0.192196  0.004469   \n",
       "5   0.097509  0.016212  0.001074  0.002948  0.008398  ...  0.366730  0.002054   \n",
       "22  0.212149  0.065726  0.001103  0.044836  0.001468  ...  0.085256  0.008028   \n",
       "20  0.244922  0.052227  0.001205  0.023126  0.001877  ...  0.179127  0.002877   \n",
       "4   0.173143  0.008332  0.016828  0.001215  0.004718  ...  0.277271  0.002765   \n",
       "\n",
       "    topic_12  topic_13  topic_14  topic_15  topic_16  topic_17  topic_18  \\\n",
       "14  0.015625  0.083005  0.002078  0.008874  0.016490  0.014173  0.123507   \n",
       "35  0.018741  0.021303  0.002664  0.054534  0.002378  0.158546  0.115178   \n",
       "13  0.032306  0.087861  0.007485  0.281538  0.005139  0.022966  0.076958   \n",
       "23  0.045036  0.039245  0.002044  0.003167  0.203841  0.011590  0.169308   \n",
       "1   0.017893  0.077661  0.001577  0.002935  0.016583  0.019074  0.156916   \n",
       "7   0.019991  0.087184  0.002117  0.006969  0.001545  0.013514  0.127875   \n",
       "26  0.006591  0.036549  0.001360  0.014032  0.030190  0.085716  0.161308   \n",
       "0   0.003534  0.124392  0.004479  0.003180  0.083181  0.026454  0.064948   \n",
       "19  0.069528  0.053066  0.002091  0.053561  0.002134  0.043046  0.100612   \n",
       "17  0.004160  0.110246  0.001030  0.005890  0.215904  0.002924  0.246911   \n",
       "31  0.042355  0.012842  0.235558  0.002848  0.001192  0.025035  0.095057   \n",
       "18  0.016795  0.061075  0.001887  0.008141  0.231974  0.022243  0.242665   \n",
       "9   0.006967  0.092629  0.002220  0.269775  0.001491  0.034476  0.018572   \n",
       "12  0.016608  0.068083  0.000669  0.090614  0.003589  0.011036  0.089505   \n",
       "3   0.018805  0.049275  0.001645  0.091627  0.001141  0.045904  0.050329   \n",
       "28  0.035775  0.037198  0.004651  0.002380  0.003922  0.022339  0.077454   \n",
       "33  0.045413  0.046138  0.023868  0.005401  0.002704  0.135847  0.077819   \n",
       "34  0.315110  0.008041  0.002255  0.003226  0.008802  0.122521  0.099644   \n",
       "8   0.001485  0.071182  0.002025  0.023770  0.280372  0.026811  0.092159   \n",
       "24  0.020017  0.037103  0.001407  0.003419  0.002523  0.031114  0.346733   \n",
       "10  0.182623  0.145878  0.002945  0.007158  0.255475  0.016093  0.091462   \n",
       "6   0.017163  0.140055  0.000971  0.114532  0.001611  0.050910  0.051469   \n",
       "11  0.030170  0.448126  0.002645  0.006172  0.016087  0.008256  0.068905   \n",
       "21  0.018475  0.028184  0.004665  0.190624  0.006336  0.008588  0.115302   \n",
       "25  0.060208  0.055492  0.003419  0.004173  0.002780  0.005247  0.118250   \n",
       "27  0.070160  0.025299  0.001440  0.004561  0.006007  0.074763  0.109635   \n",
       "16  0.016420  0.048388  0.000975  0.005130  0.013534  0.004210  0.171107   \n",
       "30  0.273404  0.046246  0.002967  0.064175  0.001297  0.064665  0.058386   \n",
       "15  0.016136  0.043851  0.001855  0.082101  0.001080  0.019608  0.113396   \n",
       "32  0.051579  0.031472  0.000955  0.001353  0.014744  0.294156  0.131184   \n",
       "29  0.065575  0.020071  0.008582  0.011509  0.002960  0.080396  0.088763   \n",
       "2   0.018313  0.060085  0.005796  0.083551  0.001762  0.037142  0.024236   \n",
       "5   0.025713  0.058655  0.267700  0.014612  0.008383  0.042393  0.040403   \n",
       "22  0.045328  0.062126  0.001137  0.024072  0.009993  0.010976  0.096935   \n",
       "20  0.028274  0.039291  0.003959  0.005845  0.001139  0.002140  0.092084   \n",
       "4   0.015619  0.047126  0.000873  0.095101  0.001337  0.029255  0.029865   \n",
       "\n",
       "    topic_19  \n",
       "14  0.001151  \n",
       "35  0.000688  \n",
       "13  0.001343  \n",
       "23  0.008203  \n",
       "1   0.013624  \n",
       "7   0.016444  \n",
       "26  0.004487  \n",
       "0   0.008142  \n",
       "19  0.003564  \n",
       "17  0.003995  \n",
       "31  0.002403  \n",
       "18  0.011125  \n",
       "9   0.001427  \n",
       "12  0.008371  \n",
       "3   0.006140  \n",
       "28  0.002550  \n",
       "33  0.008610  \n",
       "34  0.002883  \n",
       "8   0.013566  \n",
       "24  0.001124  \n",
       "10  0.006702  \n",
       "6   0.000981  \n",
       "11  0.003743  \n",
       "21  0.020478  \n",
       "25  0.003394  \n",
       "27  0.003995  \n",
       "16  0.414324  \n",
       "30  0.003529  \n",
       "15  0.034068  \n",
       "32  0.009539  \n",
       "29  0.002622  \n",
       "2   0.001454  \n",
       "5   0.003871  \n",
       "22  0.002440  \n",
       "20  0.000976  \n",
       "4   0.000751  \n",
       "\n",
       "[36 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if docLevel is True:\n",
    "    #Variables\n",
    "    docTopicsCSV = 'docTopics.csv'\n",
    "    sortOrder = ['topic_0','Filenames']\n",
    "    \n",
    "    docTopics = []\n",
    "    for i in range(len(texts)):\n",
    "        docTopics.append(optimalModel[corpus[i]])\n",
    "\n",
    "\n",
    "    topicSeriesDf = pd.DataFrame([[y[1] for y in  x] for x in docTopics])\n",
    "\n",
    "\n",
    "    txtPaths = pd.Series(os.path.basename(pathName) for pathName in paths)\n",
    "\n",
    "    textPath = pd.Series(txtPaths)\n",
    "    contents = pd.Series(texts)\n",
    "    docTopicDis = pd.concat([textPath, topicSeriesDf], axis=1)\n",
    "\n",
    "    docTopicsDf = docTopicDis.reset_index(drop = True)\n",
    "    # get length of df's columns\n",
    "    numCols = len(list(docTopicsDf))\n",
    "\n",
    "    rng = range(0, (numCols) + 1)\n",
    "\n",
    "    newCols = ['Filenames'] + ['topic_' + str(i) for i in rng]\n",
    "\n",
    "    # ensure the length of the new columns list is equal to the length of df's columns\n",
    "    docTopicsDf.columns = newCols[:numCols]\n",
    "\n",
    "    sortedDf = docTopicsDf.sort_values(sortOrder, ascending = False)\n",
    "    sortedDf.to_csv(os.path.join(dataResults, docTopicsCSV))\n",
    "\n",
    "sortedDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a stacked bar graph\n",
    "\n",
    "This stacked bar graph shows the distribution of topics within a document. This will only be run if `docLevel` was set to **True** above as it is really only useful at the document level. That said, there are a few places where changes might need to be made. These can all be found in the four lines after the `#Variables` line. \n",
    "\n",
    "1. In the `graphName` variable you will want to change the name of the .png file to a name that fits better with your dataset.\n",
    "\n",
    "2. The `boxSize` variable changes the size and dimensions of the legend box. The numbers indicate the following: (x, y, width, height). So the first two numbers determine where the legend resides in relation to the graph, and the third and fourth numbers determine how wide and high the legend box is. Feel free to play with these numbers to better fit your graph if needed.\n",
    "\n",
    "3. In the `colorScheme` variable you may wish to change the color from `\"Vega20\"` to a different color scheme. Some options can be found [here](https://matplotlib.org/users/colormaps.html).\n",
    "\n",
    "4. The next line which is the variable `topN` you may want to change the number depending on how many documents you wish to see. Right now we are diplaying the top 10, but you may only want 5 or 20. Adjust this number accordingly.\n",
    "\n",
    "The rest of the code should not need to be adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if docLevel is True:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.colors as colors\n",
    "    \n",
    "    #Variables\n",
    "    graphName = 'barGraphLDA.png'\n",
    "    boxSize = (1.01,.5,.35,.5)\n",
    "    colorScheme = \"tab20\"\n",
    "    topN = min(10, len(sortedDf))\n",
    "    \n",
    "    colors = plt.cm.get_cmap(colorScheme)\n",
    "    sortedDfSh = sortedDf[:topN]\n",
    "    sortedDfSh = sortedDfSh.iloc[::-1]\n",
    "    ax = sortedDfSh.plot(kind='barh', figsize = (10,2*topN), stacked = True, colormap = colors)\n",
    "    ax.set_yticklabels(sortedDfSh['Filenames'], rotation=0)\n",
    "    ax.tick_params(axis = 'y', which = 'major',labelsize = 24)\n",
    "    lgd = ax.legend(bbox_to_anchor = boxSize, fontsize = 24)\n",
    "    ax.figure.savefig(os.path.join(dataResults, graphName), dpi = 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making pyLDAvis work with MALLET\n",
    "#### The code below was adapted from http://jeriwieringa.com/2018/07/17/pyLDAviz-and-Mallet/#topic=0&lambda=1&term= and was last accessed on 01/23/2019.\n",
    "\n",
    "There should be no need to change any of the code that follows below until the last cell.\n",
    "\n",
    "The first step is to extract the data from the MALLET statefile and put it into a pandas dataframe. We do this by creating two functions. One that extracts the parameters we need from the statefile and another that saves those parameters to a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractParams(statefile):\n",
    "    \"\"\"Extract the alpha and beta values from the statefile.\n",
    "\n",
    "    Args:\n",
    "        statefile (str): Path to statefile produced by MALLET.\n",
    "    Returns:\n",
    "        tuple: alpha (list), beta    \n",
    "    \"\"\"\n",
    "    with gzip.open(statefile, 'r') as state:\n",
    "        params = [x.decode('utf8').strip() for x in state.readlines()[1:3]]\n",
    "    return (list(params[0].split(\":\")[1].split(\" \")), float(params[1].split(\":\")[1]))\n",
    "\n",
    "\n",
    "def stateToDf(statefile):\n",
    "    \"\"\"Transform state file into pandas dataframe.\n",
    "    The MALLET statefile is tab-separated, and the first two rows contain the alpha and beta hypterparamters.\n",
    "    \n",
    "    Args:\n",
    "        statefile (str): Path to statefile produced by MALLET.\n",
    "    Returns:\n",
    "        datframe: topic assignment for each token in each document of the model\n",
    "    \"\"\"\n",
    "    return pd.read_csv(statefile,\n",
    "                       compression='gzip',\n",
    "                       sep=' ',\n",
    "                       skiprows=[1,2]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look up the state file of the MALLET LDA results we saved as the variable `optimalModel` previously and save it as the variable `statefile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statefile = optimalModel.fstate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we run the `extractParams` function we created above and run it on our `statefile`. We then print out the parameters to make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5], 0.01\n"
     ]
    }
   ],
   "source": [
    "params = extractParams(statefile)\n",
    "\n",
    "alpha = [float(x) for x in params[0][1:]]\n",
    "beta = params[1]\n",
    "print(\"{}, {}\".format(alpha, beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the `stateToDf` function from above and create our dataframe containing the information from the MALLET statefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = stateToDf(statefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here we set the Python class (such as str, int, float, list, et cetera) for the entire column `['type']` to a string (str). This is because `nan` is used in Pandas to indicate missing integer values, and Pandas assumes it is an integer, rather than a string, so we change it to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['type'] = df.type.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next bit of data to gather is the length of the chunks. To do this, we group the data by the chunk id and count the tokens in the chunk. This data is sorted by the chunk id, so it is in the correct order for the visualization preprocessing. Then the dataframe is ordered using `reset_index` and this is indexing the dataframe by the column `'doc_length'`. The `reset_index` function will be used in a similar way later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get document lengths from dataframe\n",
    "docs = df.groupby('#doc')['type'].count().reset_index(name ='doc_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we gather the vocabulary and frequencies. Here we use pandas to generate a new dataframe with the counts for each word. We then sort this dataframe so that it is alphabetical by type, a step we will repeat in creating the topic-term matrix later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get vocab and term frequencies from dataframe\n",
    "vocab = df['type'].value_counts().reset_index()\n",
    "vocab.columns = ['type', 'term_freq']\n",
    "vocab = vocab.sort_values(by='type', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is to create the matrix files. Here is where things get a bit tricky, as there is the adding of smoothing values and normalizing the data so that the percent distribution of each topic in each row sums to 1. To do the normalizing, we use sklearn because these are large matrices that require a more optimized function than dividing by the sum of the row with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Topic-term matrix from state file\n",
    "# https://ldavis.cpsievert.me/reviews/reviews.html\n",
    "import sklearn.preprocessing\n",
    "\n",
    "def pivotAndSmooth(df, smoothValue, rowsVariable, colsVariable, valuesVariable):\n",
    "    \"\"\"\n",
    "    Turns the pandas dataframe into a data matrix.\n",
    "    Args:\n",
    "        df (dataframe): aggregated dataframe \n",
    "        smooth_value (float): value to add to the matrix to account for the priors\n",
    "        rows_variable (str): name of dataframe column to use as the rows in the matrix\n",
    "        cols_variable (str): name of dataframe column to use as the columns in the matrix\n",
    "        values_variable(str): name of the dataframe column to use as the values in the matrix\n",
    "    Returns:\n",
    "        dataframe: pandas matrix that has been normalized on the rows.\n",
    "    \"\"\"\n",
    "    matrix = df.pivot(index=rowsVariable, columns=colsVariable, values=valuesVariable).fillna(value=0)\n",
    "    matrix = matrix.values + smoothValue\n",
    "    \n",
    "    normed = sklearn.preprocessing.normalize(matrix, norm='l1', axis=1)\n",
    "    \n",
    "    return pd.DataFrame(normed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to aggregate the data from the statefile dataframe to get the number of topic assignments for each word in the documents. We aggregate by topic and word, count the number of times each word is assigned to each topic, and then sort the resulting dataframe alphabetically by word, so that it matches the order of the vocabulary frame.\n",
    "\n",
    "Then we do this again, but focused on the documents and topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phiDf = df.groupby(['topic', 'type'])['type'].count().reset_index(name ='token_count')\n",
    "phiDf = phiDf.sort_values(by='type', ascending=True)\n",
    "\n",
    "phi = pivotAndSmooth(phiDf, beta, 'topic', 'type', 'token_count')\n",
    "\n",
    "thetaDf = df.groupby(['#doc', 'topic'])['topic'].count().reset_index(name ='topic_count')\n",
    "\n",
    "theta = pivotAndSmooth(thetaDf, alpha , '#doc', 'topic', 'topic_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of the data in place, we can queue that data up and pass it to the visualization library. Then we plot the pyLDAvis graph. \n",
    "\n",
    "First, you will want to make a change, which is the file name in the first line. Change the file name to match your data, but keep the .html file extention. This file can be opened in a web browser simply by double clicking on the file. The file can also be used to embed the graph in a webpage.\n",
    "\n",
    "**NOTE:** In `n_jobs` you want to keep it equal to 1. Anything higher and ReD will give an error. If you are running this on your own computer then feel free to change this number to the number of cores on your computer or any number between 1 and the number of cores on your computer. If you remove the `n_jobs` variable then it will default to using all available cores.\n",
    "\n",
    "The result is an interactive bubble and bar graph. The bubbles represent the topics and the topics (bubbles) that are closest in proximity to one another on the graph are the most similar. The larger the bubble, the more weight that topic has throughout the entire corpus. Note that the topic numbers in the bubble are off by 1 when compared to the topic numbers above. This is because the topic bubbles start counting at 1 while the topics above started counting at 0. So topic 1 in our bubble graph is the same as topic 0 from above, and topic 2 below is the same as 1 above and so on.\n",
    "\n",
    "The bar graphs show the top 30 words (by estimated frequency within the topic) for the currently highlighted topic. The red part of the bar shows the estimated word frequency in that topic, while the blue shows the actual frequency throughout the entire corpus.\n",
    "\n",
    "The visualization is interactive, so as you hover over and click on aspects of the visualization you will be shown additional information. Hovering over a bubble shows you the words associated with that topic ranked by estimated frequency. Clicking on the bubble makes that the default bubble when you are not hovering over other bubbles. In the bar graph if you hover over a word, it will show you which topics have that word in the top 30 estimated frequencies of words in that topic. It does this by removing the bubbles that do not contain the word in their top 30 and it changes the bubble size of the remaining bubbles so you can see in which topics that word had the highest estimated frequency. \n",
    "\n",
    "The slide bar over the bar graph that goes from 0 to 1 changes the lambda setting. What this does is give more importance to words that occur dispraportinately more often in that topic than in others. These are called \"jargon\" words. The closer you move the slider to 0, the more \"jargon\" words rise to the top of the bar graph. The default is to set the slider to 1 which will place more emphasis on the relevance of the word in relation to the whole corpus, and less on the uniqueness of the word to that topic. Recommendations vary as to the best setting, but most fall in a range between 0.4 and 0.6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el255601405009330250084089467896\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el255601405009330250084089467896_data = {\"mdsDat\": {\"x\": [0.11376231946745624, -0.0220863744156949, -0.2625839474649677, 0.04745971461030026, 0.1115630351771093, -0.02294807645209027, -0.11849860449189129, 0.02448585241822712, 0.16239352319302994, -0.1255761660573154, 0.09192038753136854, -0.032248734987161166, 0.02879253456001917, 0.07020829237434269, -0.19823728875962227, -0.18630389040532208, 0.15580274576104425, -0.07960720473411032, 0.0785236328013998, 0.163178249873882], \"y\": [-0.10949778022165792, -0.15758306071737915, -0.04896643821112048, -0.16812802998222426, 0.15214278364023662, 0.02709697315810015, 0.00792377342535138, -0.05604870012727382, -0.13643521720696328, 0.09440333105987736, 0.21816092935137205, -0.07852307162520142, 0.1837054499018463, 0.039147049541932724, 0.00892521408312063, 0.016266286993000378, -0.07897043555109108, -0.06336111056775007, 0.22361556297946877, -0.07387350992364583], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [1.8398264065453025, 1.552001385333349, 3.8593290312674506, 2.484853993051684, 18.049219328309196, 7.360040109492296, 1.8772355605190045, 3.621844929863437, 2.3504596584754474, 1.544444112181618, 14.599536482252706, 2.3364943690436313, 4.338918344358073, 7.056690989030488, 1.7777123523099192, 5.06632341606294, 3.4957995175024017, 4.574067836510752, 10.587964532230796, 1.6272376456595268]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"Freq\": [3000.0, 2442.0, 1549.0, 3013.0, 2845.0, 1017.0, 400.0, 832.0, 1032.0, 1075.0, 1538.0, 1291.0, 760.0, 760.0, 1107.0, 705.0, 1135.0, 866.0, 525.0, 363.0, 998.0, 763.0, 647.0, 661.0, 897.0, 2010.0, 879.0, 493.0, 773.0, 447.0, 73.54991748858338, 39.23119848977763, 26.48424571879265, 23.54264123318073, 18.6399670904942, 17.65943226195689, 17.65943226195689, 16.678897433419586, 15.698362604882279, 9.815153633658438, 9.815153633658438, 8.834618805121131, 8.834618805121131, 8.834618805121131, 8.834618805121131, 7.854083976583825, 7.854083976583825, 7.854083976583825, 6.873549148046519, 6.873549148046519, 6.873549148046519, 6.873549148046519, 5.893014319509213, 5.893014319509213, 5.893014319509213, 5.893014319509213, 5.893014319509213, 5.893014319509213, 5.893014319509213, 5.893014319509213, 66.68617368882222, 16.678897433419586, 20.601036747568813, 13.737292947807665, 69.62777817443414, 13.737292947807665, 54.91975574637454, 49.0365467751507, 50.017081603688005, 64.72510403174762, 25.50371089025535, 23.54264123318073, 72.56938266004606, 19.620501919031508, 30.40638503294188, 20.601036747568813, 15.698362604882279, 37.27012883270302, 87.27740508810567, 35.309059175628406, 21.581571576106118, 70.60831300297144, 33.347989518553796, 60.80296471759838, 47.07547711807609, 75.51098714565798, 50.017081603688005, 43.15333780392687, 41.19226814685225, 33.347989518553796, 58.84189506052376, 33.347989518553796, 37.27012883270302, 37.27012883270302, 37.27012883270302, 34.3285243470911, 33.347989518553796, 31.386919861479182, 148.85334575605845, 87.16160980032079, 78.34850466378685, 77.36927075972751, 58.763826582600274, 42.116850213591704, 39.179148501413714, 32.32451117299841, 30.366043364879765, 29.386809460820437, 25.469873844583123, 25.469873844583123, 24.490639940523796, 19.594470420227157, 18.61523651616783, 17.636002612108502, 11.760599187752529, 10.781365283693201, 9.802131379633874, 9.802131379633874, 8.822897475574544, 8.822897475574544, 51.90918925418497, 7.843663571515218, 6.864429667455889, 6.864429667455889, 5.8851957633965615, 5.8851957633965615, 5.8851957633965615, 4.905961859337233, 4.905961859337233, 4.905961859337233, 4.905961859337233, 4.905961859337233, 20.57370432428648, 37.22068069329506, 14.698300899930514, 41.13761630953237, 20.57370432428648, 9.802131379633874, 71.49386733537153, 34.282978981117076, 17.636002612108502, 57.784592678540946, 87.16160980032079, 28.40757555676111, 21.55293822834581, 33.30374507705774, 35.262212885176396, 34.282978981117076, 32.32451117299841, 38.199914597354386, 40.15838240547304, 40.15838240547304, 26.44910774864245, 26.44910774864245, 26.44910774864245, 222.39293963744407, 212.50924826206324, 186.81165068607308, 163.09079138515906, 93.90495175749328, 81.0561529694982, 77.10267641934587, 66.23061590642695, 64.25387763135079, 54.37018625596995, 48.439971430741444, 37.56791091782254, 26.695850404903627, 25.707481267365544, 25.707481267365544, 24.71911212982746, 23.730742992289375, 22.742373854751293, 19.777266442137044, 17.80052816706088, 16.812159029522793, 16.812159029522793, 15.823789891984712, 14.835420754446627, 13.847051616908544, 13.847051616908544, 12.858682479370461, 11.870313341832379, 11.870313341832379, 11.870313341832379, 20.765635579675127, 26.695850404903627, 17.80052816706088, 50.41670970581762, 58.32366280612228, 52.39344798089378, 20.765635579675127, 104.77701227041219, 46.46323315566528, 33.614434367670206, 79.07941469442204, 216.46272481221555, 709.6589244437191, 74.13756900673162, 126.52113329625, 302.45083977802875, 115.64907278333112, 128.49787157132616, 132.4513481214785, 54.37018625596995, 139.3699320842451, 124.54439502117386, 90.93984434487902, 57.3352936685842, 75.12593814426971, 68.20735418150312, 65.24224676888888, 67.21898504396503, 61.28877021873653, 61.28877021873653, 60.300401081198444, 110.24769702571074, 33.47490559632552, 32.49063903953853, 29.53783936917757, 29.53783936917757, 29.53783936917757, 28.553572812390577, 23.632240028455627, 23.632240028455627, 23.632240028455627, 21.663706914881647, 19.695173801307668, 18.710907244520676, 18.710907244520676, 17.72664068773369, 16.742374130946697, 15.758107574159709, 12.805307903798738, 75.79836753816609, 11.821041347011748, 10.836774790224757, 10.836774790224757, 10.836774790224757, 9.852508233437767, 9.852508233437767, 9.852508233437767, 9.852508233437767, 9.852508233437767, 8.868241676650777, 8.868241676650777, 22.64797347166864, 60.05010262957425, 32.49063903953853, 12.805307903798738, 17.72664068773369, 21.663706914881647, 18.710907244520676, 44.301837720982405, 56.11303640242629, 23.632240028455627, 50.20743706170435, 68.90850164065716, 96.46796523069288, 195.87888746617884, 60.05010262957425, 71.86130131101812, 68.90850164065716, 44.301837720982405, 58.08156951600027, 111.23196358249773, 56.11303640242629, 44.301837720982405, 61.03436918636124, 40.364771493834446, 46.27037083455639, 45.2861042777694, 62.01863574314823, 48.238903948130364, 45.2861042777694, 47.25463739134338, 45.2861042777694, 38.39623838026047, 39.38050493704746, 37.41197182347348, 36.42770526668649, 37.41197182347348, 174.68117277814187, 77.421045897522, 70.47389397747774, 69.4814437031857, 66.50409288030959, 63.52674205743346, 59.556940960265294, 54.594689588805096, 53.60223931451306, 52.60978904022102, 51.61733876592898, 51.61733876592898, 49.6324382173449, 48.63998794305286, 48.63998794305286, 47.64753766876082, 46.65508739446878, 45.66263712017674, 44.6701868458847, 43.67773657159266, 43.67773657159266, 41.69283602300858, 40.70038574871654, 40.70038574871654, 39.7079354744245, 39.7079354744245, 38.71548520013246, 239.19044060712446, 37.72303492584042, 37.72303492584042, 116.12660659491156, 85.36064809185832, 122.0813082406638, 120.09640769207972, 136.9680623550444, 940.8527845315964, 212.39428320123938, 89.33044918902648, 178.65097387531003, 66.50409288030959, 61.54184150884937, 173.68872250384985, 162.7717694866374, 125.05865906353992, 258.04699581867317, 58.564490685973254, 594.4876388036746, 590.5178377065065, 324.54116419623983, 152.84726674371703, 100.24740220623893, 241.17534115570854, 198.49997936115082, 97.27005138336281, 507.1520146659751, 562.7292300263293, 834.6606051823483, 248.1224930757528, 263.0092471901334, 445.62009765986863, 205.4471312811951, 199.49242963544287, 542.8802245404886, 826.721002988012, 276.90355103022193, 671.8987601984537, 964.6715911146053, 370.1938768136737, 344.3901696820806, 258.04699581867317, 384.08818065376227, 287.82050404743444, 302.707258161815, 994.4450993433666, 438.6729457398244, 755.264583238985, 363.2467248936294, 279.8809018530981, 286.82805377314236, 329.5034155677001, 281.8658024016822, 99.03690437822905, 59.42610370700455, 42.591513421734135, 42.591513421734135, 28.72773318680557, 25.75692313646373, 24.766653119683117, 24.766653119683117, 23.776383102902507, 22.786113086121894, 22.786113086121894, 22.786113086121894, 21.79584306934128, 21.79584306934128, 21.79584306934128, 20.805573052560668, 18.82503301899944, 18.82503301899944, 17.834763002218832, 16.84449298543822, 16.84449298543822, 15.854222968657607, 14.86395295187699, 14.86395295187699, 12.883412918315766, 12.883412918315766, 12.883412918315766, 12.883412918315766, 12.883412918315766, 11.893142901535153, 41.60124340495353, 40.61097338817291, 47.5428635056372, 33.679083270708624, 31.6985432371474, 52.49421358954026, 69.32880387481069, 106.95906451247394, 67.34826384124946, 64.37745379090762, 51.50394357275965, 78.24123402583619, 321.84765815386686, 42.591513421734135, 183.20985580458108, 138.64770504945355, 36.64989332105046, 66.35799382446883, 246.58713687854026, 170.33634558643314, 75.27042397549435, 455.53411041924954, 204.00552615697396, 101.01744441179028, 47.5428635056372, 156.47256535150456, 119.83257473062191, 772.4205157890455, 741.7221452688465, 77.25096400905558, 127.7547348648668, 254.50929701278517, 102.00771442857088, 179.24877573745866, 174.2974256535556, 155.48229533472394, 96.06609432788721, 183.20985580458108, 185.1903958381423, 203.01525614019334, 153.50175530116272, 108.93960454603518, 253.51902699600458, 150.53094525082088, 117.8520346970607, 107.94933452925457, 143.5990551333566, 108.93960454603518, 102.9979844453515, 91.30063050573459, 40.256304236535584, 39.27468257751253, 20.62387105607444, 20.62387105607444, 17.679006079005266, 17.679006079005266, 16.69738441998221, 16.69738441998221, 13.752519442913036, 12.770897783889977, 12.770897783889977, 12.770897783889977, 11.789276124866921, 10.807654465843862, 10.807654465843862, 10.807654465843862, 10.807654465843862, 8.844411147797748, 8.844411147797748, 7.86278948877469, 7.86278948877469, 7.86278948877469, 7.86278948877469, 7.86278948877469, 7.86278948877469, 6.881167829751632, 6.881167829751632, 6.881167829751632, 6.881167829751632, 31.42170930532807, 18.660627738028325, 106.02495539108044, 53.99900746285839, 232.65414940505482, 39.27468257751253, 11.789276124866921, 14.734141101936093, 22.587114374120553, 12.770897783889977, 24.550357692166667, 53.01738580383534, 53.01738580383534, 28.4768443282589, 46.14603419067393, 72.64981898429649, 37.31143925946641, 61.85198073504285, 46.14603419067393, 92.28225216475764, 26.513601010212785, 50.072520826766166, 22.587114374120553, 55.962250780904505, 35.34819594142029, 29.458465987281958, 34.36657428239724, 35.34819594142029, 28.4768443282589, 26.513601010212785, 28.4768443282589, 28.4768443282589, 24.550357692166667, 78.01445938975766, 66.16566160875409, 31.606668080827014, 30.61926826574339, 28.644468635576125, 27.657068820492494, 21.732669929990713, 18.77047048473982, 18.77047048473982, 17.783070669656187, 17.783070669656187, 15.808271039488927, 15.808271039488927, 14.820871224405295, 14.820871224405295, 13.833471409321666, 13.833471409321666, 13.833471409321666, 12.846071594238033, 12.846071594238033, 12.846071594238033, 12.846071594238033, 11.858671779154404, 11.858671779154404, 10.871271964070772, 10.871271964070772, 10.871271964070772, 10.871271964070772, 9.883872148987143, 9.883872148987143, 21.732669929990713, 25.682269190325233, 29.631868450659756, 23.70746956015797, 16.79567085457256, 83.93885828025945, 28.644468635576125, 25.682269190325233, 25.682269190325233, 27.657068820492494, 34.56886752607791, 16.79567085457256, 62.21606234841956, 531.2309745131441, 43.45546586183058, 45.430265491997844, 111.5860531026011, 67.15306142383773, 30.61926826574339, 29.631868450659756, 101.7120549517648, 80.97665883500855, 119.48525162327013, 48.39246493724873, 105.66165421209932, 44.44286567691422, 64.19086197858684, 116.52305217801926, 59.253862903168674, 74.06486012942314, 69.12786105400498, 64.19086197858684, 55.30426364283415, 76.03965975959039, 65.17826179367046, 47.405065122165105, 47.405065122165105, 42.468066046746955, 63.203462163503204, 47.405065122165105, 72.09006049925588, 48.39246493724873, 49.37986475233236, 48.39246493724873, 52.34206419758326, 61.88565411528686, 53.046249464634876, 50.09978124775088, 37.33175230792023, 34.38528409103623, 33.40312801874157, 31.438815874152237, 30.456659801857576, 23.581567295794915, 22.59941122350025, 19.65294300661626, 13.760006572848262, 13.760006572848262, 13.760006572848262, 13.760006572848262, 13.760006572848262, 11.795694428258932, 10.813538355964265, 10.813538355964265, 10.813538355964265, 10.813538355964265, 9.831382283669601, 8.849226211374935, 8.849226211374935, 8.849226211374935, 8.849226211374935, 7.86707013908027, 7.86707013908027, 7.86707013908027, 6.884914066785605, 6.884914066785605, 6.884914066785605, 6.884914066785605, 24.563723368089583, 38.3139083802149, 61.88565411528686, 25.545879440384248, 66.7964344767602, 99.20758486248415, 185.6373192244147, 44.20684481398289, 66.7964344767602, 76.61799519970685, 18.670786934321594, 21.617255151205587, 45.189000886277555, 70.72505876593885, 73.67152698282285, 150.27970062180674, 48.13546910316155, 55.01056160922421, 80.54661948888553, 51.08193732004555, 50.09978124775088, 53.046249464634876, 50.09978124775088, 42.242532669393555, 34.38528409103623, 31.438815874152237, 35.3674401633309, 33.40312801874157, 34.38528409103623, 400.0821340870846, 151.62644337507393, 151.62644337507393, 75.32902654225175, 45.005694211258316, 42.07117817922669, 33.26763008313183, 26.42042600839138, 25.442253997714168, 24.464081987036963, 23.485909976359753, 22.507737965682548, 21.529565955005342, 18.59504992297372, 17.61687791229651, 17.61687791229651, 13.704189869587676, 13.704189869587676, 12.72601785891047, 10.769673837556054, 9.791501826878847, 9.791501826878847, 8.813329816201641, 8.813329816201641, 8.813329816201641, 7.835157805524433, 7.835157805524433, 7.835157805524433, 7.835157805524433, 7.835157805524433, 21.529565955005342, 11.747845848233263, 62.61279040344806, 42.07117817922669, 19.573221933650924, 65.54730643547968, 55.7655863287076, 23.485909976359753, 94.89246675579591, 51.85289828599877, 21.529565955005342, 46.962038232612734, 33.26763008313183, 34.24580209380903, 44.02752220058111, 43.049350189903905, 40.11483415787228, 37.18031812584066, 32.28945807245462, 35.223974104486246, 25.442253997714168, 25.442253997714168, 24.464081987036963, 23.485909976359753, 78.38397508930484, 75.40774517830731, 72.43151526730979, 68.46320871931307, 61.51867226031885, 56.558289075322975, 51.59790589032709, 47.629599342330394, 46.63752270533123, 46.63752270533123, 44.65336943133287, 42.66921615733452, 42.66921615733452, 42.66921615733452, 41.677139520335345, 41.677139520335345, 37.70883297233865, 35.724679698340296, 34.73260306134112, 34.73260306134112, 33.740526424341944, 33.740526424341944, 33.740526424341944, 31.7563731503436, 31.7563731503436, 31.7563731503436, 31.7563731503436, 29.77221987634525, 29.77221987634525, 28.78014323934607, 88.3047414592966, 87.3126648222974, 231.16377718717777, 71.4394386303106, 88.3047414592966, 261.9181529341522, 93.26512464429246, 90.28889473329494, 57.550365712322154, 55.5662124383238, 337.3159773460895, 165.68671914523225, 313.50613805810934, 73.42359190430896, 130.9640368502611, 312.51406142111017, 456.3651737859906, 79.37605172630401, 65.48697880831556, 106.16212092528174, 56.558289075322975, 160.72633596023636, 661.7250376448198, 479.18293643697154, 638.9072749938388, 106.16212092528174, 579.3826767738883, 499.0244691769551, 167.6708724192306, 100.20966110328669, 285.7279922221324, 235.1320837351745, 122.03534711726854, 215.29055099519098, 242.07662019416873, 165.68671914523225, 133.9402667612586, 190.4886350702116, 264.8943828451498, 164.69464250823307, 327.3952109760978, 526.8026150129319, 139.89272658325368, 316.48236796910686, 313.50613805810934, 174.6154088782248, 279.77553240013737, 245.05285010516624, 292.67252868112666, 219.25885754318767, 452.39686723799383, 244.06077346816707, 252.98946320115965, 248.02908001616376, 221.24301081718605, 221.24301081718605, 223.2271640911844, 41.33863415637082, 41.33863415637082, 33.46648292449826, 29.530407308561973, 25.59433169262569, 25.59433169262569, 19.690218268721264, 18.70619936473719, 14.770123748800906, 13.786104844816835, 13.786104844816835, 12.802085940832765, 11.818067036848694, 11.818067036848694, 11.818067036848694, 10.834048132864622, 10.834048132864622, 10.834048132864622, 9.850029228880551, 8.86601032489648, 8.86601032489648, 8.86601032489648, 8.86601032489648, 8.86601032489648, 8.86601032489648, 7.88199142091241, 7.88199142091241, 7.88199142091241, 7.88199142091241, 7.88199142091241, 58.06695552410003, 7.88199142091241, 16.73816155676905, 15.75414265278498, 21.65825607668941, 44.29069086832304, 62.98705004402039, 26.578350596609763, 58.06695552410003, 151.54875140258676, 24.610312788641618, 64.95508785198854, 35.434520732466396, 39.37059634840268, 25.59433169262569, 36.41853963645047, 77.74733360378146, 224.36615029740807, 62.98705004402039, 26.578350596609763, 87.58752264362217, 80.69939031573368, 49.210785388243394, 64.95508785198854, 100.3797683954151, 79.7153714117496, 43.30667196433897, 48.22676648425932, 46.25872867629118, 54.13087990816375, 33.46648292449826, 39.37059634840268, 40.35461525238675, 32.48246402051418, 33.46648292449826, 34.450501828482324, 34.450501828482324, 34.450501828482324, 41.49334860241824, 30.628629853867874, 29.640928149454208, 29.640928149454208, 25.69012133179953, 20.75161280973119, 20.75161280973119, 19.76391110531752, 19.76391110531752, 19.76391110531752, 18.77620940090385, 17.788507696490182, 16.800805992076512, 16.800805992076512, 16.800805992076512, 16.800805992076512, 15.813104287662844, 15.813104287662844, 15.813104287662844, 15.813104287662844, 15.813104287662844, 14.825402583249172, 14.825402583249172, 90.87843382310169, 13.837700878835502, 12.849999174421834, 11.862297470008166, 11.862297470008166, 11.862297470008166, 10.874595765594496, 10.874595765594496, 10.874595765594496, 24.70241962738586, 23.714717922972195, 60.25968098627795, 17.788507696490182, 34.57943667152255, 50.38266394214125, 49.39496223772758, 84.95222359661967, 43.46875201124557, 159.02985142764484, 30.628629853867874, 33.59173496710888, 37.54254178476356, 22.72701621855853, 103.7185559804794, 30.628629853867874, 100.7554508672384, 81.001416778965, 120.50948495551177, 56.30887416862327, 172.8576752894362, 99.76774916282473, 112.6078713202024, 51.37036564655493, 47.41955882890025, 94.82924064075637, 103.7185559804794, 74.08750484806933, 117.54637984227077, 88.90303041427435, 59.271979281864276, 140.26351904378512, 110.63246791137507, 59.271979281864276, 59.271979281864276, 82.97682018779234, 75.075206552483, 82.97682018779234, 66.18589121275997, 66.18589121275997, 63.222786099518956, 63.222786099518956, 62.23508439510529, 61.247382690691616, 62.23508439510529, 129.7471019617473, 50.518278536514224, 49.527918243698814, 46.556837365252576, 23.778550630498074, 23.778550630498074, 21.797830044867247, 20.807469752051833, 19.81710945923642, 19.81710945923642, 18.826749166421006, 18.826749166421006, 17.836388873605596, 17.836388873605596, 16.84602858079018, 16.84602858079018, 16.84602858079018, 15.855668287974769, 15.855668287974769, 14.865307995159352, 13.87494770234394, 13.87494770234394, 12.884587409528526, 12.884587409528526, 12.884587409528526, 11.894227116713113, 11.894227116713113, 11.894227116713113, 11.894227116713113, 11.894227116713113, 11.894227116713113, 11.894227116713113, 11.894227116713113, 48.5375579508834, 81.21944761379206, 25.7592712161289, 11.894227116713113, 48.5375579508834, 24.768910923313484, 40.614675608360095, 21.797830044867247, 27.73999180175973, 48.5375579508834, 39.624315315544685, 34.67251385146761, 34.67251385146761, 42.59539619399092, 384.2696972153085, 24.768910923313484, 124.79530049767023, 101.0266534701003, 73.29656527126875, 122.8145799120394, 159.45791074620968, 95.08449171320783, 95.08449171320783, 725.9439982366262, 26.749631508944315, 76.26764614971498, 140.64106518271683, 97.06521229883866, 76.26764614971498, 187.18799894504124, 83.20016819942288, 85.1808887850537, 255.52285914930476, 241.65781504988897, 66.36404322156085, 81.21944761379206, 180.25547689533335, 68.34476380719167, 169.3615136743638, 172.33259455281006, 164.40971221028676, 108.94953581262362, 285.23366793376715, 86.1712490778691, 158.46755045339427, 119.84349903359316, 89.14232995631535, 114.8916975695161, 211.9470062654266, 131.7278225473781, 150.54466811087096, 108.94953581262362, 101.0266534701003, 96.07485200602324, 93.103771127577, 70.61761924665802, 54.92699422309839, 49.04300983926354, 45.120353583373635, 44.13968951940116, 38.255705135566295, 33.352384815703914, 32.37172075173144, 31.39105668775896, 25.507072303924108, 24.526408239951632, 20.60375198406173, 19.62308792008925, 18.642423856116775, 16.681095728171822, 15.700431664199346, 15.700431664199346, 14.719767600226868, 10.797111344336965, 9.816447280364487, 8.835783216392011, 8.835783216392011, 8.835783216392011, 7.855119152419535, 7.855119152419535, 6.874455088447058, 6.874455088447058, 6.874455088447058, 6.874455088447058, 5.893791024474583, 35.31371294364887, 228.5045335462267, 41.19769732748373, 74.54027550254793, 15.700431664199346, 54.92699422309839, 75.5209395665204, 104.94086148569468, 20.60375198406173, 26.487736367896584, 42.17836139145621, 51.98500203118096, 73.55961143857544, 80.42425988638279, 47.08168171131859, 80.42425988638279, 49.04300983926354, 34.33304887967639, 49.04300983926354, 37.275041071593826, 33.352384815703914, 48.062345775291064, 40.217033263511254, 36.29437700762135, 32.37172075173144, 66.3082059228381, 36.62239518287177, 34.64334113354069, 33.65381410887514, 31.674760059544056, 27.716651960881883, 27.716651960881883, 22.76901683755416, 19.80043576355753, 19.80043576355753, 18.81090873889199, 18.81090873889199, 17.821381714226444, 17.821381714226444, 15.842327664895356, 12.873746590898724, 12.873746590898724, 12.873746590898724, 11.88421956623318, 11.88421956623318, 11.88421956623318, 10.894692541567638, 10.894692541567638, 10.894692541567638, 10.894692541567638, 10.894692541567638, 9.905165516902093, 9.905165516902093, 9.905165516902093, 9.905165516902093, 9.905165516902093, 9.905165516902093, 33.65381410887514, 9.905165516902093, 9.905165516902093, 251.34975953529477, 42.55955733086503, 23.758543862219707, 199.8943542526865, 36.62239518287177, 98.96259773680103, 136.56462467409168, 55.4234086515171, 165.26090838939245, 679.8149612154751, 36.62239518287177, 190.9886110306966, 80.1615842681557, 36.62239518287177, 106.87881393412539, 163.28185434006136, 83.13016534215234, 83.13016534215234, 108.85786798345647, 227.60111094332171, 179.11428673471008, 59.38151675017928, 104.89975988479429, 95.00448963813886, 125.67982740277073, 59.38151675017928, 167.23996243872355, 105.88928690945984, 67.29773294750363, 108.85786798345647, 87.08827344081452, 114.79503013144974, 117.76361120544637, 120.732192279443, 83.13016534215234, 133.59604360009504, 80.1615842681557, 74.22442212016244, 78.18253021882462, 82.14063831748679, 68.0429420211333, 57.19708834438403, 42.40728787608959, 42.40728787608959, 42.40728787608959, 39.4493277824307, 35.50538099088552, 35.50538099088552, 33.53340759511293, 26.631500709908856, 25.645514012022563, 24.659527314136266, 21.701567220477376, 21.701567220477376, 18.74360712681849, 17.757620428932192, 17.757620428932192, 15.785647033159602, 14.799660335273304, 13.813673637387007, 13.813673637387007, 13.813673637387007, 12.82768693950071, 12.82768693950071, 11.841700241614417, 11.841700241614417, 11.841700241614417, 11.841700241614417, 10.85571354372812, 10.85571354372812, 10.85571354372812, 33.53340759511293, 10.85571354372812, 39.4493277824307, 80.86076909365514, 30.575447501454043, 141.9919443626055, 245.52054764066656, 564.9802377558265, 34.51939429299922, 36.49136768877182, 137.06201087317402, 44.379261271862184, 39.4493277824307, 159.73970492455882, 137.06201087317402, 40.435314480317, 132.1320773837425, 63.113008531701816, 52.26715485495255, 168.61358520553546, 71.98688881267847, 86.77668928097292, 57.19708834438403, 68.0429420211333, 63.113008531701816, 74.94484890633737, 49.30919476129367, 53.25314155283885, 56.21110164649773, 56.21110164649773, 43.39327457397589, 55.22511494861144, 51.281168157066254, 47.337221365521074, 48.32320806340737, 45.36524796974848, 46.35123466763478, 45.36524796974848, 42.51981570482354, 25.713564438094874, 24.72496142240495, 24.72496142240495, 21.759152375335184, 20.770549359645262, 17.804740312575497, 17.804740312575497, 16.816137296885575, 16.816137296885575, 16.816137296885575, 15.827534281195655, 14.83893126550573, 14.83893126550573, 14.83893126550573, 13.850328249815808, 13.850328249815808, 12.861725234125885, 12.861725234125885, 12.861725234125885, 11.873122218435963, 11.873122218435963, 10.884519202746041, 10.884519202746041, 10.884519202746041, 10.884519202746041, 10.884519202746041, 10.884519202746041, 10.884519202746041, 9.89591618705612, 9.89591618705612, 28.679373485164643, 44.497021736203386, 17.804740312575497, 26.702167453784796, 303.51101184696296, 15.827534281195655, 159.17497155623434, 18.79334332826542, 38.565403642063856, 40.5426096734437, 44.497021736203386, 106.77901172466849, 126.55107203846691, 43.50841872051347, 421.1547707140637, 36.58819761068401, 95.90437855207934, 63.28047903431191, 45.48562475189331, 197.7304891681413, 166.09519266606378, 32.633785547924326, 37.57680062637394, 68.22349411276153, 28.679373485164643, 61.303273002932066, 77.12092125397082, 45.48562475189331, 129.51688108553668, 106.77901172466849, 68.22349411276153, 243.2062278898777, 235.29740376435834, 61.303273002932066, 66.24628808138168, 123.58526299139714, 110.73342378742818, 87.00695141087004, 72.17790617552122, 86.01834839518013, 108.75621775604833, 63.28047903431191, 91.94996648931965, 73.16650919121113, 61.303273002932066, 57.34886094017238, 66.24628808138168, 66.24628808138168, 65.25768506569176, 125.89241897855055, 93.18279118316305, 91.2003894985941, 65.42916759919788, 63.44676591462895, 59.48196254549105, 43.622749068939534, 41.640347384370585, 34.701941488379305, 33.71074064609483, 30.737138119241422, 29.74593727695695, 29.74593727695695, 29.74593727695695, 29.74593727695695, 28.75473643467248, 28.75473643467248, 26.77233475010354, 25.781133907819072, 25.781133907819072, 24.7899330655346, 23.79873222325013, 23.79873222325013, 22.80753138096566, 22.80753138096566, 22.80753138096566, 22.80753138096566, 22.80753138096566, 22.80753138096566, 22.80753138096566, 108.0508038174301, 82.27958191803388, 37.67554401523271, 36.68434317294824, 93.18279118316305, 76.33237686432705, 32.719539803810356, 105.0772012905767, 71.3763726529047, 58.49076170320658, 95.16519286773199, 59.48196254549105, 72.36757349518918, 166.53165351221384, 437.12948345587415, 439.1118851404431, 68.4027701260513, 76.33237686432705, 173.47005940820512, 273.58134447893656, 144.72523498195548, 128.86602150540398, 123.91001729398161, 1061.5860140950904, 289.44055795548815, 245.82772089497143, 224.02130236471308, 141.75163245510208, 147.6988375088089, 117.96281224027481, 235.91571247212673, 192.30287541161007, 204.1972855190237, 663.1232754967334, 258.71333184466954, 165.54045266992935, 197.25887962303239, 148.69003835109336, 340.98300175428056, 372.7014287073836, 191.3116745693256, 244.83652005268698, 215.1004947841529, 184.37326867333428, 167.5228543544983, 242.85411836811804, 193.29407625389453, 260.6957335292385, 217.0828964687218, 180.4084653041964, 195.27647793846344, 165.54045266992935, 45.03058298949852, 34.26474050124632, 30.34988868733643, 26.435036873426544, 26.435036873426544, 24.477610966471595, 24.477610966471595, 24.477610966471595, 22.52018505951665, 22.52018505951665, 19.58404619908423, 18.605333245606758, 16.647907338651812, 15.66919438517434, 15.66919438517434, 13.711768478219394, 10.775629617786976, 10.775629617786976, 8.81820371083203, 8.81820371083203, 8.81820371083203, 8.81820371083203, 7.8394907573545565, 7.8394907573545565, 6.860777803877084, 6.860777803877084, 6.860777803877084, 5.882064850399612, 5.882064850399612, 5.882064850399612, 5.882064850399612, 83.20038817511997, 5.882064850399612, 5.882064850399612, 11.754342571264447, 11.754342571264447, 42.0944441290661, 12.733055524741921, 17.626620292129285, 36.22216640820127, 26.435036873426544, 13.711768478219394, 147.79544310463316, 44.05187003602105, 23.498898012994125, 29.37117573385896, 21.54147210603918, 23.498898012994125, 44.05187003602105, 80.26424931468755, 22.52018505951665, 36.22216640820127, 55.796425477750724, 59.711277291660615, 93.96623066337216, 37.200879361678744, 54.81771252427325, 44.05187003602105, 43.073157082543574, 36.22216640820127, 36.22216640820127, 35.24345345472379, 35.24345345472379, 26.435036873426544, 28.39246278038149, 27.413749826904013, 25.456323919949067], \"Term\": [\"lord\", \"love\", \"king\", \"good\", \"man\", \"great\", \"caesar\", \"master\", \"god\", \"father\", \"speak\", \"hear\", \"pray\", \"lady\", \"hand\", \"brother\", \"heart\", \"friend\", \"duke\", \"france\", \"eye\", \"son\", \"noble\", \"night\", \"life\", \"make\", \"death\", \"fool\", \"fair\", \"queen\", \"jew\", \"bassanio\", \"lancelet\", \"lorenzo\", \"jessica\", \"nerissa\", \"shylock\", \"gratiano\", \"casket\", \"griffith\", \"packet\", \"bellario\", \"tubal\", \"sola\", \"forfeiture\", \"jacob\", \"lieu\", \"cranmer\", \"belmont\", \"choir\", \"thomas_lovell\", \"monk\", \"miscarried\", \"exaction\", \"bullen\", \"daniel\", \"wolsey\", \"thousand_ducat\", \"gobbo\", \"plea\", \"antonio\", \"cromwell\", \"clerk\", \"canterbury\", \"cardinal\", \"thousand_ducats\", \"bond\", \"christian\", \"judge\", \"choose\", \"venice\", \"venture\", \"ring\", \"ducat\", \"doctor\", \"merchant\", \"portia\", \"conscience\", \"pray\", \"flesh\", \"pound\", \"lady\", \"sad\", \"fair\", \"madam\", \"man\", \"master\", \"fall\", \"swear\", \"devil\", \"lord\", \"state\", \"wife\", \"soul\", \"grace\", \"lose\", \"friend\", \"sweet\", \"hector\", \"troilus\", \"troy\", \"achille\", \"ajax\", \"trojan\", \"cressid\", \"agamemnon\", \"grecian\", \"diome\", \"patroclus\", \"thersite\", \"aenea\", \"ulysse\", \"nestor\", \"greece\", \"menelaus\", \"antenor\", \"pandarus\", \"ilium\", \"mocking\", \"greekish\", \"greek\", \"unarm\", \"calchas\", \"diomed\", \"loo\", \"cassandra\", \"pandar\", \"fumble\", \"helenus\", \"myrmidon\", \"arming\", \"brainsick\", \"priam\", \"helen\", \"pari\", \"tent\", \"paris\", \"hecuba\", \"sweet\", \"praise\", \"yonder\", \"great\", \"lord\", \"field\", \"jove\", \"fight\", \"prince\", \"fool\", \"faith\", \"fair\", \"eye\", \"love\", \"kiss\", \"wit\", \"queen\", \"york\", \"henry\", \"edward\", \"warwick\", \"clarence\", \"suffolk\", \"buckingham\", \"somerset\", \"clifford\", \"protector\", \"hasting\", \"richmond\", \"winchester\", \"duke_humphrey\", \"oxford\", \"humphrey\", \"stanley\", \"catesby\", \"coronation\", \"cade\", \"regent\", \"rutland\", \"succour\", \"dorset\", \"haughty\", \"pomfret\", \"beaufort\", \"ratcliffe\", \"regal\", \"eleanor\", \"mayor\", \"bishop\", \"grey\", \"london\", \"margaret\", \"tower\", \"lewis\", \"richard\", \"lancaster\", \"plantagenet\", \"gloucester\", \"duke\", \"lord\", \"sovereign\", \"crown\", \"king\", \"queen\", \"grace\", \"brother\", \"foe\", \"god\", \"death\", \"die\", \"traitor\", \"soul\", \"fall\", \"prince\", \"head\", \"follow\", \"son\", \"sweet\", \"cassio\", \"othello\", \"handkerchief\", \"posthumus\", \"britain\", \"desdemona\", \"roderigo\", \"cyprus\", \"provost\", \"imogen\", \"pisanio\", \"cloten\", \"briton\", \"emilia\", \"milford\", \"leonatus\", \"barnardine\", \"parolle\", \"angelo\", \"florence\", \"unlawful\", \"florentine\", \"lucio\", \"fidele\", \"cymbeline\", \"vienna\", \"count_rossillion\", \"master_froth\", \"iago\", \"fasten\", \"virginity\", \"moor\", \"lieutenant\", \"italian\", \"mystery\", \"strumpet\", \"err\", \"friar\", \"sense\", \"token\", \"tonight\", \"husband\", \"die\", \"lord\", \"honest\", \"wife\", \"madam\", \"report\", \"faith\", \"love\", \"nature\", \"general\", \"soul\", \"justice\", \"false\", \"devil\", \"death\", \"kill\", \"mistress\", \"lose\", \"lady\", \"ring\", \"bed\", \"free\", \"pleasure\", \"war\", \"point\", \"affair\", \"add\", \"drive\", \"private\", \"merit\", \"tie\", \"start\", \"spur\", \"heed\", \"companion\", \"retire\", \"profit\", \"equal\", \"absence\", \"express\", \"treasure\", \"constant\", \"benefit\", \"vantage\", \"enter\", \"wither\", \"neglect\", \"check\", \"punish\", \"alike\", \"reply\", \"lead\", \"familiar\", \"censure\", \"danger\", \"blame\", \"breed\", \"chance\", \"bold\", \"great\", \"strong\", \"dispatch\", \"receive\", \"greet\", \"twill\", \"half\", \"deliver\", \"suffer\", \"high\", \"prize\", \"fear\", \"true\", \"power\", \"deserve\", \"perceive\", \"state\", \"begin\", \"guard\", \"honour\", \"stand\", \"hear\", \"news\", \"farewell\", \"world\", \"worthy\", \"work\", \"leave\", \"speak\", \"end\", \"time\", \"make\", \"show\", \"peace\", \"ere\", \"hold\", \"turn\", \"lose\", \"good\", \"word\", \"love\", \"lie\", \"set\", \"give\", \"bear\", \"eye\", \"timon\", \"instant\", \"bounty\", \"displeasure\", \"recompense\", \"level\", \"division\", \"flatterer\", \"altogether\", \"apemantus\", \"undone\", \"rot\", \"acknowledge\", \"steward\", \"commendation\", \"unkindness\", \"mankind\", \"stool\", \"description\", \"thinking\", \"sow\", \"bounteous\", \"theft\", \"discovery\", \"fully\", \"alcibiade\", \"bench\", \"surge\", \"rout\", \"husbandry\", \"observe\", \"abhor\", \"borrow\", \"invite\", \"derive\", \"debt\", \"jewel\", \"lordship\", \"deal\", \"quality\", \"mere\", \"beggar\", \"fool\", \"necessity\", \"serve\", \"gold\", \"beloved\", \"heel\", \"fortune\", \"honest\", \"health\", \"god\", \"nature\", \"slave\", \"root\", \"wear\", \"knave\", \"lord\", \"man\", \"feast\", \"enemy\", \"friend\", \"dog\", \"send\", \"poor\", \"fall\", \"breath\", \"master\", \"art\", \"heart\", \"noble\", \"horse\", \"good\", \"live\", \"dost\", \"bad\", \"make\", \"pray\", \"day\", \"talbot\", \"burgundy\", \"edmund\", \"cordelia\", \"orleance\", \"regan\", \"leek\", \"nuncle\", \"lear\", \"dover\", \"pucelle\", \"reignier\", \"cornwall\", \"fluellen\", \"goneril\", \"edgar\", \"cambridge\", \"alanson\", \"monmouth\", \"salic\", \"legitimate\", \"alencon\", \"harfleur\", \"albany\", \"attaint\", \"beadle\", \"replete\", \"fingre\", \"bordeaux\", \"ish\", \"kent\", \"joan\", \"french\", \"dauphin\", \"france\", \"charle\", \"foul_fiend\", \"tom\", \"frenchman\", \"roan\", \"herald\", \"gloucester\", \"english\", \"ransom\", \"knight\", \"duke\", \"captain\", \"daughter\", \"soldier\", \"king\", \"bastard\", \"sword\", \"maintain\", \"father\", \"majesty\", \"town\", \"wear\", \"spirit\", \"base\", \"battle\", \"sister\", \"law\", \"earl\", \"hamlet\", \"madness\", \"phrase\", \"horatio\", \"player\", \"carriage\", \"denmark\", \"property\", \"ophelia\", \"laertes\", \"distemper\", \"laerte\", \"assume\", \"skull\", \"norway\", \"waist\", \"coldly\", \"quantity\", \"impart\", \"distraction\", \"violet\", \"gertrude\", \"disclose\", \"bias\", \"wildly\", \"bearer\", \"arra\", \"pyrrhus\", \"generous\", \"antique\", \"calf\", \"toy\", \"exchange\", \"bore\", \"jump\", \"form\", \"discretion\", \"huge\", \"gait\", \"visage\", \"vouchsafe\", \"fantasy\", \"sense\", \"lord\", \"wench\", \"angel\", \"play\", \"walk\", \"memory\", \"sore\", \"follow\", \"light\", \"hold\", \"brain\", \"soul\", \"shape\", \"mad\", \"father\", \"mark\", \"mother\", \"spirit\", \"matter\", \"heaven\", \"sweet\", \"night\", \"fit\", \"wind\", \"watch\", \"eye\", \"purpose\", \"love\", \"ear\", \"dear\", \"gentleman\", \"make\", \"valentine\", \"sylvia\", \"proteus\", \"dromio\", \"petruchio\", \"lucentio\", \"julia\", \"hortensio\", \"thurio\", \"grumio\", \"baptista\", \"signior_gremio\", \"pisa\", \"antipholus\", \"shrew\", \"beautiful\", \"biondello\", \"goldsmith\", \"vincentio\", \"signior_baptista\", \"eglamour\", \"lucetta\", \"gremio\", \"jail\", \"centaur\", \"choleric\", \"syracusian\", \"cambio\", \"balthazar\", \"litio\", \"epidamium\", \"raiment\", \"cuff\", \"dine\", \"bianca\", \"chain\", \"padua\", \"kate\", \"mistress\", \"master\", \"knock\", \"sister\", \"home\", \"item\", \"katherine\", \"servant\", \"gentleman\", \"wife\", \"love\", \"mad\", \"husband\", \"father\", \"house\", \"long\", \"pray\", \"sweet\", \"daughter\", \"company\", \"today\", \"madam\", \"villain\", \"fair\", \"caesar\", \"antony\", \"brutus\", \"cassius\", \"egypt\", \"mark_antony\", \"cleopatra\", \"ero\", \"casca\", \"charmian\", \"lepidus\", \"octavia\", \"octavius\", \"titinius\", \"fulvia\", \"messala\", \"enobarbus\", \"philippi\", \"cinna\", \"lucilius\", \"agrippa\", \"alexas\", \"menas\", \"pindarus\", \"decius\", \"antonius\", \"isis\", \"tiber\", \"calphurnia\", \"cicero\", \"caius\", \"egyptian\", \"roman\", \"pompey\", \"capitol\", \"rome\", \"madam\", \"lucius\", \"man\", \"noble\", \"street\", \"death\", \"fight\", \"sword\", \"god\", \"heart\", \"friend\", \"die\", \"war\", \"hand\", \"fortune\", \"world\", \"follow\", \"today\", \"post\", \"resolve\", \"stain\", \"depart\", \"wretched\", \"knife\", \"guess\", \"hollow\", \"govern\", \"lamb\", \"plant\", \"chase\", \"swallow\", \"prey\", \"lament\", \"gaze\", \"extreme\", \"sour\", \"renowned\", \"restore\", \"willingly\", \"miserable\", \"tyranny\", \"amiss\", \"back\", \"climb\", \"height\", \"hearted\", \"pitiful\", \"beware\", \"fearful\", \"intend\", \"weep\", \"nought\", \"rule\", \"shalt\", \"breast\", \"bury\", \"ease\", \"troop\", \"tear\", \"burn\", \"rest\", \"possess\", \"fast\", \"gentle\", \"hast\", \"join\", \"groan\", \"strength\", \"desert\", \"age\", \"hand\", \"live\", \"heart\", \"loss\", \"father\", \"life\", \"sorrow\", \"beg\", \"stay\", \"dost\", \"vow\", \"wrong\", \"boy\", \"deed\", \"open\", \"shame\", \"send\", \"kiss\", \"friend\", \"make\", \"sight\", \"art\", \"bear\", \"seek\", \"son\", \"head\", \"word\", \"madam\", \"man\", \"blood\", \"death\", \"leave\", \"poor\", \"bring\", \"stand\", \"percy\", \"hal\", \"wale\", \"westmoreland\", \"davy\", \"francis\", \"poin\", \"doll\", \"instinct\", \"tavern\", \"glendower\", \"mouldy\", \"harry_percy\", \"hotspur\", \"swagger\", \"misuse\", \"shilling\", \"sheriff\", \"worcester\", \"commence\", \"irish\", \"esquire\", \"drawer\", \"colevile\", \"douglas\", \"military\", \"peto\", \"harry_monmouth\", \"swaggerer\", \"gloucestershire\", \"bardolph\", \"leapt\", \"shrewsbury\", \"thousand_pound\", \"scot\", \"sack\", \"harry\", \"pistol\", \"john\", \"prince\", \"mortimer\", \"yea\", \"jack\", \"shallow\", \"lad\", \"rogue\", \"faith\", \"lord\", \"cousin\", \"ride\", \"god\", \"art\", \"horse\", \"master\", \"man\", \"good\", \"sword\", \"head\", \"grace\", \"king\", \"merry\", \"set\", \"father\", \"drink\", \"devil\", \"meet\", \"son\", \"sweet\", \"macbeth\", \"island\", \"thane\", \"naple\", \"banquo\", \"stage\", \"cawdor\", \"horror\", \"grove\", \"potent\", \"middle\", \"shriek\", \"trinculo\", \"stephano\", \"mantle\", \"ariel\", \"sailor\", \"sprite\", \"duncan\", \"macduff\", \"noon\", \"kite\", \"defect\", \"monster\", \"orb\", \"invest\", \"amazement\", \"banner\", \"caliban\", \"consecrate\", \"bake\", \"famine\", \"bottle\", \"horrible\", \"hail\", \"neptune\", \"confine\", \"charm\", \"roar\", \"moon\", \"wood\", \"sleep\", \"pour\", \"asleep\", \"thunder\", \"milan\", \"strange\", \"isle\", \"sea\", \"air\", \"spirit\", \"wake\", \"night\", \"bed\", \"nature\", \"knock\", \"awake\", \"thing\", \"dear\", \"devil\", \"lie\", \"follow\", \"dream\", \"speak\", \"eye\", \"drink\", \"sight\", \"fall\", \"place\", \"fear\", \"draw\", \"play\", \"cry\", \"hast\", \"dead\", \"art\", \"make\", \"romeo\", \"early\", \"juliet\", \"tybalt\", \"livery\", \"gray\", \"hare\", \"cord\", \"stumble\", \"immediately\", \"mercutio\", \"untimely\", \"capulet\", \"enrich\", \"fray\", \"thursday\", \"sullen\", \"loathsome\", \"loving\", \"thumb\", \"philosophy\", \"maidenhead\", \"boisterous\", \"hatred\", \"shaft\", \"mew\", \"airy\", \"visor\", \"pupil\", \"daylight\", \"repay\", \"gallop\", \"scarlet\", \"kinsman\", \"nurse\", \"county\", \"churchyard\", \"slow\", \"mask\", \"tedious\", \"sadness\", \"meantime\", \"spite\", \"tomb\", \"east\", \"bound\", \"hie\", \"night\", \"corse\", \"holy\", \"watch\", \"match\", \"hate\", \"light\", \"banish\", \"haste\", \"love\", \"kindre\", \"tale\", \"bed\", \"dream\", \"slay\", \"dead\", \"deep\", \"lip\", \"day\", \"death\", \"sigh\", \"beauty\", \"lady\", \"wall\", \"fair\", \"lie\", \"sweet\", \"child\", \"good\", \"joy\", \"eye\", \"stay\", \"tomorrow\", \"dear\", \"man\", \"true\", \"time\", \"soul\", \"hour\", \"mother\", \"sleep\", \"martius\", \"tribune\", \"empress\", \"titus\", \"andronicus\", \"lavinia\", \"coriolanus\", \"aufidius\", \"goth\", \"tamora\", \"aaron\", \"bassianus\", \"volsce\", \"cominius\", \"coriole\", \"saturnine\", \"patrician\", \"menenius\", \"caius_martius\", \"volscian\", \"tullus\", \"mildly\", \"tarquin\", \"plebeian\", \"traitorous\", \"titus_lartius\", \"surname\", \"mutius\", \"chiron\", \"popular\", \"consul\", \"rome\", \"marcus\", \"emperor\", \"rape\", \"lucius\", \"roman\", \"people\", \"senate\", \"dishonour\", \"city\", \"revenge\", \"mother\", \"noble\", \"voice\", \"son\", \"war\", \"wound\", \"brother\", \"enemy\", \"country\", \"god\", \"sweet\", \"sword\", \"general\", \"bolingbroke\", \"gaunt\", \"hereford\", \"hubert\", \"ireland\", \"arthur\", \"sceptre\", \"exeter\", \"mowbray\", \"aumerle\", \"pope\", \"gage\", \"christendom\", \"ashe\", \"philip\", \"model\", \"angier\", \"proffer\", \"brittany\", \"mirror\", \"faulconbridge\", \"scroop\", \"peaceful\", \"christ\", \"crew\", \"welshman\", \"unite\", \"helmet\", \"fist\", \"signal\", \"uphold\", \"blanch\", \"depose\", \"jerusalem\", \"meteor\", \"england\", \"castle\", \"robert\", \"majesty\", \"armour\", \"liege\", \"uncle\", \"claim\", \"land\", \"king\", \"colour\", \"arm\", \"english\", \"northumberland\", \"royal\", \"war\", \"subject\", \"field\", \"cousin\", \"day\", \"blood\", \"kingdom\", \"crown\", \"earth\", \"soul\", \"lion\", \"god\", \"tongue\", \"richard\", \"peace\", \"fight\", \"noble\", \"fair\", \"hand\", \"france\", \"lord\", \"mother\", \"horse\", \"face\", \"man\", \"hero\", \"rosalind\", \"beatrice\", \"hermia\", \"pyramus\", \"lysander\", \"thisbe\", \"toby\", \"malvolio\", \"berowne\", \"orlando\", \"helena\", \"leonato\", \"phoebe\", \"costard\", \"signior_benedict\", \"cesario\", \"topas\", \"olivia\", \"jaque\", \"andrew\", \"audrey\", \"armado\", \"dumaine\", \"boyet\", \"chamber_window\", \"wrestle\", \"sonnet\", \"rowland\", \"motley\", \"twelvemonth\", \"benedict\", \"simplicity\", \"demetrius\", \"lover\", \"rhyme\", \"wit\", \"lady\", \"love\", \"cupid\", \"niece\", \"fool\", \"horn\", \"shepherd\", \"sweet\", \"fair\", \"study\", \"eye\", \"youth\", \"sing\", \"man\", \"play\", \"grace\", \"praise\", \"faith\", \"break\", \"word\", \"write\", \"prove\", \"tongue\", \"madam\", \"woo\", \"heart\", \"master\", \"swear\", \"true\", \"letter\", \"day\", \"god\", \"camillo\", \"bohemia\", \"sovereignty\", \"tribute\", \"mingle\", \"prophecy\", \"juno\", \"precedent\", \"paulina\", \"repeat\", \"hermione\", \"allay\", \"blemish\", \"nobleness\", \"polixene\", \"arch\", \"sicilia\", \"verily\", \"flaw\", \"protection\", \"grand\", \"cedar\", \"vine\", \"knell\", \"surprised\", \"deem\", \"beggary\", \"curious\", \"evidence\", \"advancement\", \"justify\", \"oracle\", \"require\", \"pine\", \"design\", \"queen\", \"square\", \"court\", \"settle\", \"commission\", \"dread\", \"rare\", \"highness\", \"business\", \"blessing\", \"king\", \"betwixt\", \"royal\", \"kingdom\", \"perform\", \"son\", \"grace\", \"goodness\", \"garment\", \"feel\", \"continue\", \"tender\", \"comfort\", \"thither\", \"woman\", \"daughter\", \"joy\", \"good\", \"lord\", \"report\", \"prithee\", \"life\", \"honour\", \"boy\", \"dare\", \"long\", \"father\", \"bless\", \"lady\", \"tongue\", \"pity\", \"free\", \"mother\", \"swear\", \"death\", \"respect\", \"claudio\", \"whip\", \"smell\", \"countenance\", \"acquaint\", \"dish\", \"midnight\", \"conclusion\", \"partly\", \"extremity\", \"absent\", \"needful\", \"apprehend\", \"busy\", \"doublet\", \"price\", \"invention\", \"board\", \"corner\", \"isabel\", \"function\", \"assist\", \"bolt\", \"fever\", \"sufferance\", \"shrewd\", \"meddle\", \"instruction\", \"egg\", \"affection\", \"practice\", \"bawd\", \"modest\", \"wisdom\", \"evil\", \"behavior\", \"understand\", \"advise\", \"remedy\", \"catch\", \"fancy\", \"trick\", \"maid\", \"brother\", \"pray\", \"nose\", \"foolish\", \"fault\", \"place\", \"promise\", \"mercy\", \"warrant\", \"good\", \"woman\", \"answer\", \"marry\", \"tomorrow\", \"charge\", \"patience\", \"duke\", \"fellow\", \"hour\", \"man\", \"bring\", \"mistress\", \"young\", \"talk\", \"hear\", \"speak\", \"swear\", \"life\", \"die\", \"meet\", \"matter\", \"hand\", \"head\", \"make\", \"time\", \"poor\", \"bear\", \"daughter\", \"ford\", \"master_brook\", \"gar\", \"basket\", \"mistress_ford\", \"mistress_page\", \"hugh\", \"windsor\", \"mistress_anne\", \"dat\", \"master_slender\", \"buck\", \"master_fenton\", \"anne_page\", \"bully\", \"rugby\", \"wart\", \"nan\", \"vat\", \"robert_shallow\", \"herne\", \"doctor_caius\", \"canary\", \"pless\", \"cheater\", \"thame\", \"parson\", \"fery\", \"jackanape\", \"nostril\", \"brentford\", \"page\", \"discuss\", \"venison\", \"oman\", \"slender\", \"host\", \"cheese\", \"garter\", \"doctor\", \"jealousy\", \"linen\", \"master\", \"humour\", \"falstaff\", \"fairy\", \"william\", \"forsooth\", \"knight\", \"wife\", \"appoint\", \"worship\", \"husband\", \"woman\", \"good\", \"knave\", \"pray\", \"marry\", \"boy\", \"honest\", \"desire\", \"gentleman\", \"heart\", \"shallow\", \"letter\", \"follow\", \"quickly\"], \"Total\": [3000.0, 2442.0, 1549.0, 3013.0, 2845.0, 1017.0, 400.0, 832.0, 1032.0, 1075.0, 1538.0, 1291.0, 760.0, 760.0, 1107.0, 705.0, 1135.0, 866.0, 525.0, 363.0, 998.0, 763.0, 647.0, 661.0, 897.0, 2010.0, 879.0, 493.0, 773.0, 447.0, 73.73724540441057, 39.41852640560487, 26.671573634619897, 23.729969149007978, 18.827295006321446, 17.846760177784137, 17.846760177784137, 16.866225349246832, 15.885690520709522, 10.002481549485681, 10.002481549485681, 9.021946720948375, 9.021946720948375, 9.021946720948375, 9.021946720948375, 8.041411892411064, 8.041411892411064, 8.041411892411064, 7.060877063873759, 7.060877063873759, 7.060877063873759, 7.060877063873759, 6.080342235336453, 6.080342235336453, 6.080342235336453, 6.080342235336453, 6.080342235336453, 6.080342235336453, 6.080342235336453, 6.080342235336453, 68.84547500042201, 17.84784700826989, 22.752676807985388, 14.912990001172991, 94.52716623345981, 15.905160897196133, 90.70841224189017, 81.85681638584325, 105.74676054825392, 151.1141712871475, 43.40783682824841, 41.45938308594364, 233.95076558343501, 32.5758587746894, 66.80609222743561, 37.47040705122868, 24.68923861680439, 123.48066347840376, 760.9927144319755, 133.36997669600845, 54.13464495839648, 760.563984501448, 156.23685880894175, 773.7118107639614, 504.32074227504523, 2845.7952031634472, 832.3807481679085, 546.8695429607455, 461.9802296728193, 263.102561892, 3000.807505565019, 293.47974770057033, 526.9281149359036, 555.5073335486278, 629.2631000596464, 473.2406117973506, 866.9169628186961, 764.2323872456977, 149.04068668113047, 87.34895072539277, 78.53584558885883, 77.55661168479949, 58.951167507672295, 42.304191138663725, 39.366489426485735, 32.511852098070435, 30.55338428995179, 29.574150385892462, 25.65721476965515, 25.65721476965515, 24.67798086559582, 19.781811345299182, 18.802577441239855, 17.823343537180527, 11.947940112824552, 10.968706208765225, 9.989472304705897, 9.989472304705897, 9.010238400646568, 9.010238400646568, 53.086890472072405, 8.031004496587238, 7.05177059252791, 7.05177059252791, 6.072536688468582, 6.072536688468582, 6.072536688468582, 5.0933027844092535, 5.0933027844092535, 5.0933027844092535, 5.0933027844092535, 5.0933027844092535, 25.69804432477666, 61.045900251148595, 20.827803581895015, 97.66965125904277, 41.55861139848218, 12.95167174995679, 764.2323872456977, 222.59829443485273, 50.53297133256804, 1017.4522168603969, 3000.807505565019, 181.15923111255242, 86.88363622665392, 323.0305607099747, 463.8356389080782, 493.3602263660834, 405.2240299170608, 773.7118107639614, 998.9020449742209, 2442.574997314027, 259.64888437516976, 336.9215665216303, 447.73809171042126, 222.5801892101813, 212.69649783480045, 186.9989002588103, 163.27804095789628, 94.09220133023048, 81.2434025422354, 77.28992599208307, 66.41786547916415, 64.44112720408799, 54.557435828707185, 48.62722100347868, 37.755160490559774, 26.883099977640864, 25.89473084010278, 25.89473084010278, 24.9063617025647, 23.917992565026612, 22.92962342748853, 19.96451601487428, 17.987777739798116, 16.99940860226003, 16.99940860226003, 16.011039464721947, 15.022670327183862, 14.03430118964578, 14.03430118964578, 13.045932052107696, 12.057562914569614, 12.057562914569614, 12.057562914569614, 21.934506811435423, 28.846343295686978, 18.969399398821174, 63.39620503034778, 75.27268624292655, 69.44600038261699, 22.916128470458478, 173.23611842439047, 63.378804096131724, 42.70742716239734, 132.27423385440437, 525.1957776163629, 3000.807505565019, 150.4929757918821, 346.2232609385679, 1549.9815156471925, 447.73809171042126, 629.2631000596464, 705.102039759219, 128.64860678455534, 1032.8765292190787, 879.4795390333236, 681.798063905326, 189.8371486407471, 555.5073335486278, 546.8695429607455, 463.8356389080782, 598.3968311948047, 447.0382814408101, 763.4042368056765, 764.2323872456977, 110.43498762425544, 33.66219619487027, 32.67792963808328, 29.725129967722317, 29.725129967722317, 29.725129967722317, 28.740863410935326, 23.819530627000375, 23.819530627000375, 23.819530627000375, 21.850997513426396, 19.882464399852417, 18.898197843065425, 18.898197843065425, 17.913931286278437, 16.929664729491446, 15.945398172704454, 12.992598502343483, 76.97685897899527, 12.008331945556494, 11.024065388769502, 11.024065388769502, 11.024065388769502, 10.039798831982512, 10.039798831982512, 10.039798831982512, 10.039798831982512, 10.039798831982512, 9.055532275195523, 9.055532275195523, 24.807237465985978, 75.92801825167862, 44.50790765366218, 13.984675139342658, 21.875011353400886, 28.791920731983495, 23.85487352860021, 83.11317973932827, 127.31962048777368, 41.559283415998145, 183.6502314745855, 343.1410859997841, 681.798063905326, 3000.807505565019, 286.38691196379693, 526.9281149359036, 504.32074227504523, 177.02802194080056, 405.2240299170608, 2442.574997314027, 386.62689012852826, 201.38505996864586, 555.5073335486278, 170.6026112927869, 272.6544240107058, 263.102561892, 879.4795390333236, 358.23966865084833, 319.0101154208791, 473.2406117973506, 760.563984501448, 233.95076558343501, 299.59995070705486, 191.9429368265216, 199.954378834432, 391.80118861529115, 174.86838153951155, 77.60825465889167, 70.6611027388474, 69.66865246455536, 66.69130164167925, 63.713950818803156, 59.74414972163499, 54.78189835017479, 53.78944807588275, 52.79699780159071, 51.80454752729867, 51.80454752729867, 49.819646978714594, 48.827196704422555, 48.827196704422555, 47.834746430130515, 46.842296155838476, 45.849845881546436, 44.8573956072544, 43.86494533296236, 43.86494533296236, 41.88004478437828, 40.88759451008624, 40.88759451008624, 39.8951442357942, 39.8951442357942, 38.90269396150216, 240.3616682724782, 37.91024368721012, 37.91024368721012, 117.30241837197114, 86.53738387789352, 125.22131667239442, 123.23567316540161, 141.1124552061006, 1017.4522168603969, 221.47080730233205, 91.47872760747074, 188.67850203196022, 67.67728833956555, 62.716751974632736, 189.72025153370933, 178.660047329822, 135.03191547408377, 296.8144035280108, 59.73909926242658, 756.7472162397902, 770.7363136087544, 397.8811029649, 172.64517207583285, 108.31444268697884, 293.47974770057033, 236.22721790878606, 105.36652901929205, 710.6786588523053, 808.687069999357, 1291.0203347602935, 314.5597942003865, 342.4266818951729, 646.5643892293331, 261.86282528573435, 253.0478984707026, 881.6021398673589, 1538.2517604345894, 383.85858162288406, 1207.6625287513486, 2010.483865654035, 578.2986597468337, 530.243622154913, 355.22304856590983, 620.7797669782948, 436.1116354160329, 473.2406117973506, 3013.7609435622926, 899.3244040514843, 2442.574997314027, 802.8723946460216, 489.8178657487701, 561.9411620964902, 896.75348080632, 998.9020449742209, 99.22413494217383, 59.613334270949366, 42.77874398567895, 42.77874398567895, 28.91496375075038, 25.944153700408542, 24.95388368362793, 24.95388368362793, 23.96361366684732, 22.973343650066706, 22.973343650066706, 22.973343650066706, 21.983073633286093, 21.983073633286093, 21.983073633286093, 20.99280361650548, 19.012263582944254, 19.012263582944254, 18.021993566163644, 17.03172354938303, 17.03172354938303, 16.041453532602418, 15.0511835158218, 15.0511835158218, 13.070643482260575, 13.070643482260575, 13.070643482260575, 13.070643482260575, 13.070643482260575, 12.080373465479962, 42.77446066678464, 41.788564244933134, 49.691163726656626, 34.854015539067106, 32.8741429386303, 57.6033157791964, 78.38991471973213, 125.9253086896423, 76.43081664303699, 74.46366394608985, 58.60297284228988, 96.26256251177921, 493.3602263660834, 48.71036207981848, 282.6245528449652, 208.93384260094982, 41.74790424646861, 87.14340380668783, 456.4312908377468, 286.38691196379693, 104.1539382547399, 1032.8765292190787, 386.62689012852826, 157.35644779493515, 58.60215458250092, 301.9004488239721, 214.26931721440442, 3000.807505565019, 2845.7952031634472, 119.87224928474353, 268.8839494319596, 866.9169628186961, 203.6020290696301, 565.8292539213743, 607.7515960661674, 546.8695429607455, 207.03937619420887, 832.3807481679085, 876.6437644834292, 1135.9134607740086, 647.648766953518, 293.3946086649358, 3013.7609435622926, 772.654057495504, 397.56091268690784, 336.221357363251, 2010.483865654035, 760.9927144319755, 918.7812815352927, 91.48794755325694, 40.44362128405797, 39.46199962503491, 20.811188103596827, 20.811188103596827, 17.866323126527654, 17.866323126527654, 16.8847014675046, 16.8847014675046, 13.93983649043542, 12.958214831412361, 12.958214831412361, 12.958214831412361, 11.976593172389306, 10.994971513366247, 10.994971513366247, 10.994971513366247, 10.994971513366247, 9.031728195320133, 9.031728195320133, 8.050106536297074, 8.050106536297074, 8.050106536297074, 8.050106536297074, 8.050106536297074, 8.050106536297074, 7.068484877274016, 7.068484877274016, 7.068484877274016, 7.068484877274016, 32.601476627142496, 20.819918181323303, 148.58177122731064, 70.01875690502948, 363.4010726866592, 51.29383999967047, 12.957257236361782, 16.9021787350893, 28.678833822458795, 14.926252639380504, 38.601526482824774, 132.27423385440437, 141.18609547708658, 60.380413301586714, 159.27778021089802, 525.1957776163629, 138.33151444569845, 451.7899301798348, 264.16223768268196, 1549.9815156471925, 77.06597033528108, 391.22917090636275, 56.446485820943835, 1075.8274867502391, 269.0095539463107, 148.9292156030594, 301.9004488239721, 359.0594726266185, 157.6826970337464, 116.5862289084754, 219.2320368702583, 251.4837970235413, 93.8017078278425, 78.20171865571942, 66.35292087471585, 31.793927346788795, 30.80652753170517, 28.831727901537906, 27.844328086454276, 21.919929195952495, 18.957729750701603, 18.957729750701603, 17.97032993561797, 17.97032993561797, 15.995530305450707, 15.995530305450707, 15.008130490367074, 15.008130490367074, 14.020730675283446, 14.020730675283446, 14.020730675283446, 13.033330860199813, 13.033330860199813, 13.033330860199813, 13.033330860199813, 12.045931045116184, 12.045931045116184, 11.058531230032552, 11.058531230032552, 11.058531230032552, 11.058531230032552, 10.071131414948923, 10.071131414948923, 22.898642149429968, 27.84626673136318, 32.772042876900784, 25.870132234947093, 17.965086192829006, 122.65501872657029, 34.74764808885568, 31.742544581967714, 31.79853023262292, 37.717010954292284, 51.5737185410465, 18.96365070616517, 127.31962048777368, 3000.807505565019, 80.05986312343803, 86.04321044030839, 373.2659252703888, 176.95023219712922, 51.589052240240186, 48.66933109419159, 447.0382814408101, 298.8376778527507, 620.7797669782948, 122.7394264227239, 555.5073335486278, 112.98628439086063, 248.41826805587425, 1075.8274867502391, 235.06783062682788, 418.7986937923723, 359.0594726266185, 376.78588038763536, 261.6088339396846, 764.2323872456977, 661.6551877450263, 219.27139864832995, 233.90512968931773, 150.5434267930423, 998.9020449742209, 262.9252969733254, 2442.574997314027, 348.8704157815769, 476.4278457742167, 453.90058422573276, 2010.483865654035, 62.07296581867653, 53.23356116802454, 50.28709295114055, 37.5190640113099, 34.5725957944259, 33.59043972213124, 31.626127577541908, 30.643971505247244, 23.768878999184587, 22.786722926889922, 19.84025471000593, 13.947318276237931, 13.947318276237931, 13.947318276237931, 13.947318276237931, 13.947318276237931, 11.983006131648601, 11.000850059353935, 11.000850059353935, 11.000850059353935, 11.000850059353935, 10.01869398705927, 9.036537914764605, 9.036537914764605, 9.036537914764605, 9.036537914764605, 8.054381842469937, 8.054381842469937, 8.054381842469937, 7.0722257701752715, 7.0722257701752715, 7.0722257701752715, 7.0722257701752715, 26.73593562006333, 44.40681942432651, 75.81357190360357, 29.655330457923142, 109.24861415224464, 319.0101154208791, 832.3807481679085, 102.62599676004476, 219.2320368702583, 331.26834624897873, 28.698287677551974, 39.46723573409579, 159.16914643953515, 453.90058422573276, 526.9281149359036, 2442.574997314027, 248.41826805587425, 343.1410859997841, 1075.8274867502391, 456.22471054571065, 520.5028006196288, 760.9927144319755, 764.2323872456977, 451.7899301798348, 207.647328936647, 161.7467575364875, 504.32074227504523, 294.99919268133766, 773.7118107639614, 400.2694856310905, 151.8137949190798, 151.8137949190798, 75.51637808625757, 45.19304575526416, 42.258529723232535, 33.45498162713767, 26.607777552397224, 25.62960554172001, 24.651433531042805, 23.673261520365596, 22.69508950968839, 21.716917499011185, 18.78240146697956, 17.80422945630235, 17.80422945630235, 13.891541413593519, 13.891541413593519, 12.913369402916313, 10.957025381561897, 9.97885337088469, 9.97885337088469, 9.000681360207484, 9.000681360207484, 9.000681360207484, 8.022509349530274, 8.022509349530274, 8.022509349530274, 8.022509349530274, 8.022509349530274, 31.52355813873595, 13.909997022406367, 138.3112748733346, 89.53944741209347, 37.412526629161334, 297.1709893706844, 504.32074227504523, 78.59044910282427, 2845.7952031634472, 647.648766953518, 73.09698722694627, 879.4795390333236, 323.0305607099747, 391.22917090636275, 1032.8765292190787, 1135.9134607740086, 866.9169628186961, 681.798063905326, 391.80118861529115, 1107.9548372584245, 456.4312908377468, 646.5643892293331, 447.0382814408101, 161.7467575364875, 78.57118758704745, 75.59495767604992, 72.6187277650524, 68.65042121705568, 61.70588475806147, 56.745501573065596, 51.78511838806971, 47.816811840073015, 46.82473520307385, 46.82473520307385, 44.84058192907549, 42.85642865507714, 42.85642865507714, 42.85642865507714, 41.864352018077966, 41.864352018077966, 37.89604547008127, 35.91189219608292, 34.919815559083744, 34.919815559083744, 33.927738922084565, 33.927738922084565, 33.927738922084565, 31.943585648086223, 31.943585648086223, 31.943585648086223, 31.943585648086223, 29.959432374087875, 29.959432374087875, 28.967355737088695, 89.48148098170473, 88.47859027351748, 240.26341983594594, 72.61405094313685, 90.45519727508531, 278.9389464351917, 96.41744455464931, 93.41809942295498, 58.72159711404885, 56.74179407360451, 364.96178363506147, 178.59720003818205, 352.2137170279851, 76.5768048745033, 141.99881803128036, 370.9376494594503, 563.0178393969167, 84.50510991173704, 68.60870733808979, 121.0626492226231, 58.72223984814176, 201.5279996995775, 1107.9548372584245, 772.654057495504, 1135.9134607740086, 126.0633332146313, 1075.8274867502391, 897.1342337997241, 227.18720198402724, 119.02910311020084, 499.8924020064798, 397.56091268690784, 156.6534120087844, 355.037276034132, 433.3595062373893, 254.47206950326785, 184.48689268591258, 323.40135282979446, 565.8292539213743, 259.64888437516976, 866.9169628186961, 2010.483865654035, 200.3332421881009, 876.6437644834292, 896.75348080632, 304.6499317152331, 763.4042368056765, 598.3968311948047, 899.3244040514843, 504.32074227504523, 2845.7952031634472, 655.5806911555019, 879.4795390333236, 881.6021398673589, 607.7515960661674, 667.415523392676, 808.687069999357, 41.525927231443596, 41.525927231443596, 33.65377599957103, 29.717700383634746, 25.781624767698464, 25.781624767698464, 19.877511343794037, 18.893492439809965, 14.95741682387368, 13.97339791988961, 13.97339791988961, 12.98937901590554, 12.005360111921469, 12.005360111921469, 12.005360111921469, 11.021341207937397, 11.021341207937397, 11.021341207937397, 10.037322303953326, 9.053303399969256, 9.053303399969256, 9.053303399969256, 9.053303399969256, 9.053303399969256, 9.053303399969256, 8.069284495985185, 8.069284495985185, 8.069284495985185, 8.069284495985185, 8.069284495985185, 60.21167450612775, 8.069284495985185, 17.915814924657237, 16.92359180015242, 24.79999331209277, 58.23646611006455, 94.83920790839058, 35.57406025297979, 99.64135849611651, 463.8356389080782, 37.64923635645586, 163.223160432376, 68.12899338037872, 86.70933245739107, 47.497335065735896, 98.77325956594217, 405.2240299170608, 3000.807505565019, 286.5912757417242, 65.42401909169227, 1032.8765292190787, 876.6437644834292, 293.3946086649358, 832.3807481679085, 2845.7952031634472, 3013.7609435622926, 391.22917090636275, 598.3968311948047, 629.2631000596464, 1549.9815156471925, 172.88925130064513, 489.8178657487701, 1075.8274867502391, 187.06857404251653, 263.102561892, 473.77182019935935, 763.4042368056765, 764.2323872456977, 41.680604849486706, 30.815886100936353, 29.828184396522687, 29.828184396522687, 25.87737757886801, 20.938869056799668, 20.938869056799668, 19.951167352385998, 19.951167352385998, 19.951167352385998, 18.963465647972328, 17.97576394355866, 16.98806223914499, 16.98806223914499, 16.98806223914499, 16.98806223914499, 16.00036053473132, 16.00036053473132, 16.00036053473132, 16.00036053473132, 16.00036053473132, 15.012658830317651, 15.012658830317651, 92.05596008695078, 14.024957125903981, 13.037255421490313, 12.049553717076645, 12.049553717076645, 12.049553717076645, 11.061852012662975, 11.061852012662975, 11.061852012662975, 25.879202899119885, 24.89150119470622, 70.2805208775158, 18.959782847542733, 40.701727857002375, 66.42913366576124, 65.34304531058561, 135.35738419933313, 62.4043097036081, 361.2941203539355, 39.70248443668902, 45.60624222848023, 54.59518275036682, 26.84289675480567, 256.3670568877944, 41.68794661385526, 258.6794187758665, 187.02635094568873, 359.0594726266185, 109.97558622772405, 661.6551877450263, 299.59995070705486, 386.62689012852826, 102.62599676004476, 90.18653309463276, 318.9739946894487, 476.4278457742167, 263.102561892, 802.8723946460216, 447.0382814408101, 184.18553860194865, 1538.2517604345894, 998.9020449742209, 187.06857404251653, 200.3332421881009, 546.8695429607455, 455.242956769044, 756.7472162397902, 339.1804363684768, 373.2659252703888, 348.9457083221533, 563.0178393969167, 500.6722817954743, 876.6437644834292, 2010.483865654035, 129.93433162293178, 50.70550819769868, 49.71514790488327, 46.74406702643703, 23.965780291682535, 23.965780291682535, 21.985059706051707, 20.994699413236294, 20.00433912042088, 20.00433912042088, 19.013978827605467, 19.013978827605467, 18.023618534790057, 18.023618534790057, 17.03325824197464, 17.03325824197464, 17.03325824197464, 16.04289794915923, 16.04289794915923, 15.052537656343812, 14.0621773635284, 14.0621773635284, 13.071817070712987, 13.071817070712987, 13.071817070712987, 12.081456777897573, 12.081456777897573, 12.081456777897573, 12.081456777897573, 12.081456777897573, 12.081456777897573, 12.081456777897573, 12.081456777897573, 50.68803093011397, 86.3099975948389, 26.934870014851445, 12.081456777897573, 52.67919967482754, 25.948590858789984, 43.74350975515647, 22.974586730717252, 29.890464780990303, 55.64337157483443, 44.76754918815149, 38.772431555360896, 38.818129495944255, 49.62982992991583, 661.6551877450263, 26.933346615877788, 193.1928639473336, 150.5434267930423, 105.03412821983667, 212.02392119484992, 298.8376778527507, 153.4074946418727, 157.5595959451267, 2442.574997314027, 29.896536270315035, 127.71551768822607, 299.59995070705486, 184.18553860194865, 132.6679109527746, 500.6722817954743, 154.53557932470423, 163.29809265271533, 918.7812815352927, 879.4795390333236, 116.76101159375568, 167.14867942643278, 760.563984501448, 123.7214183981815, 773.7118107639614, 802.8723946460216, 764.2323872456977, 329.70538862131275, 3013.7609435622926, 210.77353874202598, 998.9020449742209, 499.8924020064798, 231.07128006417904, 476.4278457742167, 2845.7952031634472, 770.7363136087544, 1207.6625287513486, 555.5073335486278, 430.2110375416151, 418.7986937923723, 361.2941203539355, 70.80494587013091, 55.114320846571275, 49.230336462736425, 45.30768020684652, 44.327016142874044, 38.44303175903918, 33.5397114391768, 32.55904737520432, 31.578383311231853, 25.694398927397, 24.713734863424524, 20.791078607534622, 19.810414543562143, 18.829750479589666, 16.868422351644714, 15.887758287672236, 15.887758287672236, 14.907094223699758, 10.984437967809855, 10.003773903837377, 9.023109839864901, 9.023109839864901, 9.023109839864901, 8.042445775892423, 8.042445775892423, 7.061781711919947, 7.061781711919947, 7.061781711919947, 7.061781711919947, 6.081117647947472, 36.49130958390237, 297.1709893706844, 51.166744057728685, 101.43030441357647, 17.859731683444828, 78.59044910282427, 138.3112748733346, 209.96776647287757, 36.53861482719717, 61.33028030962289, 142.35799439040633, 210.28445059446267, 418.7986937923723, 647.648766953518, 208.82765463376538, 763.4042368056765, 391.80118861529115, 175.964440984835, 705.102039759219, 268.8839494319596, 175.34580738983053, 1032.8765292190787, 764.2323872456977, 391.22917090636275, 201.38505996864586, 66.49544391670406, 36.80963317673773, 34.830579127406644, 33.841052102741095, 31.861998053410016, 27.903889954747843, 27.903889954747843, 22.95625483142012, 19.98767375742349, 19.98767375742349, 18.99814673275795, 18.99814673275795, 18.008619708092404, 18.008619708092404, 16.029565658761314, 13.060984584764682, 13.060984584764682, 13.060984584764682, 12.071457560099137, 12.071457560099137, 12.071457560099137, 11.081930535433596, 11.081930535433596, 11.081930535433596, 11.081930535433596, 11.081930535433596, 10.092403510768051, 10.092403510768051, 10.092403510768051, 10.092403510768051, 10.092403510768051, 10.092403510768051, 34.82845191782473, 10.092403510768051, 10.092403510768051, 304.9079616337628, 48.632810366410396, 25.903207763040612, 269.0095539463107, 43.693131269788395, 138.654273123726, 204.89165330790414, 72.30516222130593, 278.2472432362603, 1549.9815156471925, 48.64319917837945, 391.9295525336023, 141.18609547708658, 51.57616784929533, 211.85776756699906, 391.80118861529115, 157.54028960322992, 181.15923111255242, 286.5912757417242, 918.7812815352927, 655.5806911555019, 122.83934774820025, 346.2232609385679, 301.6574906634746, 555.5073335486278, 127.61411230271538, 1032.8765292190787, 474.95215209054606, 173.23611842439047, 530.243622154913, 323.0305607099747, 647.648766953518, 773.7118107639614, 1107.9548372584245, 363.4010726866592, 3000.807505565019, 418.7986937923723, 293.3946086649358, 470.8484509232212, 2845.7952031634472, 68.23021541826705, 57.38436174151778, 42.59456127322334, 42.59456127322334, 42.59456127322334, 39.63660117956445, 35.69265438801927, 35.69265438801927, 33.72068099224668, 26.818774107042607, 25.832787409156314, 24.846800711270017, 21.888840617611127, 21.888840617611127, 18.93088052395224, 17.944893826065943, 17.944893826065943, 15.972920430293353, 14.986933732407055, 14.000947034520758, 14.000947034520758, 14.000947034520758, 13.014960336634461, 13.014960336634461, 12.028973638748168, 12.028973638748168, 12.028973638748168, 12.028973638748168, 11.042986940861871, 11.042986940861871, 11.042986940861871, 34.71188183453115, 11.042986940861871, 47.48191369134425, 121.57968480339159, 39.66775931340576, 336.9215665216303, 760.563984501448, 2442.574997314027, 52.432202977692434, 58.37589977048895, 493.3602263660834, 88.63581024732767, 74.23770672871171, 764.2323872456977, 773.7118107639614, 88.19230610222827, 998.9020449742209, 261.58326795969873, 170.42721592090868, 2845.7952031634472, 373.2659252703888, 629.2631000596464, 222.59829443485273, 405.2240299170608, 418.84382620793974, 899.3244040514843, 187.96614338890512, 287.4651506523018, 474.95215209054606, 504.32074227504523, 132.30776019771488, 1135.9134607740086, 832.3807481679085, 461.9802296728193, 770.7363136087544, 323.3706718335029, 918.7812815352927, 1032.8765292190787, 42.70706293877925, 25.90081167205059, 24.912208656360665, 24.912208656360665, 21.9463996092909, 20.95779659360098, 17.991987546531213, 17.991987546531213, 17.00338453084129, 17.00338453084129, 17.00338453084129, 16.01478151515137, 15.026178499461444, 15.026178499461444, 15.026178499461444, 14.037575483771523, 14.037575483771523, 13.0489724680816, 13.0489724680816, 13.0489724680816, 12.060369452391678, 12.060369452391678, 11.071766436701756, 11.071766436701756, 11.071766436701756, 11.071766436701756, 11.071766436701756, 11.071766436701756, 11.071766436701756, 10.083163421011834, 10.083163421011834, 29.856890735900972, 50.58986831088104, 18.979387361614844, 29.827116399918495, 447.73809171042126, 16.99640317417443, 249.77370248484058, 20.94383388026725, 49.57958300067646, 53.58859781109023, 61.42293443235219, 187.08976557843326, 235.52202217546443, 63.40627336406469, 1549.9815156471925, 53.50426151797477, 211.85776756699906, 122.83934774820025, 81.28168205264132, 763.4042368056765, 629.2631000596464, 49.55356424725887, 62.425832877575594, 167.42538231553965, 40.67148794708726, 141.64494058046853, 215.02688338343114, 89.2487248697272, 564.7140943475177, 451.7899301798348, 210.77353874202598, 3013.7609435622926, 3000.807505565019, 177.02802194080056, 212.68377967916956, 897.1342337997241, 710.6786588523053, 433.3595062373893, 319.1125259420014, 520.5028006196288, 1075.8274867502391, 222.96145303950672, 760.563984501448, 474.95215209054606, 235.94786702923153, 191.9429368265216, 418.7986937923723, 461.9802296728193, 879.4795390333236, 126.07964023424032, 93.37001243885281, 91.38761075428387, 65.61638885488765, 63.63398717031871, 59.669183801180814, 43.8099703246293, 41.82756864006035, 34.88916274406907, 33.89796190178459, 30.924359374931193, 29.933158532646722, 29.933158532646722, 29.933158532646722, 29.933158532646722, 28.94195769036225, 28.94195769036225, 26.95955600579331, 25.968355163508843, 25.968355163508843, 24.977154321224372, 23.9859534789399, 23.9859534789399, 22.99475263665543, 22.99475263665543, 22.99475263665543, 22.99475263665543, 22.99475263665543, 22.99475263665543, 22.99475263665543, 110.20655818669384, 87.37491146883893, 38.85046697533615, 37.85222849261048, 103.2384011005293, 83.43533537116437, 33.88729588803743, 121.05968632930791, 79.48575404283937, 64.63268460464859, 114.11874650728147, 67.55707738427118, 85.39099234696614, 225.15013204401296, 705.102039759219, 760.9927144319755, 81.44183058571005, 93.3849009490028, 255.00756489782722, 455.242956769044, 208.24005877819056, 181.29431749663314, 183.183093711923, 3013.7609435622926, 564.7140943475177, 459.3486109583492, 429.29131319338205, 231.07128006417904, 245.82689963006266, 181.64293826391182, 525.1957776163629, 387.75053997796897, 430.2110375416151, 2845.7952031634472, 667.415523392676, 319.0101154208791, 452.2827871179118, 273.7749415237436, 1291.0203347602935, 1538.2517604345894, 461.9802296728193, 897.1342337997241, 681.798063905326, 473.77182019935935, 376.78588038763536, 1107.9548372584245, 598.3968311948047, 2010.483865654035, 1207.6625287513486, 607.7515960661674, 896.75348080632, 451.7899301798348, 45.217929124076356, 34.45208663582416, 30.53723482191427, 26.622383008004384, 26.622383008004384, 24.664957101049435, 24.664957101049435, 24.664957101049435, 22.70753119409449, 22.70753119409449, 19.77139233366207, 18.792679380184598, 16.835253473229653, 15.85654051975218, 15.85654051975218, 13.899114612797234, 10.962975752364816, 10.962975752364816, 9.00554984540987, 9.00554984540987, 9.00554984540987, 9.00554984540987, 8.026836891932396, 8.026836891932396, 7.048123938454923, 7.048123938454923, 7.048123938454923, 6.069410984977451, 6.069410984977451, 6.069410984977451, 6.069410984977451, 89.27094328092164, 6.069410984977451, 6.069410984977451, 12.932889548126756, 13.906000850431617, 70.77574762780137, 15.862888371422487, 24.71230795392863, 66.80609222743561, 44.34434145346812, 17.849921430451907, 832.3807481679085, 123.13201902516374, 44.35064113123745, 65.11578322732888, 39.51946271630252, 47.43238343833458, 159.27778021089802, 526.9281149359036, 45.525293845075524, 120.66158413695908, 343.1410859997841, 564.7140943475177, 3013.7609435622926, 214.26931721440442, 760.9927144319755, 429.29131319338205, 433.3595062373893, 286.38691196379693, 318.8534421655706, 453.90058422573276, 1135.9134607740086, 86.70933245739107, 323.3706718335029, 447.0382814408101, 108.89173855653469], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 3.993, 3.9907, 3.9885, 3.9876, 3.9855, 3.9849, 3.9849, 3.9843, 3.9836, 3.9766, 3.9766, 3.9745, 3.9745, 3.9745, 3.9745, 3.9719, 3.9719, 3.9719, 3.9686, 3.9686, 3.9686, 3.9686, 3.9642, 3.9642, 3.9642, 3.9642, 3.9642, 3.9642, 3.9642, 3.9642, 3.9636, 3.9278, 3.8962, 3.9134, 3.6898, 3.849, 3.4937, 3.4831, 3.2468, 3.1476, 3.4637, 3.4296, 2.8249, 3.4885, 3.2084, 3.3973, 3.5427, 2.7976, 1.83, 2.6665, 3.0759, 1.6186, 2.4511, 1.4519, 1.624, 0.3662, 1.1836, 1.456, 1.5782, 1.93, 0.0637, 1.8207, 1.3466, 1.2938, 1.1691, 1.3719, 0.7376, 0.803, 4.1644, 4.1635, 4.1632, 4.1632, 4.1624, 4.1612, 4.1609, 4.1598, 4.1595, 4.1593, 4.1583, 4.1583, 4.158, 4.1561, 4.1556, 4.1551, 4.1498, 4.1484, 4.1467, 4.1467, 4.1446, 4.1446, 4.1432, 4.142, 4.1387, 4.1387, 4.1343, 4.1343, 4.1343, 4.1281, 4.1281, 4.1281, 4.1281, 4.1281, 3.9432, 3.6709, 3.8171, 3.301, 3.4625, 3.887, 1.7964, 2.2949, 3.1129, 1.2973, 0.6268, 2.3129, 2.7716, 1.8935, 1.5889, 1.499, 1.637, 1.1573, 0.9518, 0.0576, 1.8815, 1.621, 1.3366, 3.2538, 3.2538, 3.2537, 3.2535, 3.2527, 3.2524, 3.2523, 3.2519, 3.2518, 3.2512, 3.2508, 3.2497, 3.2477, 3.2474, 3.2474, 3.2471, 3.2468, 3.2465, 3.2453, 3.2442, 3.2436, 3.2436, 3.2429, 3.2421, 3.2412, 3.2412, 3.2402, 3.239, 3.239, 3.239, 3.1999, 3.1772, 3.1911, 3.0256, 2.9996, 2.9729, 3.1561, 2.7519, 2.9442, 3.0153, 2.7403, 2.3683, 1.8128, 2.5467, 2.248, 1.6206, 1.901, 1.666, 1.5825, 2.3934, 1.2517, 1.3, 1.2401, 2.0574, 1.254, 1.173, 1.2933, 1.0684, 1.2676, 0.7325, 0.7151, 3.6933, 3.6894, 3.6892, 3.6886, 3.6886, 3.6886, 3.6884, 3.6871, 3.6871, 3.6871, 3.6863, 3.6855, 3.685, 3.685, 3.6844, 3.6838, 3.6831, 3.6804, 3.6795, 3.6792, 3.6778, 3.6778, 3.6778, 3.6761, 3.6761, 3.6761, 3.6761, 3.6761, 3.6741, 3.6741, 3.6039, 3.4603, 3.3802, 3.6069, 3.4847, 3.4105, 3.4521, 3.0658, 2.8756, 3.1304, 2.3981, 2.0896, 1.7394, 0.9658, 2.1328, 1.7026, 1.7045, 2.3097, 1.7524, 0.6058, 1.7649, 2.1808, 1.4865, 2.2536, 1.9213, 1.9354, 1.0431, 1.6899, 1.7427, 1.3909, 0.8739, 1.8878, 1.6658, 2.0597, 1.9922, 1.3462, 1.711, 1.7097, 1.7094, 1.7094, 1.7093, 1.7091, 1.7089, 1.7086, 1.7086, 1.7085, 1.7084, 1.7084, 1.7083, 1.7082, 1.7082, 1.7081, 1.7081, 1.708, 1.7079, 1.7078, 1.7078, 1.7076, 1.7075, 1.7075, 1.7074, 1.7074, 1.7072, 1.7072, 1.7071, 1.7071, 1.702, 1.6984, 1.6867, 1.6863, 1.6823, 1.6338, 1.6702, 1.6883, 1.6575, 1.6946, 1.6932, 1.6238, 1.6189, 1.6353, 1.5721, 1.6922, 1.4707, 1.4457, 1.5083, 1.5903, 1.6347, 1.5158, 1.5381, 1.6321, 1.3747, 1.3495, 1.2759, 1.4748, 1.4482, 1.3399, 1.4694, 1.4743, 1.2272, 1.0911, 1.3855, 1.1257, 0.9777, 1.266, 1.2805, 1.3925, 1.232, 1.2965, 1.2652, 0.6033, 0.9942, 0.5383, 0.919, 1.1524, 1.0396, 0.7109, 0.4468, 2.6072, 2.606, 2.6047, 2.6047, 2.6026, 2.6019, 2.6016, 2.6016, 2.6013, 2.6009, 2.6009, 2.6009, 2.6006, 2.6006, 2.6006, 2.6001, 2.5992, 2.5992, 2.5987, 2.5981, 2.5981, 2.5974, 2.5966, 2.5966, 2.5947, 2.5947, 2.5947, 2.5947, 2.5947, 2.5935, 2.5813, 2.5805, 2.5649, 2.5748, 2.5727, 2.5162, 2.4863, 2.4459, 2.4826, 2.4636, 2.48, 2.4018, 2.1819, 2.4749, 2.1756, 2.199, 2.4789, 2.3366, 1.9934, 2.0895, 2.2843, 1.7905, 1.9698, 2.1659, 2.4, 1.9519, 2.028, 1.252, 1.2645, 2.1697, 1.8649, 1.3835, 1.918, 1.4596, 1.3601, 1.3514, 1.8412, 1.0954, 1.0544, 0.8872, 1.1695, 1.6184, 0.1336, 0.9734, 1.3932, 1.473, -0.03, 0.6653, 0.4208, 3.9733, 3.9707, 3.9706, 3.9663, 3.9663, 3.9648, 3.9648, 3.9642, 3.9642, 3.9618, 3.9608, 3.9608, 3.9608, 3.9596, 3.9582, 3.9582, 3.9582, 3.9582, 3.9544, 3.9544, 3.9518, 3.9518, 3.9518, 3.9518, 3.9518, 3.9518, 3.9485, 3.9485, 3.9485, 3.9485, 3.9385, 3.8659, 3.6379, 3.7156, 3.5294, 3.7084, 3.8809, 3.8381, 3.7366, 3.8194, 3.5228, 3.0611, 2.9959, 3.2238, 2.7365, 1.9972, 2.665, 1.9869, 2.2306, 1.1542, 2.9084, 1.9195, 3.0595, 1.0192, 1.9459, 2.3549, 1.8024, 1.6571, 2.2639, 2.4944, 1.9343, 1.7971, 2.6349, 3.3158, 3.3154, 3.3123, 3.3121, 3.3117, 3.3114, 3.3096, 3.3083, 3.3083, 3.3077, 3.3077, 3.3064, 3.3064, 3.3056, 3.3056, 3.3047, 3.3047, 3.3047, 3.3037, 3.3037, 3.3037, 3.3037, 3.3025, 3.3025, 3.3011, 3.3011, 3.3011, 3.3011, 3.2994, 3.2994, 3.2659, 3.2373, 3.2175, 3.2309, 3.2509, 2.9389, 3.125, 3.1063, 3.1046, 3.008, 2.9181, 3.1968, 2.6021, 1.5867, 2.7071, 2.6795, 2.1107, 2.3493, 2.7965, 2.822, 1.8377, 2.0124, 1.6704, 2.3875, 1.6585, 2.3851, 1.9649, 1.0954, 1.9401, 1.5857, 1.6707, 1.5484, 1.7642, 1.0106, 1.0006, 1.7866, 1.722, 2.0527, 0.5579, 1.605, -0.2047, 1.3428, 1.0514, 1.0797, -0.3301, 3.7475, 3.747, 3.7468, 3.7456, 3.7451, 3.745, 3.7446, 3.7444, 3.7426, 3.7423, 3.7411, 3.737, 3.737, 3.737, 3.737, 3.737, 3.7348, 3.7334, 3.7334, 3.7334, 3.7334, 3.7317, 3.7296, 3.7296, 3.7296, 3.7296, 3.727, 3.727, 3.727, 3.7237, 3.7237, 3.7237, 3.7237, 3.6658, 3.603, 3.5476, 3.6014, 3.2586, 2.5826, 2.2501, 2.9083, 2.5621, 2.2865, 3.3207, 3.1486, 2.4914, 1.8915, 1.7831, 0.9622, 2.1095, 1.9199, 1.1586, 1.561, 1.4098, 1.0871, 1.0257, 1.3808, 1.9523, 2.1126, 1.0931, 1.5722, 0.637, 4.17, 4.1693, 4.1693, 4.168, 4.1664, 4.1661, 4.1649, 4.1634, 4.1632, 4.1629, 4.1626, 4.1622, 4.1618, 4.1605, 4.1599, 4.1599, 4.1569, 4.1569, 4.1559, 4.1533, 4.1516, 4.1516, 4.1495, 4.1495, 4.1495, 4.1469, 4.1469, 4.1469, 4.1469, 4.1469, 3.7892, 4.0016, 3.378, 3.4152, 3.5227, 2.659, 1.9685, 2.9627, 0.7697, 1.6456, 2.9481, 1.2405, 1.8973, 1.7348, 1.0152, 0.8977, 1.0973, 1.2616, 1.6745, 0.722, 1.2835, 0.9352, 1.2651, 2.2409, 1.9218, 1.9217, 1.9216, 1.9214, 1.9211, 1.9209, 1.9206, 1.9203, 1.9202, 1.9202, 1.92, 1.9198, 1.9198, 1.9198, 1.9197, 1.9197, 1.9192, 1.919, 1.9188, 1.9188, 1.9186, 1.9186, 1.9186, 1.9183, 1.9183, 1.9183, 1.9183, 1.9179, 1.9179, 1.9177, 1.9109, 1.9109, 1.8856, 1.9079, 1.9001, 1.8612, 1.8909, 1.8901, 1.904, 1.9032, 1.8454, 1.8491, 1.8078, 1.8821, 1.8433, 1.7528, 1.7142, 1.8616, 1.8776, 1.7928, 1.8866, 1.698, 1.4088, 1.4464, 1.3487, 1.7524, 1.3053, 1.3376, 1.6204, 1.7521, 1.3648, 1.399, 1.6745, 1.4239, 1.3419, 1.4951, 1.604, 1.3949, 1.1652, 1.4689, 0.9504, 0.5849, 1.5651, 0.9053, 0.8732, 1.3676, 0.9204, 1.0314, 0.8016, 1.0912, 0.0851, 0.9361, 0.6782, 0.656, 0.9137, 0.82, 0.637, 3.752, 3.752, 3.7509, 3.7502, 3.7492, 3.7492, 3.7471, 3.7466, 3.7439, 3.743, 3.743, 3.742, 3.7408, 3.7408, 3.7408, 3.7394, 3.7394, 3.7394, 3.7377, 3.7356, 3.7356, 3.7356, 3.7356, 3.7356, 3.7356, 3.733, 3.733, 3.733, 3.733, 3.733, 3.7202, 3.733, 3.6885, 3.6849, 3.6211, 3.4828, 3.3473, 3.465, 3.2165, 2.6379, 3.3314, 2.8351, 3.1028, 2.967, 3.1382, 2.7588, 2.1055, 1.1632, 2.2414, 2.8557, 1.2891, 1.3711, 1.9711, 1.2059, 0.4119, 0.124, 1.5555, 1.2382, 1.1462, 0.4019, 2.1144, 1.2355, 0.4734, 2.0057, 1.6945, 1.1353, 0.6583, 0.6572, 3.133, 3.1314, 3.1312, 3.1312, 3.1303, 3.1286, 3.1286, 3.1281, 3.1281, 3.1281, 3.1276, 3.1271, 3.1265, 3.1265, 3.1265, 3.1265, 3.1258, 3.1258, 3.1258, 3.1258, 3.1258, 3.125, 3.125, 3.1247, 3.1241, 3.1231, 3.1219, 3.1219, 3.1219, 3.1205, 3.1205, 3.1205, 3.091, 3.0891, 2.9837, 3.0738, 2.9745, 2.8611, 2.8577, 2.6717, 2.776, 2.3169, 2.8781, 2.8318, 2.7631, 2.9711, 2.2326, 2.8293, 2.1947, 2.3008, 2.0458, 2.4681, 1.7953, 2.0379, 1.904, 2.4455, 2.4947, 1.9245, 1.6129, 1.8702, 1.2162, 1.5224, 2.0037, 0.7427, 0.9371, 1.9882, 1.9197, 1.2519, 1.3352, 0.9271, 1.5035, 1.4077, 1.4293, 0.9509, 1.0525, 0.4764, -0.3377, 2.6498, 2.6475, 2.6474, 2.6472, 2.6434, 2.6434, 2.6426, 2.6422, 2.6418, 2.6418, 2.6413, 2.6413, 2.6408, 2.6408, 2.6401, 2.6401, 2.6401, 2.6395, 2.6395, 2.6387, 2.6378, 2.6378, 2.6368, 2.6368, 2.6368, 2.6356, 2.6356, 2.6356, 2.6356, 2.6356, 2.6356, 2.6356, 2.6356, 2.6078, 2.5904, 2.6066, 2.6356, 2.5693, 2.6047, 2.577, 2.5986, 2.5765, 2.5146, 2.5292, 2.5394, 2.5383, 2.4983, 2.1078, 2.5674, 2.2142, 2.2523, 2.2914, 2.1052, 2.0231, 2.1729, 2.1462, 1.4379, 2.54, 2.1356, 1.895, 2.0106, 2.0976, 1.6674, 2.032, 2.0004, 1.3715, 1.3594, 2.0862, 1.9295, 1.2115, 2.0577, 1.132, 1.1124, 1.1147, 1.5439, 0.2936, 1.7567, 0.8101, 1.223, 1.6987, 1.2289, 0.0539, 0.8846, 0.569, 1.0222, 1.2023, 1.1789, 1.2952, 4.0272, 4.0264, 4.026, 4.0257, 4.0256, 4.025, 4.0242, 4.0241, 4.0239, 4.0225, 4.0222, 4.0208, 4.0203, 4.0198, 4.0187, 4.018, 4.018, 4.0172, 4.0126, 4.0109, 4.0089, 4.0089, 4.0089, 4.0063, 4.0063, 4.003, 4.003, 4.003, 4.003, 3.9986, 3.997, 3.7671, 3.8131, 3.7218, 3.901, 3.6716, 3.4247, 3.3363, 3.4569, 3.1903, 2.8134, 2.6323, 2.2905, 1.9438, 2.5402, 1.7794, 1.9518, 2.3957, 1.3642, 2.0539, 2.3702, 0.9622, 1.0853, 1.6522, 2.2019, 2.9797, 2.9775, 2.9772, 2.977, 2.9767, 2.9758, 2.9758, 2.9744, 2.9731, 2.9731, 2.9727, 2.9727, 2.9721, 2.9721, 2.9708, 2.9681, 2.9681, 2.9681, 2.9669, 2.9669, 2.9669, 2.9655, 2.9655, 2.9655, 2.9655, 2.9655, 2.9638, 2.9638, 2.9638, 2.9638, 2.9638, 2.9638, 2.9482, 2.9638, 2.9638, 2.7894, 2.8492, 2.8961, 2.6856, 2.806, 2.6453, 2.5769, 2.7167, 2.4616, 2.1584, 2.6987, 2.2637, 2.4165, 2.6402, 2.2983, 2.1073, 2.3433, 2.2036, 2.0145, 1.5871, 1.6851, 2.2557, 1.7885, 1.8272, 1.4964, 2.2175, 1.1619, 1.4817, 2.037, 1.3993, 1.6717, 1.2524, 1.1, 0.7659, 1.5075, -0.1293, 1.3292, 1.6081, 1.1871, -0.5626, 3.3509, 3.3503, 3.3492, 3.3492, 3.3492, 3.3489, 3.3483, 3.3483, 3.348, 3.3466, 3.3463, 3.346, 3.345, 3.345, 3.3437, 3.3431, 3.3431, 3.3418, 3.341, 3.3401, 3.3401, 3.3401, 3.3391, 3.3391, 3.3379, 3.3379, 3.3379, 3.3379, 3.3365, 3.3365, 3.3365, 3.3191, 3.3365, 3.1683, 2.9458, 3.0933, 2.4895, 2.2229, 1.8896, 2.9356, 2.8838, 2.0728, 2.6618, 2.7214, 1.7883, 1.6228, 2.5738, 1.3308, 1.9318, 2.1717, 0.5276, 1.7078, 1.3724, 1.9947, 1.5693, 1.461, 0.8687, 2.0155, 1.6676, 1.2195, 1.1595, 2.2388, 0.3298, 0.5666, 1.0754, 0.5842, 1.3896, 0.3668, 0.2283, 3.0804, 3.0775, 3.0772, 3.0772, 3.0762, 3.0758, 3.0743, 3.0743, 3.0737, 3.0737, 3.0737, 3.073, 3.0722, 3.0722, 3.0722, 3.0713, 3.0713, 3.0703, 3.0703, 3.0703, 3.0691, 3.0691, 3.0677, 3.0677, 3.0677, 3.0677, 3.0677, 3.0677, 3.0677, 3.066, 3.066, 3.0445, 2.9564, 3.0209, 2.9741, 2.696, 3.0135, 2.6342, 2.9764, 2.8335, 2.8058, 2.7624, 2.5239, 2.4636, 2.7082, 1.7818, 2.7047, 2.2922, 2.4215, 2.5042, 1.7339, 1.7528, 2.6671, 2.5772, 2.187, 2.7354, 2.2473, 2.0594, 2.4107, 1.6123, 1.6423, 1.9568, 0.5677, 0.539, 2.0243, 1.9183, 1.1025, 1.2257, 1.4792, 1.5984, 1.2845, 0.793, 1.8253, 0.972, 1.2143, 1.737, 1.8767, 1.2408, 1.1426, 0.4838, 2.244, 2.2434, 2.2434, 2.2426, 2.2425, 2.2423, 2.2412, 2.241, 2.2401, 2.2399, 2.2394, 2.2392, 2.2392, 2.2392, 2.2392, 2.239, 2.239, 2.2385, 2.2382, 2.2382, 2.2379, 2.2376, 2.2376, 2.2373, 2.2373, 2.2373, 2.2373, 2.2373, 2.2373, 2.2373, 2.2257, 2.1854, 2.2147, 2.2141, 2.143, 2.1565, 2.2104, 2.1039, 2.1378, 2.1456, 2.0638, 2.1182, 2.08, 1.9439, 1.7673, 1.6956, 2.071, 2.0438, 1.8602, 1.7362, 1.8816, 1.9041, 1.8545, 1.202, 1.5771, 1.6203, 1.5951, 1.7568, 1.736, 1.8138, 1.4452, 1.5442, 1.5003, 0.7888, 1.2978, 1.5894, 1.4157, 1.635, 0.9141, 0.8278, 1.3638, 0.9468, 1.0918, 1.3017, 1.4349, 0.7276, 1.1154, 0.2027, 0.5293, 1.0309, 0.7211, 1.2415, 4.1141, 4.1128, 4.1121, 4.1112, 4.1112, 4.1107, 4.1107, 4.1107, 4.11, 4.11, 4.1088, 4.1083, 4.1071, 4.1064, 4.1064, 4.1047, 4.101, 4.101, 4.0973, 4.0973, 4.0973, 4.0973, 4.0947, 4.0947, 4.0913, 4.0913, 4.0913, 4.0869, 4.0869, 4.0869, 4.0869, 4.0479, 4.0869, 4.0869, 4.0227, 3.9502, 3.5987, 3.8985, 3.7804, 3.5062, 3.601, 3.8545, 2.3898, 3.0904, 3.4831, 3.3221, 3.5115, 3.4159, 2.833, 2.2365, 3.4144, 2.915, 2.3019, 1.8715, 0.6503, 2.3674, 1.4877, 1.8415, 1.8096, 2.0506, 1.9432, 1.5627, 0.6454, 2.9304, 1.6856, 1.3267, 2.6649], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.26, -4.8885, -5.2814, -5.3992, -5.6327, -5.6867, -5.6867, -5.7438, -5.8044, -6.2741, -6.2741, -6.3793, -6.3793, -6.3793, -6.3793, -6.497, -6.497, -6.497, -6.6303, -6.6303, -6.6303, -6.6303, -6.7842, -6.7842, -6.7842, -6.7842, -6.7842, -6.7842, -6.7842, -6.7842, -4.358, -5.7438, -5.5326, -5.9379, -4.3148, -5.9379, -4.5521, -4.6654, -4.6456, -4.3878, -5.3192, -5.3992, -4.2734, -5.5814, -5.1433, -5.5326, -5.8044, -4.9398, -4.0889, -4.9938, -5.4861, -4.3008, -5.051, -4.4504, -4.7062, -4.2337, -4.6456, -4.7932, -4.8397, -5.051, -4.4831, -5.051, -4.9398, -4.9398, -4.9398, -5.022, -5.051, -5.1116, -3.3849, -3.9201, -4.0267, -4.0393, -4.3143, -4.6474, -4.7197, -4.912, -4.9745, -5.0073, -5.1504, -5.1504, -5.1896, -5.4126, -5.4639, -5.5179, -5.9231, -6.01, -6.1053, -6.1053, -6.2105, -6.2105, -4.4384, -6.3282, -6.4615, -6.4615, -6.6154, -6.6154, -6.6154, -6.7974, -6.7974, -6.7974, -6.7974, -6.7974, -5.3638, -4.771, -5.7001, -4.6709, -5.3638, -6.1053, -4.1183, -4.8532, -5.5179, -4.3311, -3.9201, -5.0412, -5.3174, -4.8822, -4.8251, -4.8532, -4.912, -4.745, -4.695, -4.695, -5.1126, -5.1126, -5.1126, -3.8944, -3.9398, -4.0687, -4.2045, -4.7565, -4.9037, -4.9537, -5.1057, -5.136, -5.303, -5.4185, -5.6727, -6.0143, -6.052, -6.052, -6.0912, -6.132, -6.1746, -6.3143, -6.4196, -6.4767, -6.4767, -6.5373, -6.6018, -6.6707, -6.6707, -6.7448, -6.8248, -6.8248, -6.8248, -6.2655, -6.0143, -6.4196, -5.3785, -5.2328, -5.34, -6.2655, -4.647, -5.4602, -5.7839, -4.9284, -3.9214, -2.734, -4.9929, -4.4584, -3.5869, -4.5483, -4.4429, -4.4126, -5.303, -4.3617, -4.4741, -4.7886, -5.2499, -4.9796, -5.0763, -5.1207, -5.0909, -5.1832, -5.1832, -5.1995, -4.1558, -5.3477, -5.3776, -5.4729, -5.4729, -5.4729, -5.5068, -5.6959, -5.6959, -5.6959, -5.7829, -5.8782, -5.9294, -5.9294, -5.9835, -6.0406, -6.1012, -6.3087, -4.5305, -6.3887, -6.4756, -6.4756, -6.4756, -6.5708, -6.5708, -6.5708, -6.5708, -6.5708, -6.6761, -6.6761, -5.7385, -4.7634, -5.3776, -6.3087, -5.9835, -5.7829, -5.9294, -5.0675, -4.8312, -5.6959, -4.9424, -4.6258, -4.2893, -3.581, -4.7634, -4.5838, -4.6258, -5.0675, -4.7967, -4.1469, -4.8312, -5.0675, -4.7471, -5.1606, -5.024, -5.0455, -4.7311, -4.9824, -5.0455, -5.003, -5.0455, -5.2106, -5.1853, -5.2365, -5.2632, -5.2365, -5.6785, -6.4922, -6.5862, -6.6004, -6.6442, -6.69, -6.7545, -6.8415, -6.8598, -6.8785, -6.8976, -6.8976, -6.9368, -6.957, -6.957, -6.9776, -6.9986, -7.0201, -7.0421, -7.0646, -7.0646, -7.1111, -7.1352, -7.1352, -7.1599, -7.1599, -7.1852, -5.3642, -7.2111, -7.2111, -6.0867, -6.3945, -6.0367, -6.0531, -5.9217, -3.9946, -5.483, -6.3491, -5.656, -6.6442, -6.7217, -5.6842, -5.7491, -6.0126, -5.2883, -6.7713, -4.4537, -4.4604, -5.059, -5.812, -6.2338, -5.3559, -5.5506, -6.2639, -4.6126, -4.5086, -4.1144, -5.3275, -5.2692, -4.742, -5.5162, -5.5456, -4.5445, -4.124, -5.2178, -4.3313, -3.9696, -4.9274, -4.9996, -5.2883, -4.8905, -5.1791, -5.1287, -3.9392, -4.7577, -4.2144, -4.9463, -5.2071, -5.1825, -5.0438, -5.2, -5.3489, -5.8596, -6.1927, -6.1927, -6.5865, -6.6957, -6.7349, -6.7349, -6.7757, -6.8182, -6.8182, -6.8182, -6.8627, -6.8627, -6.8627, -6.9092, -7.0092, -7.0092, -7.0632, -7.1204, -7.1204, -7.1809, -7.2454, -7.2454, -7.3884, -7.3884, -7.3884, -7.3884, -7.3884, -7.4684, -6.2163, -6.2403, -6.0828, -6.4275, -6.4881, -5.9837, -5.7055, -5.2719, -5.7345, -5.7796, -6.0027, -5.5846, -4.1703, -6.1927, -4.7338, -5.0124, -6.343, -5.7493, -4.4367, -4.8066, -5.6233, -3.8229, -4.6262, -5.3291, -6.0828, -4.8915, -5.1583, -3.2949, -3.3354, -5.5973, -5.0943, -4.405, -5.3193, -4.7556, -4.7836, -4.8979, -5.3793, -4.7338, -4.723, -4.6311, -4.9107, -5.2536, -4.4089, -4.9302, -5.175, -5.2627, -4.9774, -5.2536, -5.3097, -4.064, -4.8829, -4.9075, -5.5517, -5.5517, -5.7057, -5.7057, -5.7629, -5.7629, -5.9569, -6.0309, -6.0309, -6.0309, -6.1109, -6.1979, -6.1979, -6.1979, -6.1979, -6.3983, -6.3983, -6.516, -6.516, -6.516, -6.516, -6.516, -6.516, -6.6493, -6.6493, -6.6493, -6.6493, -5.1306, -5.6517, -3.9144, -4.5892, -3.1286, -4.9075, -6.1109, -5.888, -5.4607, -6.0309, -5.3774, -4.6075, -4.6075, -5.229, -4.7463, -4.2925, -4.9588, -4.4534, -4.7463, -4.0533, -5.3005, -4.6646, -5.4607, -4.5534, -5.0129, -5.1951, -5.041, -5.0129, -5.229, -5.3005, -5.229, -5.229, -5.3774, -4.8784, -5.0431, -5.7819, -5.8137, -5.8803, -5.9154, -6.1565, -6.303, -6.303, -6.3571, -6.3571, -6.4748, -6.4748, -6.5393, -6.5393, -6.6082, -6.6082, -6.6082, -6.6823, -6.6823, -6.6823, -6.6823, -6.7622, -6.7622, -6.8492, -6.8492, -6.8492, -6.8492, -6.9444, -6.9444, -6.1565, -5.9895, -5.8465, -6.0695, -6.4142, -4.8052, -5.8803, -5.9895, -5.9895, -5.9154, -5.6923, -6.4142, -5.1047, -2.9601, -5.4636, -5.4191, -4.5205, -5.0283, -5.8137, -5.8465, -4.6132, -4.8411, -4.4521, -5.356, -4.5751, -5.4411, -5.0734, -4.4772, -5.1535, -4.9304, -4.9993, -5.0734, -5.2225, -4.904, -5.0582, -5.3766, -5.3766, -5.4865, -5.0889, -5.3766, -4.9574, -5.356, -5.3358, -5.356, -5.2775, -4.6776, -4.8318, -4.8889, -5.1831, -5.2653, -5.2943, -5.3549, -5.3866, -5.6425, -5.685, -5.8247, -6.1812, -6.1812, -6.1812, -6.1812, -6.1812, -6.3352, -6.4221, -6.4221, -6.4221, -6.4221, -6.5173, -6.6226, -6.6226, -6.6226, -6.6226, -6.7402, -6.7402, -6.7402, -6.8736, -6.8736, -6.8736, -6.8736, -5.6017, -5.1571, -4.6776, -5.5625, -4.6013, -4.2057, -3.5791, -5.014, -4.6013, -4.4641, -5.876, -5.7294, -4.9921, -4.5441, -4.5033, -3.7904, -4.9289, -4.7954, -4.4141, -4.8695, -4.8889, -4.8318, -4.8889, -5.0595, -5.2653, -5.3549, -5.2371, -5.2943, -5.2653, -2.3913, -3.3616, -3.3616, -4.0611, -4.5762, -4.6436, -4.8784, -5.1088, -5.1466, -5.1858, -5.2266, -5.2691, -5.3136, -5.4601, -5.5141, -5.5141, -5.7653, -5.7653, -5.8393, -6.0062, -6.1015, -6.1015, -6.2067, -6.2067, -6.2067, -6.3244, -6.3244, -6.3244, -6.3244, -6.3244, -5.3136, -5.9193, -4.246, -4.6436, -5.4088, -4.2002, -4.3618, -5.2266, -3.8302, -4.4346, -5.3136, -4.5336, -4.8784, -4.8494, -4.5982, -4.6206, -4.6912, -4.7672, -4.9082, -4.8213, -5.1466, -5.1466, -5.1858, -5.2266, -6.2677, -6.3064, -6.3467, -6.403, -6.51, -6.594, -6.6858, -6.7659, -6.7869, -6.7869, -6.8304, -6.8758, -6.8758, -6.8758, -6.8994, -6.8994, -6.9994, -7.0535, -7.0816, -7.0816, -7.1106, -7.1106, -7.1106, -7.1712, -7.1712, -7.1712, -7.1712, -7.2357, -7.2357, -7.2696, -6.1485, -6.1598, -5.1862, -6.3605, -6.1485, -5.0613, -6.0939, -6.1263, -6.5766, -6.6117, -4.8083, -5.5192, -4.8815, -6.3331, -5.7544, -4.8847, -4.506, -6.2551, -6.4475, -5.9643, -6.594, -5.5496, -4.1345, -4.4572, -4.1695, -5.9643, -4.2673, -4.4167, -5.5073, -6.022, -4.9743, -5.1692, -5.825, -5.2573, -5.1401, -5.5192, -5.7319, -5.3797, -5.05, -5.5252, -4.8381, -4.3625, -5.6884, -4.872, -4.8815, -5.4667, -4.9953, -5.1278, -4.9503, -5.2391, -4.5147, -5.1319, -5.096, -5.1158, -5.23, -5.23, -5.2211, -5.0752, -5.0752, -5.2864, -5.4115, -5.5546, -5.5546, -5.8168, -5.8681, -6.1044, -6.1733, -6.1733, -6.2474, -6.3273, -6.3273, -6.3273, -6.4143, -6.4143, -6.4143, -6.5095, -6.6147, -6.6147, -6.6147, -6.6147, -6.6147, -6.6147, -6.7324, -6.7324, -6.7324, -6.7324, -6.7324, -4.7354, -6.7324, -5.9793, -6.0399, -5.7216, -5.0062, -4.654, -5.5169, -4.7354, -3.7761, -5.5938, -4.6233, -5.2293, -5.124, -5.5546, -5.2019, -4.4435, -3.3837, -4.654, -5.5169, -4.3243, -4.4062, -4.9009, -4.6233, -4.188, -4.4185, -5.0287, -4.9211, -4.9627, -4.8056, -5.2864, -5.124, -5.0993, -5.3163, -5.2864, -5.2574, -5.2574, -5.2574, -5.6904, -5.994, -6.0268, -6.0268, -6.1698, -6.3833, -6.3833, -6.4321, -6.4321, -6.4321, -6.4834, -6.5374, -6.5945, -6.5945, -6.5945, -6.5945, -6.6551, -6.6551, -6.6551, -6.6551, -6.6551, -6.7196, -6.7196, -4.9064, -6.7885, -6.8626, -6.9426, -6.9426, -6.9426, -7.0295, -7.0295, -7.0295, -6.209, -6.2498, -5.3173, -6.5374, -5.8727, -5.4963, -5.5161, -4.9739, -5.6439, -4.3469, -5.994, -5.9017, -5.7905, -6.2924, -4.7743, -5.994, -4.8032, -5.0215, -4.6242, -5.3851, -4.2635, -4.8131, -4.692, -5.4769, -5.5569, -4.8639, -4.7743, -5.1107, -4.6491, -4.9284, -5.3338, -4.4724, -4.7097, -5.3338, -5.3338, -4.9974, -5.0975, -4.9974, -5.2235, -5.2235, -5.2693, -5.2693, -5.285, -5.301, -5.285, -5.0367, -5.98, -5.9998, -6.0616, -6.7335, -6.7335, -6.8205, -6.867, -6.9157, -6.9157, -6.967, -6.967, -7.0211, -7.0211, -7.0782, -7.0782, -7.0782, -7.1388, -7.1388, -7.2033, -7.2722, -7.2722, -7.3463, -7.3463, -7.3463, -7.4262, -7.4262, -7.4262, -7.4262, -7.4262, -7.4262, -7.4262, -7.4262, -6.02, -5.5051, -6.6535, -7.4262, -6.02, -6.6927, -6.1982, -6.8205, -6.5794, -6.02, -6.2229, -6.3563, -6.3563, -6.1505, -3.9509, -6.6927, -5.0756, -5.2869, -5.6078, -5.0916, -4.8305, -5.3475, -5.3475, -3.3148, -6.6158, -5.568, -4.9561, -5.3269, -5.568, -4.6702, -5.481, -5.4575, -4.359, -4.4148, -5.7071, -5.5051, -4.7079, -5.6777, -4.7703, -4.7529, -4.7999, -5.2114, -4.249, -5.446, -4.8367, -5.1161, -5.4121, -5.1583, -4.546, -5.0216, -4.888, -5.2114, -5.2869, -5.3372, -5.3686, -4.2664, -4.5176, -4.6309, -4.7143, -4.7363, -4.8794, -5.0165, -5.0464, -5.0771, -5.2847, -5.3239, -5.4982, -5.5469, -5.5982, -5.7094, -5.77, -5.77, -5.8345, -6.1444, -6.2396, -6.3448, -6.3448, -6.3448, -6.4625, -6.4625, -6.5958, -6.5958, -6.5958, -6.5958, -6.7497, -4.9594, -3.0921, -4.8053, -4.2123, -5.77, -4.5176, -4.1992, -3.8702, -5.4982, -5.247, -4.7817, -4.5727, -4.2255, -4.1363, -4.6718, -4.1363, -4.6309, -4.9875, -4.6309, -4.9053, -5.0165, -4.6511, -4.8294, -4.932, -5.0464, -5.3766, -5.9703, -6.0258, -6.0548, -6.1154, -6.2489, -6.2489, -6.4455, -6.5852, -6.5852, -6.6365, -6.6365, -6.6905, -6.6905, -6.8082, -7.0157, -7.0157, -7.0157, -7.0957, -7.0957, -7.0957, -7.1827, -7.1827, -7.1827, -7.1827, -7.1827, -7.2779, -7.2779, -7.2779, -7.2779, -7.2779, -7.2779, -6.0548, -7.2779, -7.2779, -4.0441, -5.82, -6.403, -4.2731, -5.9703, -4.9762, -4.6541, -5.5559, -4.4634, -3.0491, -5.9703, -4.3187, -5.1869, -5.9703, -4.8992, -4.4755, -5.1505, -5.1505, -4.8809, -4.1433, -4.3829, -5.487, -4.9179, -5.017, -4.7372, -5.487, -4.4515, -4.9085, -5.3618, -4.8809, -5.104, -4.8278, -4.8023, -4.7774, -5.1505, -4.6761, -5.1869, -5.2638, -5.2119, -5.1625, -4.9797, -5.1534, -5.4526, -5.4526, -5.4526, -5.5249, -5.6302, -5.6302, -5.6873, -5.9178, -5.9555, -5.9947, -6.1225, -6.1225, -6.269, -6.3231, -6.3231, -6.4408, -6.5053, -6.5742, -6.5742, -6.5742, -6.6483, -6.6483, -6.7283, -6.7283, -6.7283, -6.7283, -6.8152, -6.8152, -6.8152, -5.6873, -6.8152, -5.5249, -4.8072, -5.7797, -4.2441, -3.6965, -2.8631, -5.6584, -5.6028, -4.2794, -5.4071, -5.5249, -4.1263, -4.2794, -5.5002, -4.3161, -5.055, -5.2435, -4.0723, -4.9234, -4.7365, -5.1534, -4.9797, -5.055, -4.8831, -5.3018, -5.2248, -5.1708, -5.1708, -5.4296, -5.1885, -5.2626, -5.3426, -5.322, -5.3851, -5.3636, -5.3851, -5.7188, -6.2217, -6.2609, -6.2609, -6.3887, -6.4352, -6.5893, -6.5893, -6.6464, -6.6464, -6.6464, -6.707, -6.7715, -6.7715, -6.7715, -6.8404, -6.8404, -6.9145, -6.9145, -6.9145, -6.9944, -6.9944, -7.0814, -7.0814, -7.0814, -7.0814, -7.0814, -7.0814, -7.0814, -7.1766, -7.1766, -6.1125, -5.6733, -6.5893, -6.184, -3.7533, -6.707, -4.3987, -6.5352, -5.8164, -5.7664, -5.6733, -4.798, -4.6281, -5.6958, -3.4257, -5.869, -4.9054, -5.3211, -5.6513, -4.1818, -4.3562, -5.9834, -5.8423, -5.2459, -6.1125, -5.3529, -5.1233, -5.6513, -4.6049, -4.798, -5.2459, -3.9748, -4.0079, -5.3529, -5.2753, -4.6518, -4.7616, -5.0027, -5.1896, -5.0142, -4.7796, -5.3211, -4.9475, -5.176, -5.3529, -5.4196, -5.2753, -5.2753, -5.2904, -5.4726, -5.7735, -5.795, -6.1271, -6.1578, -6.2224, -6.5325, -6.579, -6.7612, -6.7902, -6.8826, -6.9153, -6.9153, -6.9153, -6.9153, -6.9492, -6.9492, -7.0207, -7.0584, -7.0584, -7.0976, -7.1384, -7.1384, -7.1809, -7.1809, -7.1809, -7.1809, -7.1809, -7.1809, -7.1809, -5.6254, -5.8979, -6.679, -6.7057, -5.7735, -5.9729, -6.8201, -5.6533, -6.0401, -6.2392, -5.7524, -6.2224, -6.0263, -5.1929, -4.2278, -4.2233, -6.0826, -5.9729, -5.152, -4.6964, -5.3332, -5.4493, -5.4885, -3.3405, -4.6401, -4.8034, -4.8963, -5.354, -5.3129, -5.5377, -4.8446, -5.049, -4.9889, -3.8111, -4.7523, -5.1988, -5.0235, -5.3062, -4.4762, -4.3873, -5.0541, -4.8074, -4.9369, -5.0911, -5.1869, -4.8156, -5.0438, -4.7447, -4.9278, -5.1128, -5.0336, -5.1988, -4.6279, -4.9011, -5.0224, -5.1605, -5.1605, -5.2374, -5.2374, -5.2374, -5.3208, -5.3208, -5.4605, -5.5118, -5.6229, -5.6835, -5.6835, -5.8169, -6.0579, -6.0579, -6.2584, -6.2584, -6.2584, -6.2584, -6.376, -6.376, -6.5094, -6.5094, -6.5094, -6.6633, -6.6633, -6.6633, -6.6633, -4.014, -6.6633, -6.6633, -5.971, -5.971, -4.6953, -5.891, -5.5658, -4.8455, -5.1605, -5.8169, -3.4394, -4.6498, -5.2782, -5.0552, -5.3652, -5.2782, -4.6498, -4.0499, -5.3208, -4.8455, -4.4135, -4.3457, -3.8923, -4.8189, -4.4312, -4.6498, -4.6723, -4.8455, -4.8455, -4.8729, -4.8729, -5.1605, -5.0891, -5.1242, -5.1982]}, \"token.table\": {\"Topic\": [15, 6, 14, 5, 19, 2, 6, 19, 5, 18, 6, 19, 2, 5, 4, 19, 2, 7, 8, 11, 19, 10, 6, 8, 13, 18, 14, 2, 7, 7, 6, 7, 10, 5, 18, 6, 13, 11, 17, 15, 1, 8, 9, 12, 16, 4, 19, 16, 20, 1, 2, 5, 6, 7, 9, 16, 19, 2, 9, 8, 1, 17, 10, 10, 6, 11, 20, 19, 18, 13, 3, 5, 6, 7, 15, 16, 17, 2, 6, 10, 16, 8, 6, 11, 12, 13, 14, 19, 16, 16, 12, 13, 14, 19, 8, 7, 17, 15, 16, 3, 10, 13, 19, 11, 6, 11, 19, 13, 9, 6, 12, 14, 15, 13, 13, 9, 12, 20, 4, 5, 7, 20, 1, 15, 2, 7, 18, 19, 2, 3, 5, 7, 10, 12, 13, 19, 7, 5, 11, 12, 18, 19, 8, 17, 3, 9, 2, 8, 9, 14, 17, 18, 19, 4, 9, 13, 14, 1, 11, 15, 5, 6, 11, 14, 18, 5, 8, 14, 17, 1, 19, 1, 1, 6, 9, 6, 17, 19, 5, 17, 4, 12, 18, 11, 4, 9, 8, 9, 3, 7, 5, 16, 16, 18, 6, 7, 11, 14, 18, 19, 1, 8, 18, 19, 5, 8, 11, 16, 19, 18, 14, 5, 16, 18, 16, 19, 1, 6, 10, 7, 8, 13, 1, 6, 13, 16, 9, 11, 14, 6, 6, 11, 12, 15, 17, 18, 20, 17, 2, 5, 6, 8, 13, 18, 20, 2, 3, 5, 6, 9, 11, 16, 17, 18, 3, 11, 2, 6, 14, 16, 4, 5, 20, 1, 5, 6, 11, 13, 18, 19, 4, 4, 16, 3, 11, 15, 19, 10, 20, 3, 1, 20, 7, 11, 20, 11, 15, 4, 5, 12, 13, 18, 19, 3, 10, 10, 15, 15, 2, 8, 20, 13, 10, 9, 7, 18, 20, 1, 3, 10, 15, 4, 6, 7, 12, 16, 14, 1, 3, 19, 8, 10, 1, 2, 4, 10, 5, 16, 20, 13, 19, 3, 13, 18, 5, 9, 17, 3, 9, 20, 17, 5, 12, 3, 5, 12, 19, 7, 17, 13, 19, 10, 11, 20, 5, 2, 12, 20, 11, 13, 14, 15, 16, 17, 18, 20, 15, 1, 9, 1, 5, 15, 16, 16, 1, 8, 16, 20, 14, 10, 10, 3, 6, 7, 15, 16, 19, 7, 9, 16, 3, 19, 10, 1, 9, 3, 11, 4, 8, 12, 16, 18, 20, 4, 7, 11, 18, 19, 15, 12, 6, 4, 18, 5, 4, 5, 6, 9, 11, 12, 14, 17, 20, 19, 8, 13, 16, 1, 8, 16, 18, 13, 5, 6, 15, 4, 9, 18, 14, 7, 15, 15, 19, 7, 3, 14, 18, 17, 4, 19, 3, 4, 5, 15, 3, 14, 1, 12, 17, 18, 20, 2, 12, 14, 16, 17, 1, 2, 16, 1, 7, 3, 5, 10, 13, 16, 2, 5, 9, 11, 12, 13, 9, 2, 6, 17, 18, 4, 4, 5, 18, 1, 5, 7, 14, 18, 20, 1, 7, 9, 14, 18, 19, 7, 16, 12, 6, 10, 11, 13, 14, 16, 17, 18, 14, 10, 11, 12, 13, 14, 16, 18, 19, 3, 6, 4, 5, 8, 13, 14, 19, 3, 4, 10, 11, 14, 15, 16, 18, 6, 9, 13, 10, 2, 4, 5, 10, 11, 13, 15, 18, 18, 13, 14, 15, 16, 20, 13, 5, 9, 15, 15, 17, 8, 11, 8, 16, 3, 6, 6, 4, 3, 11, 1, 5, 2, 18, 1, 5, 8, 10, 11, 17, 19, 20, 1, 2, 4, 9, 12, 13, 15, 16, 20, 3, 4, 5, 10, 11, 14, 19, 5, 9, 2, 2, 8, 6, 8, 17, 20, 19, 3, 15, 19, 1, 5, 6, 8, 8, 6, 1, 20, 20, 6, 7, 9, 14, 15, 20, 12, 3, 6, 8, 11, 12, 13, 19, 12, 7, 1, 5, 11, 13, 19, 12, 3, 8, 13, 16, 18, 13, 14, 18, 20, 6, 11, 12, 13, 19, 5, 9, 1, 9, 3, 7, 19, 3, 17, 13, 5, 8, 13, 14, 15, 19, 20, 3, 7, 12, 14, 2, 6, 7, 8, 11, 13, 14, 15, 16, 11, 12, 10, 14, 7, 7, 3, 19, 9, 10, 8, 10, 3, 4, 11, 15, 18, 15, 1, 5, 8, 11, 14, 17, 3, 6, 10, 15, 16, 3, 8, 16, 7, 16, 20, 10, 14, 5, 9, 5, 5, 13, 14, 10, 3, 4, 11, 12, 18, 13, 16, 19, 1, 8, 9, 18, 16, 5, 11, 19, 2, 5, 8, 11, 13, 14, 17, 5, 9, 11, 16, 17, 1, 2, 4, 5, 9, 14, 16, 17, 20, 13, 20, 1, 2, 3, 4, 5, 8, 9, 12, 14, 16, 17, 1, 3, 6, 10, 13, 14, 18, 19, 2, 3, 4, 6, 9, 16, 17, 18, 12, 20, 5, 13, 17, 19, 8, 14, 5, 7, 11, 14, 11, 13, 17, 4, 7, 8, 9, 11, 12, 18, 19, 16, 11, 19, 3, 5, 13, 16, 11, 16, 6, 14, 15, 18, 6, 10, 13, 14, 16, 18, 5, 6, 18, 19, 20, 19, 4, 2, 5, 16, 20, 2, 3, 5, 10, 12, 15, 16, 20, 7, 16, 4, 8, 9, 13, 15, 18, 19, 6, 18, 1, 5, 7, 12, 14, 18, 4, 4, 7, 3, 6, 8, 14, 15, 1, 3, 6, 7, 8, 10, 13, 15, 17, 20, 2, 6, 17, 11, 19, 20, 1, 8, 14, 16, 17, 20, 3, 12, 19, 20, 1, 6, 10, 11, 14, 7, 15, 3, 7, 16, 17, 12, 14, 2, 4, 5, 6, 7, 13, 18, 1, 7, 12, 16, 20, 1, 4, 7, 8, 4, 14, 1, 5, 6, 10, 11, 6, 10, 2, 19, 16, 8, 17, 18, 14, 20, 12, 13, 15, 18, 20, 3, 7, 20, 16, 11, 2, 4, 5, 6, 10, 15, 8, 1, 11, 16, 17, 1, 4, 6, 8, 9, 12, 14, 17, 18, 20, 8, 1, 4, 5, 6, 8, 11, 20, 12, 3, 7, 12, 1, 3, 6, 10, 11, 12, 14, 15, 16, 17, 1, 6, 9, 11, 9, 7, 5, 6, 12, 14, 15, 18, 19, 20, 4, 18, 15, 11, 1, 3, 4, 5, 9, 12, 13, 16, 17, 18, 18, 1, 14, 2, 5, 10, 18, 2, 2, 2, 14, 2, 5, 17, 9, 3, 7, 1, 10, 11, 13, 9, 3, 5, 16, 11, 8, 13, 15, 12, 5, 6, 8, 10, 11, 13, 15, 16, 19, 4, 14, 7, 12, 16, 12, 12, 3, 9, 10, 11, 12, 13, 4, 5, 8, 13, 14, 3, 5, 6, 14, 15, 14, 3, 3, 11, 12, 13, 19, 6, 16, 5, 9, 10, 11, 14, 15, 19, 6, 10, 11, 13, 16, 17, 18, 19, 20, 11, 2, 4, 5, 8, 11, 18, 2, 2, 8, 5, 6, 15, 16, 20, 11, 2, 4, 17, 17, 2, 16, 3, 7, 11, 12, 14, 16, 17, 18, 20, 17, 10, 14, 5, 10, 16, 3, 16, 18, 20, 5, 8, 11, 14, 11, 3, 14, 18, 5, 9, 10, 15, 20, 1, 4, 6, 20, 4, 5, 6, 15, 18, 8, 2, 15, 17, 20, 13, 16, 13, 6, 9, 10, 12, 16, 17, 9, 2, 7, 13, 20, 12, 11, 12, 14, 18, 19, 1, 9, 10, 11, 19, 20, 16, 8, 9, 10, 20, 9, 10, 12, 14, 17, 20, 3, 1, 4, 9, 11, 14, 15, 19, 20, 6, 4, 2, 14, 4, 8, 6, 12, 19, 11, 20, 19, 13, 6, 13, 16, 12, 19, 7, 10, 13, 3, 13, 4, 11, 9, 12, 12, 14, 20, 20, 1, 9, 17, 4, 17, 20, 16, 1, 1, 6, 17, 7, 17, 12, 16, 20, 3, 11, 2, 6, 8, 15, 17, 18, 3, 4, 14, 15, 18, 1, 4, 11, 19, 9, 14, 8, 9, 18, 1, 4, 11, 12, 15, 18, 20, 18, 7, 9, 12, 1, 7, 9, 5, 7, 4, 11, 13, 14, 15, 16, 17, 20, 13, 14, 17, 3, 7, 12, 16, 18, 16, 18, 7, 14, 2, 10, 11, 19, 13, 4, 6, 9, 12, 20, 18, 11, 2, 7, 12, 17, 20, 7, 9, 13, 12, 13, 15, 17, 18, 1, 2, 4, 5, 14, 17, 18, 8, 8, 11, 11, 3, 12, 1, 6, 16, 18, 15, 1, 6, 7, 11, 16, 19, 5, 12, 12, 7, 1, 3, 5, 8, 9, 11, 17, 7, 7, 17, 4, 10, 1, 6, 11, 14, 17, 20, 6, 3, 7, 5, 13, 14, 16, 19, 1, 16, 17, 18, 1, 3, 4, 12, 11, 12, 18, 19, 4, 8, 13, 14, 16, 19, 13, 20, 6, 10, 13, 16, 17, 4, 6, 10, 14, 9, 5, 6, 11, 14, 16, 14, 14, 3, 12, 3, 4, 6, 9, 13, 14, 16, 18, 19, 2, 1, 2, 3, 4, 6, 8, 12, 14, 15, 16, 18, 3, 6, 1, 1, 4, 5, 7, 9, 11, 18, 1, 9, 11, 18, 2, 4, 5, 8, 9, 10, 14, 17, 10, 14, 17, 14, 9, 9, 10, 4, 10, 15, 17, 13, 13, 8, 9, 11, 1, 4, 7, 9, 10, 11, 17, 8, 14, 19, 14, 2, 6, 7, 11, 12, 7, 12, 16, 18, 5, 6, 8, 11, 13, 19, 17, 1, 5, 6, 9, 10, 11, 12, 14, 16, 17, 19, 20, 6, 13, 10, 15, 3, 17, 5, 8, 11, 10, 9, 11, 14, 17, 19, 20, 15, 5, 14, 1, 3, 6, 9, 10, 12, 17, 18, 19, 20, 20, 20, 4, 20, 2, 9, 14, 19, 5, 8, 16, 19, 3, 7, 7, 14, 19, 5, 9, 12, 13, 14, 19, 5, 8, 15, 10, 2, 15, 1, 2, 9, 14, 1, 7, 16, 19, 6, 8, 5, 1, 9, 12, 14, 17, 18, 19, 10, 16, 14, 13, 19, 9, 13, 15, 4, 12, 18, 16, 1, 11, 4, 9, 19, 20, 20, 20, 20, 12, 2, 16, 15, 19, 1, 7, 6, 13, 1, 12, 13, 14, 17, 4, 15, 3, 12, 19, 4, 8, 14, 15, 16, 18, 17, 12, 16, 15, 2, 4, 6, 20, 13, 2, 4, 6, 13, 15, 18, 6, 18, 19, 5, 12, 13, 1, 2, 3, 5, 9, 14, 16, 2, 11, 17, 7, 8, 10, 13, 14, 3, 5, 6, 10, 15, 16, 17, 18, 13, 6, 12, 16, 8, 18, 19, 20, 8, 11, 7, 14, 15, 6, 17, 10, 10, 17, 19, 20, 11, 18, 20, 8, 6, 18, 13, 17, 7, 4, 3, 1, 1, 9, 1, 20, 2, 2, 2, 14, 2, 14, 4, 20, 19, 11, 19, 15, 2, 18, 5, 8, 14, 15, 16, 20, 16, 3, 10, 15, 19, 5, 9, 13, 17, 12, 11, 13, 15, 18, 12, 9, 16, 10, 14, 17, 8, 10, 8, 18, 9, 4, 12, 20, 11, 6, 8, 11, 17, 18, 1, 3, 4, 7, 13, 19, 20, 11, 3, 16, 1, 8, 9, 13, 16, 17, 18, 8, 1, 1, 4, 8, 11, 13, 15, 20, 12, 5, 18, 3, 4, 10, 17, 6, 11, 18, 19, 16, 15, 1, 10, 8, 11, 19, 11, 4, 13, 1, 9, 12, 15, 20, 8, 13, 5, 6, 13, 16, 7, 19, 2, 4, 5, 6, 17, 1, 6, 9, 15, 19, 20, 18, 11, 2, 8, 19, 1, 2, 3, 12, 14, 16, 18, 2, 4, 6, 12, 13, 18, 5, 5, 8, 16, 5, 1, 6, 16, 19, 20, 8, 18, 18, 3, 9, 4, 5, 11, 17, 4, 7, 5, 14, 5, 8, 19, 17, 8, 6, 10, 19, 8, 2, 3, 15, 18, 7, 11, 13, 17, 20, 9, 5, 7, 12, 15, 17, 1, 2, 17, 18, 3, 5, 8, 15, 6, 3, 7, 3, 7, 5, 19, 11, 14, 18, 7, 5, 4, 6, 13, 18, 4, 18, 11, 19, 11, 13, 11, 5, 3, 4, 6, 8, 11, 15, 20, 9, 14, 17, 3, 12, 16, 3, 3, 6, 11, 12, 1, 2, 4, 5, 9, 11, 14, 7, 12, 12, 13, 16, 16, 20, 20, 4, 6, 12, 20, 10, 15, 1, 10, 15, 14, 3, 6, 17, 6, 6, 17, 3, 6, 16, 18, 20, 7, 11, 3, 6, 12, 13, 20, 1, 10, 11, 16, 17, 14, 16, 13, 7, 15, 14, 16, 7, 12, 19, 16, 11, 13, 18, 11, 19, 6, 10, 15, 6, 8, 9, 11, 19, 20, 2, 4, 8, 6, 9, 13, 16, 18, 5, 6, 11, 5, 11, 12, 13, 16, 7, 18, 14, 3, 8, 12, 17, 20, 3, 6, 11, 19, 11, 16, 19, 5, 8, 13, 14, 17, 18, 12, 12, 5, 8, 15, 19, 9, 19, 12, 14, 13, 1, 18, 2, 14, 15, 17, 18, 11, 13, 19, 16, 9, 17, 9, 17, 2, 5, 17, 18, 19, 4, 7, 9, 13, 19, 8, 6, 9, 13, 15, 16, 3, 6, 10, 14, 15, 10, 11, 13, 14, 19, 9, 20, 14, 18, 19, 1, 4, 5, 7, 10, 15, 16, 3, 3, 9, 11, 12, 15, 16, 18, 17, 5, 8, 11, 11, 16, 18, 1, 3, 4, 8, 11, 14, 16, 19, 11, 3, 6, 7, 16, 18, 18, 6, 3, 4, 5, 6, 11, 13, 19, 1, 6, 7, 8, 10, 12, 13, 16, 17, 3, 14, 13, 5, 7, 18, 13, 11, 1, 5, 7, 11, 3, 5, 1, 3, 5, 6, 11, 14, 19, 13, 6, 6, 1, 10, 13, 19, 6, 10, 12, 14, 15, 20, 11, 12, 15, 5, 13, 4, 6, 11, 5, 7, 16, 17, 14, 1, 16, 18, 19, 3, 5, 10, 20, 19, 3, 14, 6, 15, 18, 12, 12, 11, 1, 2, 14, 16, 17, 18, 19, 1, 2, 3, 4, 8, 9, 11, 12, 14, 15, 17, 18, 19, 2, 3, 6, 7, 8, 10, 12, 13, 15, 9, 9, 7, 9, 13, 14, 15, 19, 11, 12, 14, 16, 17, 19, 15, 15, 12, 11, 15, 1, 14, 14, 17, 18, 19, 2, 5, 10, 16, 20, 13, 6, 2, 5, 10, 13, 19, 6, 17, 14, 18, 1, 1, 1, 6, 9, 12, 14, 5, 13, 14, 9, 14, 10, 5, 5, 6, 12, 13, 14, 15, 16, 18, 19, 6, 10, 15, 15, 17, 2, 3, 9, 10, 12, 16, 19, 2, 4, 9, 11, 14, 7, 14, 14, 19, 14, 19, 1, 8, 11, 15, 16, 17, 18, 19, 1, 4, 10, 13, 14, 20, 17, 3, 11, 4, 7, 9, 14, 15, 16, 17, 20, 3, 8, 3, 5, 7, 10, 11, 15, 16, 18, 15, 5, 15, 18, 8, 19, 13, 2, 2, 3, 11, 2, 5, 14, 17, 1, 15, 1, 5, 11, 14, 15, 17, 17, 5, 13, 14, 11, 2, 2, 2, 8, 14, 16, 4, 8, 19, 6, 16, 6, 4, 14, 16, 9, 5, 20, 1, 4, 20, 1, 10, 12, 18, 18, 4, 4, 6, 9, 11, 12, 17, 9, 18, 8, 4, 17, 4, 6, 8, 14, 5, 8, 13, 15, 15, 15, 3, 8, 16, 19, 2, 8, 11, 17, 8, 13, 14, 12, 1, 8, 9, 10, 11, 12, 13, 20, 7, 13, 14, 15, 16, 2, 3, 4, 6, 10, 15, 16, 14, 15, 19, 20, 20, 3, 7, 8, 14, 3, 5, 6, 7, 11, 17, 6, 11, 16, 8, 9, 18, 12, 19, 1, 4, 5, 9, 14, 18, 20, 8, 3, 20, 11, 3, 5, 8, 11, 12, 13, 16, 20, 10, 13, 18, 19, 2, 8, 11, 12, 14, 17, 19, 5, 1, 9, 10, 11, 18, 19, 20, 8, 9, 14, 17, 20, 3, 13, 14, 15, 17, 12, 5, 8, 11, 17, 19, 20, 5, 11, 13, 19, 5, 8, 10, 11, 14, 19, 19, 20, 5, 6, 15, 17, 2, 5, 10, 12, 14, 15, 16, 17, 11, 4, 5, 10, 14, 15, 17, 11, 19, 20, 2, 4, 5, 12, 17, 2, 19, 3, 11, 14, 19, 5, 8, 17], \"Freq\": [1.0115832405808942, 0.9811296640795993, 0.023929991806819494, 1.003539078776599, 1.0022330241989124, 0.9928231562376444, 1.0007699727070138, 0.988785102149033, 0.9906440359232612, 0.991752249017552, 0.10064696619331745, 0.8932418249656924, 0.9725268907011347, 0.9921625004767198, 0.01814774032423668, 0.9799779775087808, 0.9842564460330818, 0.004962089642584273, 0.019848358570337093, 0.798896432456068, 0.17863522713303384, 1.0021191441871478, 0.25664832659831394, 0.10158996261183259, 0.43309405113465477, 0.21387360549859494, 0.993257702328862, 1.000828354965512, 1.0004573442166393, 0.9937756679279772, 0.9945952559752355, 0.9937756679279772, 1.0021191441871478, 1.0026282838729963, 0.9990770080043, 1.0015183992555772, 0.9958875060238607, 1.001766061973608, 0.9999323592526689, 0.9926226448037916, 0.12784274254423758, 0.5229930376809719, 0.046488270016086394, 0.03486620251206479, 0.2673075525924968, 0.9873097059044482, 0.012990917182953267, 0.9953307819660228, 1.0090473379151723, 0.0566018909815698, 0.019592962262851087, 0.032654937104751806, 0.19592962262851085, 0.05007090356061944, 0.0021769958069834537, 0.10884979034917269, 0.5355409685179296, 1.002853006602526, 1.0037771937743631, 0.9929370979269181, 0.9731939535545263, 0.02905056577774705, 0.9971942258276593, 1.001226535974675, 1.0011603165102707, 0.5052136528381335, 0.5052136528381335, 1.0022330241989124, 0.9973232212489285, 1.0007027146879355, 0.04847809989620781, 0.31383190985439796, 0.012757394709528372, 0.061235494605736185, 0.07654436825717023, 0.4873324779039838, 0.9988505276814136, 0.9816812806230849, 0.06866067761260107, 0.09154757015013476, 0.8468150238887465, 0.9947071424934268, 0.2110321290074002, 0.3604656906288566, 0.09239785107891577, 0.06958356686189952, 0.08783499423551253, 0.17795141689272667, 1.0034443242647537, 0.9995213565374735, 0.19734140679496, 0.7455119812254045, 0.06578046893165333, 1.000585614454411, 1.0002794339708618, 0.9937756679279772, 0.9999323592526689, 0.9828297379600218, 1.0006166922037103, 0.011088129964489261, 0.033264389893467784, 0.5211421083309953, 0.4324370686150812, 1.001766061973608, 0.3212169531613592, 0.3658304188782146, 0.3122942600179881, 0.9944085300913292, 0.9932481668322221, 0.16948324500505388, 0.05214869077078581, 0.6192657029030815, 0.16296465865870566, 0.9958875060238607, 1.0047385953525725, 1.008051574555316, 0.9632683441497268, 0.033216149798266446, 1.0034243000208682, 0.8180986400327243, 0.1775717978365603, 0.9766218145153551, 0.9893824948883588, 1.0100486076941513, 0.14273485368631192, 0.35034918632094747, 0.27249381158295916, 0.24654202000362968, 0.025732027084906513, 0.26589761321070066, 0.30020698265724266, 0.23158824376415862, 0.11150545070126157, 0.07719608125471954, 0.025739716349737585, 0.9781092212900283, 0.9937756679279772, 0.3679941110496488, 0.35015197233209006, 0.006690802019084523, 0.05798695083206587, 0.217451065620247, 0.9947071424934268, 0.9860413805084287, 0.9964792050177607, 1.0037771937743631, 0.07777506854741079, 0.11367125403083114, 0.08375776612798085, 0.4845985040261749, 0.1196539516114012, 0.07777506854741079, 0.04786158064456048, 0.13017358617035862, 0.06675568521556852, 0.3337784260778426, 0.4706275807697581, 0.025203920063335324, 0.8401306687778441, 0.13442090700445505, 0.020776509037511538, 0.81028385246295, 0.020776509037511538, 0.14543556326258075, 0.9935180680416218, 0.8381760652002994, 0.0338656996040525, 0.05926497430709188, 0.067731399208105, 0.029509583866000076, 0.9738162675780025, 0.9975674073869871, 0.9913782574993083, 0.8862720337184297, 0.11976649104303104, 0.9945952559752355, 0.9794916957275716, 0.028808579286105043, 1.0031790609065707, 1.0067574264294878, 0.03738020006739275, 0.28035150050544566, 0.6915337012467659, 1.0011269327862573, 0.13511438283087526, 0.8557244245955434, 0.9961870074679859, 1.0014181640370288, 0.9359938527819213, 0.06933287798384602, 0.9822344539550352, 0.011555699458294532, 0.9908442512559609, 0.9982578072353937, 0.14800764683818554, 0.013455240621653231, 0.013455240621653231, 0.17491812808149199, 0.2825600530547178, 0.36777657699185495, 0.0946278606463644, 0.2050270314004562, 0.6939376447400056, 0.0157713101077274, 0.3523593710376797, 0.001525365242587358, 0.37218911919131537, 0.2730403784231371, 1.0012185922555321, 1.0038295451588664, 0.9945059611586907, 0.9708568942401704, 0.021259640019857747, 0.007086546673285916, 0.9925492050654676, 1.000228198294954, 0.6063384711589117, 0.3527787468560941, 0.044097343357011765, 0.9903112366422113, 0.9277107585704261, 0.07730922988086884, 0.04024860458092085, 0.9659665099421004, 0.9660266623146346, 0.038641066492585384, 0.025761158844721785, 0.07728347653416535, 0.9016405595652626, 0.9974158493481798, 1.0051721016959994, 0.558427809975017, 0.04384350574184017, 0.025383082271591677, 0.07384169388099397, 0.20075710523895235, 0.09922477615258565, 0.9975913457275493, 0.04073670658016293, 0.09776809579239103, 0.2281255568489124, 0.3910723831695641, 0.19553619158478205, 0.04073670658016293, 0.008147341316032586, 0.9816812806230849, 0.0023875247465233946, 0.10266356410050596, 0.1265388115657399, 0.07162574239570184, 0.350966137738939, 0.1671267322566376, 0.15041405903097385, 0.026262772211757338, 0.031114701430399384, 0.9645557443423809, 0.04346999187032781, 0.4636799132834966, 0.29462994489888844, 0.19802996296482667, 0.02395758230085248, 0.9742750135680008, 0.9885638021301817, 0.001498316962896961, 0.1648148659186657, 0.04195287496111491, 0.3311280488002284, 0.04944445977559971, 0.023973071406351375, 0.3880640933903129, 1.0092470590566351, 1.0053868711598832, 0.9940804530237233, 0.18720694673507948, 0.1219681622667942, 0.06949348780317344, 0.61976845244871, 1.001226535974675, 1.0110319883408432, 0.9962488514724057, 0.9867865603239342, 1.0090473379151723, 0.9890311186295072, 0.9294658592884496, 0.07278949500451713, 0.963410736847906, 0.03211369122826353, 0.13586839865089104, 0.23352381018121898, 0.01698354983136138, 0.08067186169896655, 0.5392277071457238, 1.0022330241989124, 1.0006794758295707, 0.9993267395073456, 0.6978907616702867, 0.317223073486494, 1.00141673449618, 0.9926584973449412, 0.9607556577562247, 0.04367071171619203, 0.9958875060238607, 0.9971942258276593, 0.9932481668322221, 1.0004573442166393, 1.006859218149482, 0.9966566043020796, 0.9387788765967671, 0.06705563404262621, 0.5345803077734644, 0.481122276996118, 0.050603074997402894, 0.5132597606879437, 0.26747339641484386, 0.15180922499220867, 0.014458021427829398, 0.9986895786356959, 0.7405278587016616, 0.2538952658405697, 0.010578969410023736, 1.0055907944002949, 0.9754344427699, 1.007195751367651, 0.9880549608524679, 0.9960611429981281, 0.9931620384962352, 0.02056224989807864, 0.8841767456173815, 0.1028112494903932, 0.1664932413079711, 0.8324662065398556, 1.003069242403131, 1.002919495940039, 0.9949943944395745, 1.002367600523237, 0.9959566467701191, 1.0030708553902956, 0.05276100175158575, 0.817795527149579, 0.13190250437896436, 0.9975913457275493, 0.9737440216595497, 0.02434360054148874, 0.1342408013511161, 0.18305563820606743, 0.0854259644961648, 0.6020496545443995, 0.7603252164441295, 0.23394622044434757, 0.7526818015055778, 0.2408581764817849, 0.9735742130281196, 1.0033500538758928, 0.9931720924780627, 1.0027491343342791, 0.12608044343318114, 0.06304022171659057, 0.8195228823156775, 0.31846613256478823, 0.009099032358993949, 0.33059817571011346, 0.05762720494029501, 0.06369322651295764, 0.006066021572662632, 0.17894763639354766, 0.036396129435975796, 0.9912512571982135, 0.9913782574993083, 0.9959566467701191, 0.4301383480208937, 0.4896959654391713, 0.07941015655770345, 0.9926068354993176, 0.9995213565374735, 0.5986062268660906, 0.06108226804756026, 0.3298442474568254, 0.012216453609512052, 0.993257702328862, 0.9971942258276593, 1.0067085974528167, 0.11239270452294499, 0.14049088065368123, 0.028098176130736247, 0.2950308493727306, 0.07024544032684062, 0.35825174566688717, 0.05532108465170323, 0.1797935251180355, 0.7606649139609194, 0.9990200959385902, 0.9960371383789295, 0.9864001830218133, 0.922968324879899, 0.08790174522665704, 0.9931545703306691, 1.001766061973608, 1.0059115207141252, 0.9985214268953907, 0.994112270669131, 0.7606407601670548, 0.18502072544604037, 0.061673575148680125, 0.08371046316056584, 0.004650581286698103, 0.3999499906560368, 0.3580947590757539, 0.15346918246103738, 1.0090415176024172, 0.994112270669131, 1.0007699727070138, 0.2218655207295696, 0.7866141189502923, 1.003772882536969, 0.004815857758060057, 0.17337087929016204, 0.23116117238688272, 0.16373916377404193, 0.02889514654836034, 0.11076472843538131, 0.14929159049986176, 0.12039644395150143, 0.024079288790300284, 1.0031768390873688, 0.024568981531037357, 0.8599143535863074, 0.12284490765518678, 0.2996420569644181, 0.161968679440226, 0.3401342268244746, 0.2024608493002825, 0.9944085300913292, 1.003274909992969, 0.027403784939555472, 0.9591324728844415, 0.2212852407000405, 0.0737617469000135, 0.7130302200334638, 1.0002524726198445, 1.0090726149541909, 0.9839082861474361, 1.0078002344032166, 1.0012185922555321, 1.0032246084149143, 1.0017773526340075, 0.928217364018995, 0.0742573891215196, 1.0036511495574814, 0.9960358934826732, 0.9900369724024707, 0.14827842414387785, 0.005703016313226071, 0.6558468760209981, 0.18819953833646033, 0.037126594613176765, 0.9652914599425959, 0.1121014731392685, 0.08007248081376322, 0.11610509717995667, 0.6365762224694176, 0.05605073656963425, 0.04187147696294283, 0.21982525405544984, 0.21633596430853794, 0.38033258241339735, 0.13957158987647608, 0.9948501714667612, 0.9906903198170584, 0.9926068354993176, 0.9524958384124966, 0.05602916696544098, 0.36681533082358164, 0.14152717488468897, 0.05487788413896103, 0.13575055550164045, 0.3032725176100478, 0.05444973113828596, 0.6046785931672809, 0.002865775323067682, 0.15475186744565483, 0.002865775323067682, 0.18054384535326398, 0.9897874060412692, 0.17165023571161217, 0.17165023571161217, 0.6675286944340474, 0.9935180680416218, 0.9960358934826732, 1.0075765293542374, 0.9888969179830451, 0.00852497343088832, 0.9867865603239342, 0.5327274430803679, 0.07520858019958136, 0.16608561460740884, 0.22562574059874407, 1.0128798152210212, 0.011067090401970119, 0.13723192098442946, 0.092963559376549, 0.15493926562758167, 0.23683573460216054, 0.36742740134540797, 0.7712219180532346, 0.22851019794169916, 1.0084701889143595, 0.11210502659336503, 0.021767966328808747, 0.21876806160452789, 0.06203870403710492, 0.2786299690087519, 0.2481548161484197, 0.05006632255626012, 0.008707186531523498, 0.993257702328862, 0.04394091864064296, 0.13382007040559446, 0.06191674899363326, 0.12383349798726652, 0.37349780844546515, 0.12183618350360093, 0.09986572418327945, 0.03794897518964619, 0.11775355014239429, 0.8766097621711575, 0.020989537216804677, 0.3127441045303897, 0.10284873236234292, 0.21829118705476863, 0.2413796779932538, 0.10494768608402338, 0.14212951461883155, 0.07049623925094045, 0.053440697496680664, 0.28767013758851506, 0.2751627403020579, 0.022740722339013048, 0.07504438371874306, 0.0739073476017924, 0.9027258118148113, 0.05208033529700835, 0.0347202235313389, 0.9999242990413486, 0.05894556533956814, 0.05108615662762572, 0.06680497405151056, 0.023578226135827256, 0.6523309230912208, 0.06680497405151056, 0.0825237914753954, 0.003929704355971209, 0.9935180680416218, 0.207072055120477, 0.5370931429687372, 0.012942003445029812, 0.23295606201053662, 0.012942003445029812, 0.999156789582663, 0.9123472339570571, 0.03918055605950552, 0.05037500064793567, 0.16848520579865267, 0.8213653782684317, 1.003652876947353, 0.9905256048611966, 0.028712157587693802, 0.9762133579815893, 0.030419043984410716, 0.9734094075011429, 0.9987796263447271, 1.0092470590566351, 0.034058646352252336, 0.9706714210391915, 0.11584453685861067, 0.8862107069683717, 0.10057961888693329, 0.9052165699823996, 0.018817422698182408, 0.4296644849418317, 0.0031362371163637347, 0.0031362371163637347, 0.0031362371163637347, 0.08467840214182085, 0.34498608280001086, 0.11290453618909446, 0.12542637275248597, 0.03420719256885981, 0.17103596284429906, 0.05701198761476635, 0.12542637275248597, 0.281259138899514, 0.007601598348635513, 0.12542637275248597, 0.07221518431203737, 0.13347060488666362, 0.14080415460571108, 0.06746865741523655, 0.054268267920951144, 0.17600519325713884, 0.11146995572952127, 0.31534263791904044, 0.07480568581632688, 0.935071072704086, 0.9805860733647197, 0.9926584973449412, 0.9961870074679859, 0.9965993693606888, 0.8345888598227438, 0.1726735572047056, 0.9885638021301817, 1.0043375896847817, 0.21196707294292708, 0.42393414588585415, 0.3587135080572612, 0.021863006321883593, 0.9729037813238198, 1.0051721016959994, 1.001651058410632, 0.9974426445121871, 1.0018480616867798, 0.4490608416050975, 0.538873009926117, 0.9993837305322674, 0.5009773255507041, 0.09823084814719688, 0.13261164499871578, 0.18172706907231423, 0.0442038816662386, 0.04911542407359844, 1.0056372616407128, 0.998490925601766, 0.29680986292766876, 0.08552148592831134, 0.5911043880339166, 0.025153378214209217, 0.0025153378214209216, 1.0020054728245655, 0.994112270669131, 1.0043159408365987, 0.0029482832521437823, 0.2004832611457772, 0.5071047193687306, 0.19458669464148962, 0.09434506406860103, 0.994112270669131, 0.018660686057231538, 0.018660686057231538, 0.018660686057231538, 0.18660686057231538, 0.7650881283464931, 0.320329166164926, 0.5266428664067427, 0.1465913133297119, 0.00542930790110044, 0.18709716572728713, 0.0855301329039027, 0.1710602658078054, 0.31539236508314117, 0.24055349879222632, 0.9904023913065414, 0.9861653262151361, 0.6139515810873875, 0.3990685277068018, 0.4112752028973478, 0.13899578616438144, 0.4493562402026578, 1.0040652733773232, 0.9988505276814136, 0.999977467087036, 0.5446148237429121, 0.13758690284031466, 0.13185411522196822, 0.1060565709394092, 0.020064756664212553, 0.05732787618346444, 0.002866393809173222, 0.4477530417365539, 0.2665196677003297, 0.29850202782436924, 1.0058078858248125, 0.016575089811305028, 0.0033150179622610056, 0.006630035924522011, 0.13923075441496224, 0.0033150179622610056, 0.1790109699620943, 0.27514649086766346, 0.059670323320698104, 0.31492670641479553, 0.987711555040859, 0.01702950956966998, 0.10316608578671764, 0.9027032506337793, 1.0004573442166393, 0.9882925439809234, 1.0000058810035148, 1.000228198294954, 0.9999227278483619, 0.9957284190069957, 0.14378148297072813, 0.8626888978243688, 0.9952259909421615, 1.0053868711598832, 0.02957695944367539, 0.7394239860918848, 0.23661567554940313, 0.9953212494716389, 0.015630756448463637, 0.7216199227040712, 0.07033840401808636, 0.04689226934539091, 0.0989947908402697, 0.04949739542013485, 0.16735844625559226, 0.47604180268257357, 0.05578614875186409, 0.13760583358793144, 0.16363936967213466, 0.17054326729080066, 0.003279678217130782, 0.8231992324998263, 0.37539107389368587, 0.5666280360659409, 0.0566628036065941, 1.0078075271258486, 0.9986895786356959, 1.0030788746232895, 0.9897874060412692, 1.003539078776599, 0.7263042222107652, 0.0703783161056943, 0.2026895503843996, 0.977157898618163, 0.04192015517504525, 0.7964829483258598, 0.167680620700181, 0.994112270669131, 0.9935180680416218, 0.07191197798041844, 0.011985329663403073, 0.9108850544186335, 0.9867865603239342, 0.9154144010090184, 0.06102762673393456, 0.03051381336696728, 1.0019055882111922, 1.0034546764057977, 1.0027431498096762, 1.0024459884245855, 0.04004396647424253, 0.2823099636434098, 0.06306924719693198, 0.2122330223134854, 0.11112200696602301, 0.158173667573258, 0.13214508936500033, 0.42051747141095897, 0.044600337876919895, 0.28459263216701264, 0.1656583978285596, 0.08495302452746646, 0.07884072486856408, 0.04911389418041697, 0.03231177248711643, 0.23393723280672296, 0.04394401058247834, 0.21842758201290707, 0.15251156613918954, 0.17706851322939804, 0.014217179894331229, 0.5528613527432918, 0.4453605341543185, 0.06416203897217435, 0.07896866335036842, 0.0074033121890970405, 0.14313070232254277, 0.009871082918796053, 0.09377528772856251, 0.02220993656729112, 0.19248611691652304, 0.1258563072146497, 0.09624305845826152, 0.16780840961953292, 0.07862935603836792, 0.12434409792113996, 0.28343139967318665, 0.04205756253215028, 0.1517729430508032, 0.11702973921989643, 0.0018285896753108817, 0.19931627460888612, 0.05501469508307345, 0.11736468284389004, 0.1687117315880919, 0.26407053639875255, 0.09169115847178909, 0.14303820721599098, 0.05868234142194502, 0.10636174382727534, 0.47349935568821094, 0.5185945324204215, 1.002367600523237, 0.9944085300913292, 0.11841838501235373, 0.8733355894661088, 0.8964518627456697, 0.10546492502890231, 0.7680476256827211, 0.005840666355001682, 0.03212366495250925, 0.1927419897150555, 0.9225428902594283, 0.007042312139384948, 0.07042312139384949, 0.9938675857467115, 0.05205295522719879, 0.10875349574254034, 0.07529088166791253, 0.5381903763669303, 0.037180682305141995, 0.10131735928151193, 0.08737460341708368, 0.9940804530237233, 0.31763763570094056, 0.6784112466205273, 0.06342937108973819, 0.7849384672355101, 0.10967995417600561, 0.04096480216212258, 0.9834437141020539, 0.011175496751159702, 0.6423505061383711, 0.01668442873086678, 0.08342214365433391, 0.25860864532843514, 0.3165589307128659, 0.0059728100134503, 0.0059728100134503, 0.2508580205649126, 0.0119456200269006, 0.4061510809146204, 0.26821368193557904, 0.15473866265514177, 0.07994830903848991, 0.49516372049645363, 0.9885638021301817, 1.000228198294954, 0.9960358934826732, 0.15456016140079487, 0.36984038620904486, 0.4581604784380705, 0.011040011528628204, 0.10215751700851693, 0.1516884343459797, 0.28789845702400224, 0.10215751700851693, 0.0278611410023228, 0.03405250566950564, 0.2693243630224537, 0.021669776335139956, 0.9903112366422113, 0.9908442512559609, 0.15505898265614476, 0.21434624073055306, 0.10489284120856852, 0.03192390819391216, 0.09121116626832046, 0.18242233253664092, 0.22346735735738513, 1.0018480616867798, 0.9962470249514751, 0.26242787820062274, 0.09747321190308846, 0.03748969688580325, 0.1049711512802491, 0.21744024193765885, 0.2849216963321047, 0.9993061529616045, 0.997817013241411, 1.0019543811227267, 0.4197480357516228, 0.2098740178758114, 0.0233193353195346, 0.2098740178758114, 0.1399160119172076, 0.05816056718051453, 0.13645363838505334, 0.19908809534868435, 0.02013250402402426, 0.22816837893894162, 0.053686677397398026, 0.19908809534868435, 0.026843338698699013, 0.01789555913246601, 0.060397512072072786, 0.06891516215328494, 0.6526671239222868, 0.2776875651470599, 0.18204227693386585, 0.8138360615866944, 0.9951804709260708, 0.9975674073869871, 0.6848476391109416, 0.048917688507924405, 0.1467530655237732, 0.10598832510050288, 0.016305896169308134, 0.2108264285938888, 0.04216528571877776, 0.2529917143126666, 0.48490078576594425, 0.056963666869286875, 0.5411548352582253, 0.05477275660508353, 0.3461638217441279, 0.0021909102642033414, 0.9261219238840576, 0.07717682699033813, 0.1265819048356615, 0.6411648657980246, 0.22839778481217185, 0.002751780539905685, 1.0084701889143595, 0.9980474527244187, 0.015629645193516062, 0.19276562405336475, 0.15629645193516062, 0.250074323096257, 0.026049408655860102, 0.06251858077406425, 0.2969632586768052, 0.09422420990379657, 0.7134118749858883, 0.013460601414828082, 0.15479691627052294, 0.026921202829656165, 0.0697378426327005, 0.0697378426327005, 0.8019851902760557, 0.0697378426327005, 0.5293985880217703, 0.469239657564751, 0.03806592951267641, 0.2433912462780219, 0.2941458189615904, 0.04614052062142595, 0.3771987560801571, 0.9945952559752355, 1.010995732456613, 0.9816812806230849, 1.000585614454411, 1.0000975498962146, 0.8176478538409282, 0.031447994378497234, 0.15723997189248617, 0.993257702328862, 0.9824072210516999, 0.06407603736492344, 0.30436117748338637, 0.01601900934123086, 0.6087223549667727, 0.01601900934123086, 0.16186266404000932, 0.12139699803000699, 0.728381988180042, 1.005171657711128, 1.0032401787053449, 0.10427784465873259, 0.21848691261829686, 0.41711137863493036, 0.01986244660166335, 0.0794497864066534, 0.1588995728133068, 0.9929370979269181, 0.010783483439410933, 0.8438075791339055, 0.0647009006364656, 0.08357199665543473, 0.061687516987365465, 0.059484391380673844, 0.16303129489518017, 0.10575002912119795, 0.1564219180751053, 0.02203125606691624, 0.19828130460224616, 0.052875014560598975, 0.1013437779078147, 0.07710939623420683, 0.9974426445121871, 0.033811369021473345, 0.0480477349252516, 0.5107296267980448, 0.12812729313400426, 0.05160682640119616, 0.20642730560478464, 0.023134094593639656, 1.0019037660176073, 0.5972440565178864, 0.4006827214613668, 0.9914137993251252, 0.9867865603239342, 0.13457562067471215, 0.44148548940768884, 0.042599477048110325, 0.002904509798734795, 0.08519895409622065, 0.041631307115198725, 0.04647215677975672, 0.16168437879623693, 0.043567646981021925, 0.06222065242359594, 0.6652823605292181, 0.09093787661910176, 0.1866619572707878, 0.9999227278483619, 1.0004573442166393, 0.3298204531196436, 0.08428007554566345, 0.026544905683673528, 0.09456622649808695, 0.0006636226420918382, 0.08063015101415835, 0.3523836229507661, 0.0311902641783164, 0.3430631127798316, 0.6659460424549672, 0.9816842013243239, 1.003742996007688, 0.05879893481199336, 0.20341253124149053, 0.05403145361102092, 0.11918703002431086, 0.017480764403565593, 0.07310137841491066, 0.0015891604003241448, 0.06833389721393822, 0.1382569548282006, 0.26380062645380803, 0.9949943944395745, 1.0079315109328324, 1.0014278570487163, 0.05700513403860232, 0.9248591574193928, 0.013759859940352283, 0.004914235692982959, 0.9818879543850144, 1.0099115220694117, 0.9795261982307254, 0.018837042273667795, 0.9988636925915486, 0.9899923836166823, 0.014776005725622125, 0.9959566467701191, 0.9488966741413323, 0.052716481896740684, 0.9997519066170325, 0.04372622829368594, 0.9474016130298621, 1.002447608540969, 1.009359708010422, 0.05694407945146824, 0.9205959511320698, 0.01898135981715608, 1.0041494857715685, 0.056914774535765905, 0.8537216180364885, 0.08537216180364886, 0.9873349671757513, 0.9171398340102023, 0.08433469738024849, 0.9974205342390559, 0.031589735269901116, 0.5974972785335582, 0.024369224351066573, 0.018953841161940668, 0.10921022764737241, 0.21932301915959915, 0.9792542047310975, 1.000679565766391, 0.9937756679279772, 0.6642822245083965, 0.3374131934010903, 0.9914137993251252, 0.9995535234369066, 0.0017761426548600343, 0.0017761426548600343, 0.014209141238880275, 0.8099210506161757, 0.058612707610381135, 0.11189698725618216, 0.0825084624139777, 0.152323315225805, 0.1396297056236546, 0.025387219204300832, 0.6029464561021448, 0.9871014425555223, 0.028298693686011032, 0.3348678752844639, 0.5801232205632262, 0.056597387372022065, 0.9945059611586907, 0.9975559032699765, 0.11196583355266554, 0.40942730179706055, 0.08021432851534248, 0.07352980113906393, 0.32252844590543955, 0.7200879895349215, 0.27843402262016964, 0.6467752501784073, 0.010069554793196761, 0.017815366172578884, 0.002323743413814637, 0.037179894621034194, 0.022462853000208158, 0.2641321680369304, 0.17871079708983842, 0.03785499642789681, 0.5625428538936293, 0.0008803487541371351, 0.05194057649409097, 0.048419181477542435, 0.048419181477542435, 0.03961569393617108, 0.03081220639479973, 1.001354085264553, 0.03822500887835293, 0.06498251509319998, 0.3746050870078587, 0.2102375488309411, 0.2981550692511528, 0.011467502663505878, 0.9997270095700946, 0.7721010996154503, 0.23163032988463508, 1.0038449572298063, 0.7573722980388657, 0.011475337849073723, 0.04590135139629489, 0.18360540558517957, 1.001766061973608, 0.6061013081595735, 0.24571674655117845, 0.14743004793070708, 1.0061657551211611, 0.9816812806230849, 0.9908442512559609, 1.0014269260109552, 0.6476427819797077, 0.07771713383756493, 0.02590571127918831, 0.2590571127918831, 1.004864141706448, 0.9860413805084287, 0.9998009495794703, 0.9993837305322674, 0.9966259022215337, 0.14104420687890662, 0.8664144136847122, 0.8692300539776607, 0.003369108736347522, 0.12802613198120583, 0.08017541715135444, 0.342081779845779, 0.5719179756796617, 0.0053450278100902965, 0.6185768615964353, 0.19169439200514532, 0.15464421539910883, 0.03382842211855505, 1.0038310408594298, 0.07246644474309645, 0.6470218280633612, 0.279513429723372, 0.630908453423187, 0.23243995652433208, 0.021130905138575642, 0.060374014681644696, 0.05735531394756246, 0.06983559361304982, 0.20950678083914948, 0.5936025457109235, 0.1257040685034897, 0.03799185421383421, 0.713402595793109, 0.049248699906822124, 0.04362027706032817, 0.15618873399020733, 1.0062802426562265, 0.12410333892481842, 0.12410333892481842, 0.4964133556992737, 0.25948879957007487, 0.9641845147171831, 0.04017435477988263, 1.002447608540969, 0.37151330249725484, 0.10565974658178807, 0.06816757843986328, 0.16701056717766502, 0.2522200402274941, 0.03408378921993164, 0.9789853771030633, 0.0565165347462718, 0.26845354004479105, 0.0847748021194077, 0.5934236148358539, 0.9995535234369066, 0.18363080699053005, 0.016271084163717853, 0.23476850007650044, 0.0906531831978566, 0.47418588134263456, 0.061373264868770386, 0.11178701815383177, 0.004383804633483599, 0.4383804633483599, 0.3331691521447535, 0.05041375328506138, 1.0046968958523022, 0.8190899734853035, 0.03150346051866552, 0.1575173025933276, 0.9730404112066693, 0.1136991020762756, 0.08121364434019684, 0.04872818660411811, 0.29236911962470863, 0.1136991020762756, 0.3573400350968661, 1.0037596136502611, 0.04662805083040994, 0.20108346920614287, 0.16028392472953415, 0.06702782306871428, 0.2622827859210559, 0.017485519061403727, 0.08451334213011802, 0.1631981779064348, 0.9933467731184279, 0.9938675857467115, 1.0010538790211314, 0.9997830910386611, 1.0075765293542374, 0.9974426445121871, 0.9897114583767167, 1.002846960583351, 1.000228198294954, 0.9832887225152813, 0.011302169224313579, 1.0015001728588557, 0.997142387696961, 0.9754973558753981, 0.02869109870221759, 1.0043312395650346, 0.994112270669131, 1.000914662994904, 0.9903112366422113, 0.9971942258276593, 1.005974642379602, 0.26386523907953957, 0.743620219224157, 0.9295889872641732, 0.07150684517416717, 0.6620604063029847, 0.34845284542262356, 0.5137313537657533, 0.2642046962223874, 0.22017058018532282, 0.9885638021301817, 0.9948501714667612, 0.9959566467701191, 0.9999323592526689, 0.33826187306761474, 0.06765237461352296, 0.5863205799838656, 0.9908442512559609, 1.0091731177325562, 1.0035633904433012, 0.8802152706339337, 0.11481068747399135, 0.9125876400918868, 0.09606185685177755, 0.5820876077503553, 0.2609358241639524, 0.16057589179320148, 0.059168019605232686, 0.9348547097626765, 0.2532122382931632, 0.16113506073201295, 0.11509647195143782, 0.08056753036600647, 0.264721885488307, 0.1381157663417254, 0.1802882858389055, 0.014233285724124118, 0.40802085742489136, 0.07591085719532863, 0.32262114308014667, 0.4728277229559596, 0.009456554459119191, 0.4539146140377212, 0.06619588121383434, 0.9802022054073251, 1.0057296841530416, 0.9462799018902436, 0.055663523640602564, 1.000445334538392, 0.15240094980362873, 0.23446299969789036, 0.2520477246752321, 0.09378519987915615, 0.1289546498338397, 0.06447732491691985, 0.07620047490181436, 0.991752249017552, 0.18306868380159746, 0.6132800907353515, 0.2105289863718371, 0.15202483499032068, 0.30404966998064137, 0.5574243949645091, 0.03067345726197708, 0.9508771751212894, 0.13398851160389585, 0.4326712353875804, 0.09211710172767841, 0.1619027848547075, 0.033497127900973964, 0.033497127900973964, 0.09769995637784074, 0.016748563950486982, 0.0334486908770406, 0.9031146536800962, 0.0668973817540812, 0.1948410332325159, 0.05935554654765385, 0.034839125147535954, 0.43871490926526757, 0.2716161423539377, 0.4803021269775866, 0.5128649830438637, 0.03945704663015015, 0.9666976424386787, 0.10013522708779403, 0.019256774439960392, 0.6354735565186929, 0.24263535794350094, 0.999156789582663, 0.1446777373588233, 0.5600428542922192, 0.05600428542922192, 0.0700053567865274, 0.17267988007343427, 0.9935180680416218, 1.004484909285835, 0.06278339632030976, 0.2888036230734249, 0.15695849080077437, 0.21974188712108414, 0.27624694380936293, 0.06820883812088148, 0.42874126818839786, 0.4969501063092793, 0.5473991322674467, 0.10526906389758592, 0.06316143833855155, 0.04210762555903436, 0.2526457533542062, 0.09335177768973733, 0.02366664786500383, 0.05916661966250958, 0.14331470096030097, 0.23666647865003831, 0.32344418748838566, 0.12096286686557513, 1.0002794339708618, 1.001651058410632, 1.003742996007688, 1.0032401787053449, 0.7257946983383925, 0.2682284754728842, 0.9748206219917902, 0.20844770760496656, 0.5929977888761979, 0.19407200363221025, 0.9884756290342526, 0.10338638237423363, 0.027834795254601363, 0.11133918101840545, 0.3817343349202473, 0.0039763993220859085, 0.36980513695398953, 0.9943349191979539, 0.004160397151455874, 0.9914137993251252, 1.0068285798666503, 0.021551671826543703, 0.01588017924061115, 0.6159240948322753, 0.0011342985171865106, 0.03629755254996834, 0.28130603226225465, 0.028357462929662767, 1.0074820584249853, 0.9937756679279772, 1.0050783586180183, 1.0041545577914506, 0.9715602550250034, 0.08968036537008996, 0.2968729336389185, 0.29996536003099056, 0.08349551258594583, 0.13915918764324303, 0.08658793897801789, 1.0021525581538078, 0.9163851576007445, 0.08727477691435662, 0.4521266423166076, 0.14697229695140412, 0.2142308057257755, 0.06725850877437138, 0.11832515432528297, 0.014424366122602878, 0.7140061230688425, 0.06490964755171295, 0.20915330877774171, 0.9948501714667612, 0.1123395878077992, 0.7189733619699148, 0.15727542293091887, 0.5562155374302621, 0.03343981186955484, 0.13821788906082666, 0.2730917969346978, 0.07361856161538065, 0.2710501586748106, 0.08365745638111438, 0.5320614225838874, 0.030116684297201175, 0.010038894765733724, 0.22409062222402912, 0.7843171777841019, 0.007836123936104219, 0.04701674361662532, 0.250755965955335, 0.46233131223014895, 0.23508371808312659, 0.14697048575478833, 0.25719835007087954, 0.079609013117177, 0.5205204703815419, 0.9897874060412692, 0.10871618311599791, 0.19543028155375816, 0.6199410918162263, 0.03494448743014219, 0.04141568880609445, 1.0014278570487163, 0.9973260473702958, 0.7886907422307847, 0.20505959298000404, 0.09221852397885034, 0.0019212192495593821, 0.08261242773105343, 0.09606096247796911, 0.0019212192495593821, 0.170988513210785, 0.1287216897204786, 0.16522485546210686, 0.2593645986905166, 0.9880549608524679, 0.01966137444357363, 0.028992196213405187, 0.23660298059215726, 0.06531575238882088, 0.2572640859396414, 0.17695236999216268, 0.07464657415865243, 0.009330821769831554, 0.00833109086592103, 0.044654647041336724, 0.07831225413965769, 0.15088309250706486, 0.8497100472766285, 1.0113793174064583, 0.0718450596851129, 0.0993152295647149, 0.6402662671938003, 0.01267853994443169, 0.057053429749942604, 0.014791629935170305, 0.10354140954619213, 0.03173008279250979, 0.03173008279250979, 0.8408471940015093, 0.09519024837752936, 0.016376160422499175, 0.045443845172435215, 0.30910002797467195, 0.029477088760498517, 0.061410601584371914, 0.009416292242937026, 0.2972273116683601, 0.23131326596780089, 0.04935035001696784, 0.2878770417656457, 0.6662297252290658, 0.9973260473702958, 0.9824223878277419, 0.9981340894248875, 1.003922106314586, 0.997817013241411, 0.2926564266086305, 0.6998305853684642, 0.9839390573202663, 0.9836709459484946, 0.999977467087036, 0.2576300064438301, 0.1932225048328726, 0.547463763693139, 0.09319465978729713, 0.13681769202815963, 0.04362303224086249, 0.06940027856500851, 0.11104044570401361, 0.4342474573067675, 0.11104044570401361, 0.9946811554026052, 0.2576058893390389, 0.7417273020624051, 0.9955783971485338, 0.017715894717912822, 0.053147684153738474, 0.40746557851199494, 0.4428973679478206, 0.08857947358956413, 0.13010690321796284, 0.018586700459708977, 0.7434680183883591, 0.10780286266631207, 0.4799839563428049, 0.07162454892576571, 0.025864420445415395, 0.26212595336026756, 0.030838347454149123, 0.12981949492795034, 1.0082833145575425, 0.026706067926292362, 0.08679472076045018, 0.2607355579119597, 0.0010541868918273302, 0.033382584907865456, 0.15883082503531773, 0.035139563060911004, 0.07449587368913133, 0.028814441709947024, 0.0593858615729396, 0.23297530309383996, 0.0017569781530455502, 0.9993549646053058, 1.0007027146879355, 0.19543944380587394, 0.8013017196040831, 0.7705318209691276, 0.22584553373233052, 0.32756502578286917, 0.2509913833920686, 0.41690094190546984, 0.9938821884025368, 0.0582355133488068, 0.006988261601856816, 0.21197726858965674, 0.09783566242599542, 0.5217901996053089, 0.10249450349389996, 1.0027548093918024, 0.038537738154719635, 0.9634434538679909, 0.06006866462259164, 0.022826092556584823, 0.2198513125186854, 0.22345543239604088, 0.020423345971681155, 0.07808926400936912, 0.06127003791504347, 0.022826092556584823, 0.1141304627829241, 0.17780324728287125, 0.9868778155412489, 1.0097858061378355, 0.9960358934826732, 1.0115625476688714, 0.07616571999584727, 0.07616571999584727, 0.6950121949621063, 0.15233143999169454, 0.38217992630682857, 0.16985774502525713, 0.0026540272660196427, 0.4458765806913, 0.9573955858926254, 0.04559026599488693, 0.06691097025938376, 0.9367535836313727, 1.000228198294954, 0.358822523316109, 0.02743936943005539, 0.07176450466322179, 0.002110720725388876, 0.14986117150261022, 0.3883726134715532, 0.3101433212126308, 0.6009026848494721, 0.09691978787894712, 0.9999242990413486, 1.0043572269934269, 1.0062323196530507, 0.5604422703839134, 0.13343863580569365, 0.3202527259336648, 0.9992648131286876, 0.0717066049256697, 0.060674819552489746, 0.15996088791110932, 0.711550156570107, 0.8873269985797555, 0.11944786519342862, 1.0044895847380482, 0.12146504101334864, 0.12724909058541287, 0.19087363587811929, 0.1388171897295413, 0.05205644614857799, 0.07519264443683488, 0.3007705777473395, 1.010995732456613, 0.9908442512559609, 0.993257702328862, 1.0019265651493179, 1.0041224332550496, 0.14901521383991026, 0.8568374795794841, 0.9974388165194665, 1.004804568709465, 0.9914137993251252, 1.0024423318477447, 0.9940804530237233, 0.9867865603239342, 1.0021298524514524, 0.14106135769591577, 0.3103349869310147, 0.5203596750560447, 0.02821227153918315, 1.0128798152210212, 0.9766218145153551, 0.9730404112066693, 0.9980636469251104, 0.9988636925915486, 0.9953307819660228, 0.02641852381809489, 0.977485381269511, 0.9913782574993083, 0.9964870294329082, 0.010862957695030907, 0.9885291502478125, 0.07387849624275812, 0.08126634586703393, 0.627967218063444, 0.014775699248551625, 0.20685978947972275, 0.7902221259235027, 0.2107259002462674, 0.3187315643373551, 0.6640240923694898, 0.026560963694779595, 0.0692456792006551, 0.1766958710637406, 0.2292270759745824, 0.1766958710637406, 0.191022563312152, 0.1575936147325254, 0.9961073085486674, 1.0008176668092796, 1.0006166922037103, 0.9912512571982135, 0.9816812806230849, 0.8228567157841296, 0.18285704795202878, 1.0033772078376801, 1.0057601763886554, 0.007759418903849899, 0.1448424862051981, 0.5276404854617931, 0.2922714453783462, 0.02586472967949966, 0.002586472967949966, 0.8827690488019513, 0.12317707657701646, 1.0022330241989124, 1.0027491343342791, 0.05274322011180651, 0.9493779620125172, 1.008586422448071, 1.0104997604385415, 0.06358091647039686, 0.7884033642329211, 0.01907427494111906, 0.0731180539409564, 0.05722282482335718, 0.17130356944074632, 0.20556428332889556, 0.6166928499866867, 0.024181779719024462, 0.09823848010853688, 0.03476130834609766, 0.261465493211952, 0.5803627132565871, 0.06793805878296051, 0.3072653113138441, 0.2377832057403618, 0.08029043310713514, 0.12352374324174638, 0.17756538091001042, 0.004632140371565489, 0.9982578072353937, 0.999977467087036, 0.019388799938025305, 0.27144319913235426, 0.7173855977069362, 0.9994582609491374, 0.15962313109254947, 0.834951762637951, 0.9885638021301817, 0.013771439370364938, 0.9777721952959105, 1.0068285798666503, 0.9384776069654713, 0.05793071647935008, 0.9818943207065138, 0.02337843620729795, 1.0134350864834194, 1.0130351142606544, 1.0008718439559583, 0.07732224080927401, 0.9278668897112882, 0.7263388636944192, 0.23849932837727197, 0.03252263568780982, 1.0022297105114515, 0.03349310579073678, 0.9713000679313665, 0.9982205203424198, 1.0064728822405133, 1.0090726149541909, 0.9803281939467996, 1.0040652733773232, 0.9997519066170325, 0.1348830020854245, 0.8767395135552593, 0.06721111908853637, 0.9297538140580864, 0.9880549608524679, 1.0010538790211314, 0.7201911589486589, 0.28807646357946354, 0.5053104349094535, 0.5053104349094535, 1.0005696703130773, 0.9931720924780627, 1.0030101543718484, 0.3523395988398592, 0.6496261353609905, 1.0070646664114253, 0.9743847968084035, 0.9998009495794703, 0.6487583926082544, 0.0018859255599077164, 0.0697792457165855, 0.03771851119815433, 0.20556588602994108, 0.03771851119815433, 0.9926068354993176, 0.07620217268952464, 0.06667690110333406, 0.5000767582750055, 0.3571976844821468, 0.923237912869967, 0.02769713738609901, 0.01846475825739934, 0.02769713738609901, 0.9873349671757513, 0.18454342505222016, 0.23375500506614552, 0.024605790006962686, 0.5536302751566604, 0.9914137993251252, 0.983437870912828, 0.9981555545926377, 1.0078075271258486, 0.9955783971485338, 1.0050783586180183, 1.0064815098482012, 0.9999242990413486, 0.05268873968094805, 0.948397314257065, 1.0037771937743631, 1.0068190244624782, 0.7589799929497336, 0.25299333098324456, 1.001354085264553, 0.13986140419701967, 0.008476448739213313, 0.5382544949400454, 0.055096916804886535, 0.25853168654600606, 0.02416292187817542, 0.10763483382096324, 0.0593089900646124, 0.04173595597139391, 0.16474719462392332, 0.6018764176927331, 0.002196629261652311, 1.0035552186003442, 0.7961144526621361, 0.21073617864585956, 0.053581103031336896, 0.30005417697548664, 0.050902047879770054, 0.17681764000341177, 0.1366318127299091, 0.19289197091281282, 0.09108787515327273, 1.0058363515026485, 0.9867865603239342, 0.11502623815527774, 0.18004106841695647, 0.0050011407893599015, 0.6051380355125481, 0.09502167499783813, 0.9947222801278118, 0.9966566043020796, 1.00616217262249, 1.0007526715769295, 0.9982578072353937, 0.9975559032699765, 0.3015430715775592, 0.4690670002317588, 0.2345335001158794, 0.28630118147983635, 0.3636354086611715, 0.05265309084686646, 0.29617363601362384, 1.0000975498962146, 0.9866607336605548, 0.6480556265153443, 0.36453128991488115, 0.02611756919445345, 0.9532912755975509, 0.013058784597226725, 0.9927303175045605, 1.0092470590566351, 1.002447608540969, 0.40639409415001104, 0.18472458825000504, 0.11083475295000302, 0.018472458825000503, 0.29555934120000804, 0.22668606581413606, 0.7808075600264687, 0.8168269304025495, 0.0025133136320078446, 0.10053254528031379, 0.08293934985625888, 0.05722466456270095, 0.9384844988282955, 0.15274151172775804, 0.00449239740375759, 0.47170172739454697, 0.11230993509393974, 0.2560666520141826, 0.11432435337431454, 0.1432339599747159, 0.0696458704464215, 0.02365331449123749, 0.5768780589807366, 0.07227401650100344, 1.000445334538392, 1.0033500538758928, 0.8171828071661056, 0.19456733503954896, 1.0020054728245655, 0.038806849862537615, 0.07545776362160092, 0.14013584672583027, 0.3277022877280954, 0.18756644100226513, 0.10348493296676697, 0.1272002301049844, 0.018807264033176122, 0.1081417681907627, 0.41846162473816867, 0.06112360810782239, 0.08463268814929255, 0.310319856547406, 1.0046287649321846, 0.9876278807087499, 0.016739455605233048, 0.9953307819660228, 1.003620118411567, 0.014406450025042908, 0.23050320040068653, 0.05762580010017163, 0.6963117512104072, 0.004802150008347636, 1.0022297105114515, 1.0020137329900372, 0.9962470249514751, 0.9897825874651193, 0.9942909216999382, 0.07305233330839522, 0.5426744760052217, 0.20176358723271062, 0.18437017454023558, 1.0075765293542374, 1.0032246084149143, 1.0026282838729963, 0.993257702328862, 0.7340488048191897, 0.1787579991010462, 0.0874773187090226, 0.9860413805084287, 0.9947071424934268, 0.8594795986178531, 0.013429368728403954, 0.12086431855563558, 0.9985214268953907, 0.05806966278137385, 0.25908003394766793, 0.004466897137028757, 0.6789683648283712, 0.00918343313511169, 0.6152900200524833, 0.08265089821600523, 0.05510059881067015, 0.2295858283777923, 0.9897874060412692, 0.4471648755556047, 0.46372653761321964, 0.08280831028807493, 0.8958701218804582, 0.11198376523505728, 0.048841691262797506, 0.016280563754265835, 0.21164732880545584, 0.7163448051876967, 0.9952259909421615, 0.948703737162802, 0.026500104390022403, 0.026500104390022403, 1.0029409080358058, 0.9952259909421615, 1.0074820584249853, 1.0000347893126054, 1.0032246084149143, 0.092832288132566, 0.8973787852814713, 1.0022962446860748, 0.993257702328862, 0.9998009495794703, 0.9903112366422113, 1.0025012673568092, 0.24854822144888405, 0.2880899839521156, 0.11862528750969466, 0.3445782160995892, 0.11860082266135293, 0.8697393661832548, 0.9921296645392738, 0.9993683339031397, 0.8915041772068495, 0.11072822583142398, 1.0022962446860748, 1.003772882536969, 0.16168575424328263, 0.03804370688077238, 0.08084287712164132, 0.1902185344038619, 0.21399585120434467, 0.2472840947250205, 0.07608741376154476, 0.025209389622923545, 0.20167511698338836, 0.7814910783106299, 0.6061091702757565, 0.005772468288340538, 0.38675537531881604, 1.0064849283186452, 0.015284906275759246, 0.24455850041214794, 0.3362679380667034, 0.41269246944549964, 0.31203146447480057, 0.008548807245884948, 0.162427337671814, 0.25218981375360594, 0.05556724709825216, 0.021372018114712368, 0.1923481630324113, 0.87094867774793, 0.1339921042689123, 0.19895001737689127, 0.7498885270359748, 0.045911542471590294, 0.9265261746556286, 0.07721051455463572, 0.9993837305322674, 1.0090163119096165, 0.44546469553963736, 0.36447111453243053, 0.19235975489211612, 0.4554943193003995, 0.549485210584609, 0.010095198075535789, 0.22209435766178737, 0.7706001197658986, 1.0005053966588198, 0.18770640906238437, 0.8190825122722226, 0.9933019775797264, 1.0011603165102707, 0.9945952559752355, 0.9961073085486674, 0.03776118332536491, 0.004720147915670614, 0.5050558269767557, 0.4531341999043789, 1.0072584038633567, 0.022110393435080967, 0.9728573111435626, 1.0000347893126054, 0.017171371595763395, 0.7555403502135895, 0.08585685797881698, 0.13737097276610716, 0.21121776417916144, 0.032002691542297186, 0.409634451741404, 0.16001345771148595, 0.19201614925378313, 0.9575797927449019, 0.04352635421567736, 0.999977467087036, 0.9964870294329082, 1.0070646664114253, 0.993257702328862, 1.0034443242647537, 0.08064518303820575, 0.8870970134202633, 0.04032259151910288, 0.9926068354993176, 0.60692884166418, 0.39044466884128776, 0.00386578880040879, 0.5744298021493686, 0.4267192815966738, 0.21894644988143547, 0.21894644988143547, 0.5747344309387681, 0.31634985070049637, 0.04595025764364752, 0.04595025764364752, 0.4683391644448689, 0.11310832650744004, 0.010603905610072503, 0.07068824086594146, 0.43983794316585795, 0.4869634370764856, 0.4209358503122452, 0.2827181084186721, 0.08167412020983861, 0.012565249263052095, 0.2010439882088335, 0.1875279393332587, 0.6475021301506857, 0.1662983612955313, 0.5716410518672533, 0.20007436815353866, 0.07962143222436742, 0.06941355629816648, 0.07962143222436742, 0.095493499969189, 0.9071882497072955, 0.9945059611586907, 0.09226227181406566, 0.011532783976758207, 0.44977857509357005, 0.13839340772109848, 0.29985238339571335, 0.007170027798411712, 0.04302016679047027, 0.9392736415919342, 0.010755041697617568, 0.5875052727438548, 0.1731594488087151, 0.2350021090975419, 0.24781769000507903, 0.3894277985794099, 0.12390884500253951, 0.23896705821918335, 0.5253395035829764, 0.4714585288565173, 0.9980636469251104, 0.9980636469251104, 0.6398078116971216, 0.05879315026405983, 0.017292103018841126, 0.28531969981087857, 1.0037771937743631, 1.000228198294954, 0.9488823183032095, 0.055816606959012326, 1.0013482629454546, 1.008586422448071, 0.9973232212489285, 0.06851602166512778, 0.5652571787373042, 0.059951518956986805, 0.25693508124422915, 0.05138701624884583, 0.6988355924901789, 0.2945092854065754, 0.0049916828035012776, 0.9908442512559609, 0.9999227278483619, 1.0030708553902956, 1.0037771937743631, 0.9961073085486674, 0.0058676074393192975, 0.38139448355575434, 0.3051155868446035, 0.11148454134706666, 0.19949865293685612, 0.009122754267815345, 0.12771855974941485, 0.30561226797181407, 0.13684131401723018, 0.41964669631950585, 0.9994582609491374, 0.6418548551097307, 0.08896997991620029, 0.11438997417797181, 0.08261498135075741, 0.07625998278531454, 0.30904232760998734, 0.015075235493170115, 0.06030094197268046, 0.5728589487404644, 0.045225706479510346, 0.02491045243466267, 0.2131227597187806, 0.4400846596790405, 0.25740800849151424, 0.0636600451108046, 0.14382280150212443, 0.8629368090127466, 0.9301583984278785, 0.07593129783084722, 0.990606175291804, 0.9975674073869871, 0.052997733978984295, 0.5072640252274211, 0.17413541164523413, 0.0567832864060546, 0.007571104854140614, 0.20063427863472627, 0.993708537964153, 0.0799052416256467, 0.043227425797481005, 0.366778158281657, 0.044537347791344065, 0.10479375950904486, 0.09955407153359262, 0.259364554784886, 0.9975913457275493, 0.041093640595333526, 0.6164046089300029, 0.349295945060335, 0.7394782740086367, 0.06162318950071973, 0.19807453768088484, 0.06660578135600996, 0.13501171896488506, 0.10980953142477318, 0.1908165628037042, 0.03600312505730268, 0.1962170315622996, 0.2268196878610069, 0.03960343756303295, 1.0024534436513677, 0.4917173018250046, 0.06644828403040604, 0.006644828403040603, 0.25914830771858355, 0.17941036688209627, 1.0035240289149119, 0.998137384669787, 0.0006500886433034072, 0.0006500886433034072, 0.5376233080119177, 0.0019502659299102216, 0.1254671081575576, 0.09101241006247701, 0.2424830639521709, 0.07798151040319956, 0.0863366722321138, 0.09747688800399945, 0.1921687220650275, 0.06127118674537108, 0.06684129463131391, 0.33699152709954094, 0.044560863087542604, 0.03899075520159978, 0.12580114759195968, 0.8806080331437177, 0.999977467087036, 1.0039143722727961, 0.058835977809674034, 0.9413756449547845, 1.002919495940039, 0.9914797768551633, 0.027204589780342958, 0.6961901839242312, 0.0012365722627428618, 0.27575561459165815, 1.0034286922178117, 1.0039812722157064, 0.11244387477690294, 0.06474041275033805, 0.821181024885867, 0.044009470661478124, 0.5721231185992156, 0.24005165815351703, 0.14403099489211021, 1.0007027146879355, 1.0007699727070138, 0.9993549646053058, 0.06241051480730151, 0.0039006571754563444, 0.40566834624745984, 0.5304893758620629, 0.027360908785344928, 0.3009699966387942, 0.054721817570689855, 0.5061768125288811, 0.08208272635603478, 0.04104136317801739, 0.8755797157971963, 0.008260185998086757, 0.11564260397321462, 0.9572367689552721, 0.040637410002818154, 0.7641032428781769, 0.06946393117074334, 0.17365982792685838, 0.4648931614564515, 0.0680331455789929, 0.011338857596498816, 0.45355430385995266, 0.9997830910386611, 0.006347582593116534, 0.5268493552286724, 0.26025088631777793, 0.20947022557284564, 0.999310509180477, 0.9257070786646053, 0.014811313258633685, 0.05924525303453474, 1.000228198294954, 0.9970040331323043, 0.9980474527244187, 0.9945952559752355, 0.9912512571982135, 0.9935180680416218, 0.9995535234369066, 0.9914137993251252, 1.0033500538758928, 0.08874838654683721, 0.015152163556777084, 0.08441919695918662, 0.15152163556777085, 0.101735955309789, 0.14286325639246966, 0.41343760562063187, 0.04056357793435627, 0.09290367849481597, 0.07851015084068955, 0.043180582962379255, 0.09944619106487343, 0.06542512570057463, 0.0013085025140114925, 0.044489085476390744, 0.21459441229788478, 0.0523401005604597, 0.2093604022418388, 0.05103159804644821, 0.003925507542034478, 0.05623302564333963, 0.12013419114713467, 0.1456946573486527, 0.12780233100759006, 0.11757814452698287, 0.08690558508516125, 0.10991000466652746, 0.13802651748819728, 0.09201767832546486, 0.9956125203180125, 0.9932481668322221, 0.9946665373275217, 0.08612892308711266, 0.1957475524707106, 0.5950725595109602, 0.07046911888945581, 0.05480931469179896, 0.30682136039362445, 0.01095790572834373, 0.10592642204065605, 0.025568446699468703, 0.007305270485562487, 0.5442426511744053, 1.0118936844355269, 0.9974388165194665, 1.0019037660176073, 0.9233843517626452, 0.0739803486575413, 0.0685816025461094, 0.9372819014634951, 0.45183399941942565, 0.1058985936139279, 0.4306542806966401, 0.007059906240928526, 0.41978239372697673, 0.15357892453425978, 0.09214735472055587, 0.3378736339753715, 0.9931720924780627, 1.0057601763886554, 0.9965993693606888, 0.9743847968084035, 0.25393919676386517, 0.03762062174279484, 0.29782992213045917, 0.41069178735884365, 0.998137384669787, 1.0086108925561976, 0.4930042425169104, 0.5042088843922947, 0.9913782574993083, 0.9867865603239342, 0.8802174395147435, 0.1257453485021062, 0.05908911133102334, 0.9454257812963734, 0.9965097143389858, 0.2564328809743921, 0.6960321055019215, 0.05494990306594117, 1.009723681155655, 0.9980474527244187, 0.9971942258276593, 1.0042824323311503, 0.5564468417305355, 0.047198616039643634, 0.02566942275840268, 0.04305838656248191, 0.12503493021028403, 0.0008280458954323445, 0.010764596640620478, 0.010764596640620478, 0.17968595930881875, 0.9977411247545322, 1.0115852349020964, 0.9932090937906809, 0.9912512571982135, 1.0086108925561976, 0.11128507473134035, 0.037095024910446785, 0.19165762870397504, 0.142197595490046, 0.11128507473134035, 0.1607451079452694, 0.24730016606964522, 0.12031006285530087, 0.5774883017054442, 0.0962480502842407, 0.024062012571060176, 0.1924961005684814, 0.8874595538893258, 0.11832794051857677, 0.8935043513748279, 0.11168804392185348, 0.3851625350207115, 0.6145289884600117, 0.008421900990223179, 0.06316425742667385, 0.31161033663825766, 0.06316425742667385, 0.22318037624091425, 0.11790661386312451, 0.15369969307157302, 0.058953306931562255, 0.059896466841765125, 0.27225666746256877, 0.07078673354026788, 0.14701860042978712, 0.40293986784460173, 0.049006200143262374, 1.0016953424281316, 0.7487832231302425, 0.24479451525411774, 0.006714599254086566, 0.19472337836851042, 0.16115038209807758, 0.1208627865735582, 0.09400438955721192, 0.29544236717980893, 0.05371679403269253, 0.08057519104903879, 0.07182291325779068, 0.9336978723512788, 0.300257354306708, 0.03687371017801678, 0.06847974747345972, 0.0421413830605906, 0.12115647629919798, 0.07374742035603356, 0.11588880341662415, 0.24231295259839597, 0.9947222801278118, 1.0033666975597624, 0.9979257506068246, 1.0035240289149119, 0.1522408821199497, 0.8431802702027984, 1.0007027146879355, 0.996005095396168, 0.9928094325768656, 0.017623693722176228, 0.9869268484418686, 0.9931770571152436, 0.766799214679285, 0.17126479921770835, 0.06227810880643939, 0.9975674073869871, 0.9974388165194665, 0.03898084485588807, 0.6603813716762214, 0.011464954369378845, 0.18573226078393726, 0.03898084485588807, 0.06649673534239729, 0.9961073085486674, 0.988571602449651, 0.015944703265316953, 1.0054751969574711, 1.0021298524514524, 1.0110297611726373, 0.9961393999218388, 0.0829706809698733, 0.009761256584690977, 0.24403141461727443, 0.6686460760513319, 0.00826038816323866, 0.1239058224485799, 0.8673407571400592, 1.0011603165102707, 0.9908442512559609, 1.0003428024015268, 0.997817013241411, 0.9992648131286876, 0.9908442512559609, 0.9988245153471533, 1.0030788746232895, 0.9993837305322674, 0.5989701837222177, 0.414671665653843, 0.9885638021301817, 0.578879814739379, 0.02411999228080746, 0.2894399073696895, 0.1205999614040373, 0.9962470249514751, 0.9960358934826732, 0.09830535377541258, 0.24406846454585193, 0.1118647129168488, 0.4847470893063448, 0.05423743656574487, 0.0067796795707181085, 0.9999227278483619, 0.9935180680416218, 0.9974426445121871, 0.9271487819446265, 0.0806216332125762, 0.13256617832360304, 0.13256617832360304, 0.742370598612177, 0.993257702328862, 0.5650592600244649, 0.028731826780905, 0.181968236279065, 0.2250659764504225, 1.0095699893619574, 0.999622751986035, 0.2132869281326945, 0.6786402258767553, 0.019389720739335866, 0.09694860369667932, 0.09575278193850556, 0.10213630073440594, 0.7787892930998452, 0.025534075183601485, 0.9985214268953907, 0.5092039235330105, 0.48192514191517066, 0.9805734726593721, 0.011302613029475569, 0.37863753648743154, 0.09042090423580455, 0.05651306514737784, 0.2995192452811026, 0.06216437166211563, 0.09607221075054233, 0.011302613029475569, 0.11315744825154524, 0.26672827087864237, 0.5496218915075054, 0.04849604925066225, 0.024248024625331124, 0.06125555689307914, 0.051046297410899284, 0.09443565021016367, 0.16845278145596765, 0.08167407585743885, 0.12506342865670325, 0.4160273238988292, 0.1637705717929327, 0.03821313341835096, 0.6769183634107884, 0.12555743837458172, 1.0033772078376801, 0.9982971319580691, 0.04649821084266378, 0.27898926505598265, 0.6709027564441488, 0.05630995272190576, 0.04306055208145735, 0.5167266249774882, 0.11261990544381152, 0.1788669086460536, 0.0927458044831389, 0.03745888577689139, 0.9614447349402123, 0.9926068354993176, 0.537098095380224, 0.31226633452338604, 0.1498878405712253, 1.0094993762209379, 0.9957586071997653, 0.07021830673146134, 0.13664102931527614, 0.30934010803319456, 0.1404366134629227, 0.11007194028175021, 0.08160505917440103, 0.15182336590586237, 0.9947071424934268, 0.45547177929052823, 0.5566877302439789, 1.0021298524514524, 1.004348457672529, 0.2052114037163509, 0.20093616613892695, 0.38904661954558195, 0.008550475154847954, 0.188110453406655, 0.004275237577423977, 0.9730404112066693, 0.009686318165914263, 0.0774905453273141, 0.009686318165914263, 0.9008275894300264, 0.07716929571598322, 0.10684979406828445, 0.011872199340920495, 0.00890414950569037, 0.16027469110242668, 0.42146307660267757, 0.21073153830133878, 1.002864257099994, 0.9867865603239342, 0.03010372889602153, 0.03364534406025936, 0.09031118668806459, 0.23020498567545877, 0.511763391232366, 0.10624845492713482, 0.28720915495216964, 0.21918593404244527, 0.13604644181944878, 0.32499983323534987, 0.030232542626544175, 0.016024534278955126, 0.6890549739950704, 0.0640981371158205, 0.016024534278955126, 0.20831894562641665, 0.9962816473534355, 0.48814420916667156, 0.00555972903378897, 0.3258001213800336, 0.08339593550683455, 0.07227647743925661, 0.02557475355542926, 0.7864123796429783, 0.003951821003231047, 0.17388012414216605, 0.031614568025848375, 0.689799821069029, 0.02474618192175889, 0.038665909252748265, 0.0015466363701099307, 0.10517127316747528, 0.13919727330989376, 0.6961619193119022, 0.2983551082765295, 0.7828526243704585, 0.09546983224029983, 0.05728189934417989, 0.06491948592340388, 0.02841483183770584, 0.2727823856419761, 0.07387856277803519, 0.02273186547016467, 0.15344009192361155, 0.19322085649639972, 0.26141645290689375, 0.9975913457275493, 1.0047664050696574, 0.08512171240804643, 0.4681694182442554, 0.015960321076508705, 0.042560856204023216, 0.12768256861206964, 0.2606852442496422, 0.6055702161801475, 0.34925910142482924, 0.04506569050642958, 0.042886070711148416, 0.00612658153016406, 0.4839999408829607, 0.3982277994606639, 0.06739239683180466, 0.3562030794021242, 0.6530389789038944, 0.9973933474841581, 0.40240310969993187, 0.16140344509942323, 0.43556820115871747, 0.6040141681552145, 0.15291497927980113, 0.2408410923656868], \"Term\": [\"aaron\", \"abhor\", \"abhor\", \"absence\", \"absent\", \"achille\", \"acknowledge\", \"acquaint\", \"add\", \"advancement\", \"advise\", \"advise\", \"aenea\", \"affair\", \"affection\", \"affection\", \"agamemnon\", \"age\", \"age\", \"age\", \"age\", \"agrippa\", \"air\", \"air\", \"air\", \"air\", \"airy\", \"ajax\", \"alanson\", \"albany\", \"alcibiade\", \"alencon\", \"alexas\", \"alike\", \"allay\", \"altogether\", \"amazement\", \"amiss\", \"andrew\", \"andronicus\", \"angel\", \"angel\", \"angel\", \"angel\", \"angel\", \"angelo\", \"angelo\", \"angier\", \"anne_page\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"antenor\", \"antipholus\", \"antique\", \"antonio\", \"antonio\", \"antonius\", \"antony\", \"apemantus\", \"appoint\", \"appoint\", \"apprehend\", \"arch\", \"ariel\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"armado\", \"arming\", \"armour\", \"armour\", \"armour\", \"arra\", \"art\", \"art\", \"art\", \"art\", \"art\", \"art\", \"arthur\", \"ashe\", \"asleep\", \"asleep\", \"asleep\", \"assist\", \"assume\", \"attaint\", \"audrey\", \"aufidius\", \"aumerle\", \"awake\", \"awake\", \"awake\", \"awake\", \"back\", \"bad\", \"bad\", \"bad\", \"bake\", \"balthazar\", \"banish\", \"banish\", \"banish\", \"banish\", \"banner\", \"banquo\", \"baptista\", \"bardolph\", \"bardolph\", \"barnardine\", \"base\", \"base\", \"basket\", \"bassanio\", \"bassianus\", \"bastard\", \"bastard\", \"bastard\", \"bastard\", \"battle\", \"battle\", \"battle\", \"battle\", \"battle\", \"battle\", \"bawd\", \"bawd\", \"beadle\", \"bear\", \"bear\", \"bear\", \"bear\", \"bear\", \"bearer\", \"beatrice\", \"beaufort\", \"beautiful\", \"beauty\", \"beauty\", \"beauty\", \"beauty\", \"beauty\", \"beauty\", \"beauty\", \"bed\", \"bed\", \"bed\", \"bed\", \"beg\", \"beg\", \"beg\", \"beggar\", \"beggar\", \"beggar\", \"beggar\", \"beggary\", \"begin\", \"begin\", \"begin\", \"begin\", \"behavior\", \"behavior\", \"bellario\", \"belmont\", \"beloved\", \"beloved\", \"bench\", \"benedict\", \"benedict\", \"benefit\", \"berowne\", \"betwixt\", \"betwixt\", \"betwixt\", \"beware\", \"bianca\", \"bianca\", \"bias\", \"biondello\", \"bishop\", \"bishop\", \"blame\", \"blame\", \"blanch\", \"blemish\", \"bless\", \"bless\", \"bless\", \"bless\", \"bless\", \"bless\", \"blessing\", \"blessing\", \"blessing\", \"blessing\", \"blood\", \"blood\", \"blood\", \"blood\", \"board\", \"bohemia\", \"boisterous\", \"bold\", \"bold\", \"bold\", \"bolingbroke\", \"bolt\", \"bond\", \"bond\", \"bond\", \"bordeaux\", \"bore\", \"bore\", \"borrow\", \"borrow\", \"bottle\", \"bottle\", \"bound\", \"bound\", \"bound\", \"bounteous\", \"bounty\", \"boy\", \"boy\", \"boy\", \"boy\", \"boy\", \"boy\", \"boyet\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"brainsick\", \"break\", \"break\", \"break\", \"break\", \"break\", \"break\", \"break\", \"break\", \"breast\", \"breast\", \"breath\", \"breath\", \"breath\", \"breath\", \"breed\", \"breed\", \"brentford\", \"bring\", \"bring\", \"bring\", \"bring\", \"bring\", \"bring\", \"bring\", \"britain\", \"briton\", \"brittany\", \"brother\", \"brother\", \"brother\", \"brother\", \"brutus\", \"buck\", \"buckingham\", \"bullen\", \"bully\", \"burgundy\", \"burn\", \"burn\", \"bury\", \"bury\", \"business\", \"business\", \"business\", \"business\", \"business\", \"busy\", \"cade\", \"caesar\", \"caius\", \"caius\", \"caius_martius\", \"calchas\", \"calf\", \"calf\", \"caliban\", \"calphurnia\", \"cambio\", \"cambridge\", \"camillo\", \"canary\", \"canterbury\", \"canterbury\", \"capitol\", \"capitol\", \"captain\", \"captain\", \"captain\", \"captain\", \"captain\", \"capulet\", \"cardinal\", \"cardinal\", \"cardinal\", \"carriage\", \"casca\", \"casket\", \"cassandra\", \"cassio\", \"cassius\", \"castle\", \"castle\", \"castle\", \"catch\", \"catch\", \"catesby\", \"cawdor\", \"cedar\", \"censure\", \"centaur\", \"cesario\", \"chain\", \"chain\", \"chain\", \"chamber_window\", \"chance\", \"chance\", \"charge\", \"charge\", \"charge\", \"charge\", \"charle\", \"charle\", \"charm\", \"charm\", \"charmian\", \"chase\", \"cheater\", \"check\", \"cheese\", \"cheese\", \"cheese\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"chiron\", \"choir\", \"choleric\", \"choose\", \"choose\", \"choose\", \"christ\", \"christendom\", \"christian\", \"christian\", \"christian\", \"christian\", \"churchyard\", \"cicero\", \"cinna\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"claim\", \"claim\", \"claim\", \"clarence\", \"claudio\", \"cleopatra\", \"clerk\", \"clerk\", \"clifford\", \"climb\", \"cloten\", \"coldly\", \"colevile\", \"colour\", \"colour\", \"colour\", \"comfort\", \"comfort\", \"comfort\", \"comfort\", \"comfort\", \"cominius\", \"commence\", \"commendation\", \"commission\", \"commission\", \"companion\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"conclusion\", \"confine\", \"confine\", \"confine\", \"conscience\", \"conscience\", \"conscience\", \"conscience\", \"consecrate\", \"constant\", \"consul\", \"consul\", \"continue\", \"continue\", \"continue\", \"cord\", \"cordelia\", \"coriolanus\", \"coriole\", \"corner\", \"cornwall\", \"coronation\", \"corse\", \"corse\", \"costard\", \"count_rossillion\", \"countenance\", \"country\", \"country\", \"country\", \"country\", \"county\", \"county\", \"court\", \"court\", \"court\", \"court\", \"court\", \"cousin\", \"cousin\", \"cousin\", \"cousin\", \"cousin\", \"cranmer\", \"cressid\", \"crew\", \"cromwell\", \"cromwell\", \"crown\", \"crown\", \"crown\", \"crown\", \"crown\", \"cry\", \"cry\", \"cry\", \"cry\", \"cry\", \"cry\", \"cuff\", \"cupid\", \"cupid\", \"cupid\", \"curious\", \"cymbeline\", \"cyprus\", \"danger\", \"danger\", \"daniel\", \"dare\", \"dare\", \"dare\", \"dare\", \"dat\", \"daughter\", \"daughter\", \"daughter\", \"daughter\", \"daughter\", \"daughter\", \"dauphin\", \"dauphin\", \"davy\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"daylight\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"deal\", \"deal\", \"dear\", \"dear\", \"dear\", \"dear\", \"dear\", \"dear\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"debt\", \"debt\", \"debt\", \"decius\", \"deed\", \"deed\", \"deed\", \"deed\", \"deed\", \"deed\", \"deed\", \"deed\", \"deem\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"defect\", \"deliver\", \"deliver\", \"deliver\", \"demetrius\", \"demetrius\", \"denmark\", \"depart\", \"depose\", \"depose\", \"derive\", \"derive\", \"description\", \"desdemona\", \"desert\", \"desert\", \"deserve\", \"deserve\", \"design\", \"design\", \"desire\", \"desire\", \"desire\", \"desire\", \"desire\", \"desire\", \"desire\", \"desire\", \"devil\", \"devil\", \"devil\", \"devil\", \"devil\", \"devil\", \"devil\", \"devil\", \"devil\", \"die\", \"die\", \"die\", \"die\", \"die\", \"die\", \"die\", \"dine\", \"dine\", \"diome\", \"diomed\", \"disclose\", \"discovery\", \"discretion\", \"discretion\", \"discuss\", \"dish\", \"dishonour\", \"dishonour\", \"dishonour\", \"dispatch\", \"dispatch\", \"displeasure\", \"distemper\", \"distraction\", \"division\", \"doctor\", \"doctor\", \"doctor_caius\", \"dog\", \"dog\", \"dog\", \"dog\", \"dog\", \"dog\", \"doll\", \"dorset\", \"dost\", \"dost\", \"dost\", \"dost\", \"dost\", \"doublet\", \"douglas\", \"dover\", \"draw\", \"draw\", \"draw\", \"draw\", \"draw\", \"drawer\", \"dread\", \"dread\", \"dread\", \"dread\", \"dread\", \"dream\", \"dream\", \"dream\", \"dream\", \"drink\", \"drink\", \"drink\", \"drink\", \"drink\", \"drive\", \"dromio\", \"ducat\", \"ducat\", \"duke\", \"duke\", \"duke\", \"duke_humphrey\", \"dumaine\", \"duncan\", \"ear\", \"ear\", \"ear\", \"ear\", \"ear\", \"ear\", \"ear\", \"earl\", \"earl\", \"earl\", \"early\", \"earth\", \"earth\", \"earth\", \"earth\", \"earth\", \"earth\", \"earth\", \"earth\", \"earth\", \"ease\", \"ease\", \"east\", \"east\", \"edgar\", \"edmund\", \"edward\", \"egg\", \"eglamour\", \"egypt\", \"egyptian\", \"egyptian\", \"eleanor\", \"emilia\", \"emperor\", \"emperor\", \"emperor\", \"empress\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"enemy\", \"enemy\", \"enemy\", \"enemy\", \"enemy\", \"england\", \"england\", \"england\", \"english\", \"english\", \"english\", \"enobarbus\", \"enrich\", \"enter\", \"epidamium\", \"equal\", \"ere\", \"ere\", \"ere\", \"ero\", \"err\", \"err\", \"err\", \"esquire\", \"evidence\", \"evil\", \"evil\", \"evil\", \"exaction\", \"exchange\", \"exchange\", \"exchange\", \"exeter\", \"express\", \"extreme\", \"extremity\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"face\", \"face\", \"face\", \"face\", \"face\", \"fair\", \"fair\", \"fair\", \"fair\", \"fair\", \"fair\", \"fair\", \"fair\", \"fair\", \"fairy\", \"fairy\", \"faith\", \"faith\", \"faith\", \"faith\", \"faith\", \"faith\", \"faith\", \"faith\", \"faith\", \"faith\", \"faith\", \"fall\", \"fall\", \"fall\", \"fall\", \"fall\", \"fall\", \"fall\", \"fall\", \"false\", \"false\", \"false\", \"false\", \"false\", \"false\", \"false\", \"false\", \"falstaff\", \"falstaff\", \"familiar\", \"famine\", \"fancy\", \"fancy\", \"fantasy\", \"fantasy\", \"farewell\", \"farewell\", \"farewell\", \"farewell\", \"fast\", \"fast\", \"fast\", \"fasten\", \"father\", \"father\", \"father\", \"father\", \"father\", \"father\", \"father\", \"faulconbridge\", \"fault\", \"fault\", \"fear\", \"fear\", \"fear\", \"fear\", \"fearful\", \"fearful\", \"feast\", \"feast\", \"feast\", \"feast\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"fellow\", \"fellow\", \"fellow\", \"fellow\", \"fery\", \"fever\", \"fidele\", \"field\", \"field\", \"field\", \"field\", \"fight\", \"fight\", \"fight\", \"fight\", \"fight\", \"fight\", \"fight\", \"fight\", \"fingre\", \"fist\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"flatterer\", \"flaw\", \"flesh\", \"flesh\", \"flesh\", \"flesh\", \"flesh\", \"flesh\", \"florence\", \"florentine\", \"fluellen\", \"foe\", \"foe\", \"foe\", \"foe\", \"foe\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"fool\", \"fool\", \"fool\", \"foolish\", \"foolish\", \"ford\", \"forfeiture\", \"form\", \"form\", \"form\", \"form\", \"form\", \"forsooth\", \"forsooth\", \"forsooth\", \"forsooth\", \"fortune\", \"fortune\", \"fortune\", \"fortune\", \"fortune\", \"foul_fiend\", \"foul_fiend\", \"france\", \"france\", \"france\", \"france\", \"francis\", \"fray\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"french\", \"french\", \"french\", \"french\", \"french\", \"frenchman\", \"frenchman\", \"frenchman\", \"frenchman\", \"friar\", \"friar\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"fully\", \"fulvia\", \"fumble\", \"function\", \"gage\", \"gait\", \"gait\", \"gait\", \"gallop\", \"gar\", \"garment\", \"garment\", \"garment\", \"garment\", \"garment\", \"garter\", \"garter\", \"garter\", \"gaunt\", \"gaze\", \"general\", \"general\", \"general\", \"general\", \"general\", \"general\", \"generous\", \"gentle\", \"gentle\", \"gentle\", \"gentle\", \"gentleman\", \"gentleman\", \"gentleman\", \"gentleman\", \"gentleman\", \"gentleman\", \"gentleman\", \"gentleman\", \"gentleman\", \"gentleman\", \"gertrude\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"glendower\", \"gloucester\", \"gloucester\", \"gloucestershire\", \"gobbo\", \"god\", \"god\", \"god\", \"god\", \"god\", \"god\", \"god\", \"god\", \"god\", \"gold\", \"gold\", \"gold\", \"gold\", \"goldsmith\", \"goneril\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"goodness\", \"goodness\", \"goth\", \"govern\", \"grace\", \"grace\", \"grace\", \"grace\", \"grace\", \"grace\", \"grace\", \"grace\", \"grace\", \"grace\", \"grand\", \"gratiano\", \"gray\", \"great\", \"great\", \"great\", \"great\", \"grecian\", \"greece\", \"greek\", \"greek\", \"greekish\", \"greet\", \"greet\", \"gremio\", \"grey\", \"grey\", \"griffith\", \"groan\", \"groan\", \"grove\", \"grumio\", \"guard\", \"guard\", \"guard\", \"guess\", \"hail\", \"hail\", \"hail\", \"hal\", \"half\", \"half\", \"hamlet\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"handkerchief\", \"hare\", \"harfleur\", \"harry\", \"harry\", \"harry_monmouth\", \"harry_percy\", \"hast\", \"hast\", \"hast\", \"hast\", \"hast\", \"hast\", \"haste\", \"haste\", \"haste\", \"haste\", \"haste\", \"hasting\", \"hate\", \"hate\", \"hate\", \"hate\", \"hatred\", \"haughty\", \"head\", \"head\", \"head\", \"head\", \"head\", \"health\", \"health\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"heart\", \"heart\", \"heart\", \"heart\", \"heart\", \"heart\", \"heart\", \"heart\", \"heart\", \"hearted\", \"heaven\", \"heaven\", \"heaven\", \"heaven\", \"heaven\", \"heaven\", \"hector\", \"hecuba\", \"hecuba\", \"heed\", \"heel\", \"heel\", \"heel\", \"heel\", \"height\", \"helen\", \"helen\", \"helen\", \"helena\", \"helenus\", \"helmet\", \"henry\", \"herald\", \"herald\", \"herald\", \"herald\", \"hereford\", \"hermia\", \"hermione\", \"herne\", \"hero\", \"hie\", \"hie\", \"high\", \"high\", \"high\", \"highness\", \"highness\", \"highness\", \"highness\", \"hold\", \"hold\", \"hold\", \"hold\", \"hollow\", \"holy\", \"holy\", \"holy\", \"home\", \"home\", \"home\", \"home\", \"home\", \"honest\", \"honest\", \"honest\", \"honest\", \"honour\", \"honour\", \"honour\", \"honour\", \"honour\", \"horatio\", \"horn\", \"horn\", \"horn\", \"horn\", \"horrible\", \"horrible\", \"horror\", \"horse\", \"horse\", \"horse\", \"horse\", \"horse\", \"horse\", \"hortensio\", \"host\", \"host\", \"host\", \"host\", \"hotspur\", \"hour\", \"hour\", \"hour\", \"hour\", \"hour\", \"house\", \"house\", \"house\", \"house\", \"house\", \"house\", \"hubert\", \"huge\", \"huge\", \"huge\", \"hugh\", \"humour\", \"humour\", \"humour\", \"humour\", \"humour\", \"humour\", \"humphrey\", \"husband\", \"husband\", \"husband\", \"husband\", \"husband\", \"husband\", \"husband\", \"husband\", \"husbandry\", \"iago\", \"ilium\", \"immediately\", \"imogen\", \"impart\", \"instant\", \"instinct\", \"instruction\", \"intend\", \"intend\", \"invention\", \"invest\", \"invite\", \"invite\", \"ireland\", \"irish\", \"isabel\", \"ish\", \"isis\", \"island\", \"isle\", \"isle\", \"italian\", \"italian\", \"item\", \"item\", \"jack\", \"jack\", \"jack\", \"jackanape\", \"jacob\", \"jail\", \"jaque\", \"jealousy\", \"jealousy\", \"jealousy\", \"jerusalem\", \"jessica\", \"jew\", \"jewel\", \"jewel\", \"joan\", \"joan\", \"john\", \"john\", \"john\", \"join\", \"join\", \"jove\", \"jove\", \"jove\", \"jove\", \"jove\", \"jove\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"judge\", \"judge\", \"judge\", \"judge\", \"julia\", \"juliet\", \"jump\", \"jump\", \"juno\", \"justice\", \"justice\", \"justice\", \"justice\", \"justice\", \"justice\", \"justice\", \"justify\", \"kate\", \"kate\", \"kate\", \"katherine\", \"katherine\", \"katherine\", \"kent\", \"kent\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"kindre\", \"kindre\", \"kindre\", \"king\", \"king\", \"king\", \"king\", \"king\", \"kingdom\", \"kingdom\", \"kinsman\", \"kinsman\", \"kiss\", \"kiss\", \"kiss\", \"kiss\", \"kite\", \"knave\", \"knave\", \"knave\", \"knave\", \"knave\", \"knell\", \"knife\", \"knight\", \"knight\", \"knight\", \"knight\", \"knight\", \"knock\", \"knock\", \"knock\", \"lad\", \"lad\", \"lad\", \"lad\", \"lad\", \"lady\", \"lady\", \"lady\", \"lady\", \"lady\", \"lady\", \"lady\", \"laerte\", \"laertes\", \"lamb\", \"lament\", \"lancaster\", \"lancaster\", \"lancelet\", \"land\", \"land\", \"land\", \"lavinia\", \"law\", \"law\", \"law\", \"law\", \"law\", \"law\", \"lead\", \"lead\", \"leapt\", \"lear\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"leek\", \"legitimate\", \"leonato\", \"leonatus\", \"lepidus\", \"letter\", \"letter\", \"letter\", \"letter\", \"letter\", \"letter\", \"level\", \"lewis\", \"lewis\", \"lie\", \"lie\", \"lie\", \"lie\", \"lie\", \"liege\", \"liege\", \"liege\", \"liege\", \"lieu\", \"lieutenant\", \"lieutenant\", \"lieutenant\", \"life\", \"life\", \"life\", \"life\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"linen\", \"linen\", \"lion\", \"lion\", \"lion\", \"lion\", \"lion\", \"lip\", \"lip\", \"lip\", \"lip\", \"litio\", \"live\", \"live\", \"live\", \"live\", \"live\", \"livery\", \"loathsome\", \"london\", \"london\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"loo\", \"lord\", \"lord\", \"lord\", \"lord\", \"lord\", \"lord\", \"lord\", \"lord\", \"lord\", \"lord\", \"lord\", \"lordship\", \"lordship\", \"lorenzo\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"loss\", \"loss\", \"loss\", \"loss\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lover\", \"lover\", \"lover\", \"loving\", \"lucentio\", \"lucetta\", \"lucilius\", \"lucio\", \"lucius\", \"lucius\", \"lysander\", \"macbeth\", \"macduff\", \"mad\", \"mad\", \"mad\", \"madam\", \"madam\", \"madam\", \"madam\", \"madam\", \"madam\", \"madam\", \"madness\", \"maid\", \"maid\", \"maidenhead\", \"maintain\", \"maintain\", \"maintain\", \"maintain\", \"maintain\", \"majesty\", \"majesty\", \"majesty\", \"majesty\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"malvolio\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"mankind\", \"mantle\", \"marcus\", \"marcus\", \"margaret\", \"margaret\", \"mark\", \"mark\", \"mark\", \"mark_antony\", \"marry\", \"marry\", \"marry\", \"marry\", \"marry\", \"marry\", \"martius\", \"mask\", \"mask\", \"master\", \"master\", \"master\", \"master\", \"master\", \"master\", \"master\", \"master\", \"master\", \"master\", \"master_brook\", \"master_fenton\", \"master_froth\", \"master_slender\", \"match\", \"match\", \"match\", \"match\", \"matter\", \"matter\", \"matter\", \"matter\", \"mayor\", \"mayor\", \"meantime\", \"meantime\", \"meddle\", \"meet\", \"meet\", \"meet\", \"meet\", \"meet\", \"meet\", \"memory\", \"memory\", \"memory\", \"menas\", \"menelaus\", \"menenius\", \"merchant\", \"merchant\", \"merchant\", \"mercutio\", \"mercy\", \"mercy\", \"mercy\", \"mercy\", \"mere\", \"mere\", \"merit\", \"merry\", \"merry\", \"merry\", \"merry\", \"merry\", \"merry\", \"merry\", \"messala\", \"meteor\", \"mew\", \"middle\", \"midnight\", \"milan\", \"milan\", \"mildly\", \"milford\", \"military\", \"mingle\", \"mirror\", \"miscarried\", \"miserable\", \"mistress\", \"mistress\", \"mistress\", \"mistress\", \"mistress_anne\", \"mistress_ford\", \"mistress_page\", \"misuse\", \"mocking\", \"model\", \"modest\", \"modest\", \"monk\", \"monmouth\", \"monster\", \"monster\", \"moon\", \"moon\", \"moon\", \"moon\", \"moon\", \"moor\", \"moor\", \"mortimer\", \"mortimer\", \"mortimer\", \"mother\", \"mother\", \"mother\", \"mother\", \"mother\", \"mother\", \"motley\", \"mouldy\", \"mowbray\", \"mutius\", \"myrmidon\", \"mystery\", \"mystery\", \"nan\", \"naple\", \"nature\", \"nature\", \"nature\", \"nature\", \"nature\", \"nature\", \"necessity\", \"necessity\", \"needful\", \"neglect\", \"neptune\", \"neptune\", \"nerissa\", \"nestor\", \"news\", \"news\", \"news\", \"news\", \"news\", \"niece\", \"niece\", \"niece\", \"night\", \"night\", \"night\", \"night\", \"night\", \"noble\", \"noble\", \"noble\", \"noble\", \"noble\", \"noble\", \"noble\", \"nobleness\", \"noon\", \"northumberland\", \"northumberland\", \"northumberland\", \"norway\", \"nose\", \"nose\", \"nostril\", \"nought\", \"nought\", \"nuncle\", \"nurse\", \"nurse\", \"observe\", \"observe\", \"octavia\", \"octavius\", \"olivia\", \"oman\", \"oman\", \"open\", \"open\", \"open\", \"ophelia\", \"oracle\", \"oracle\", \"orb\", \"orlando\", \"orleance\", \"othello\", \"oxford\", \"packet\", \"padua\", \"padua\", \"page\", \"page\", \"pandar\", \"pandarus\", \"pari\", \"pari\", \"paris\", \"paris\", \"parolle\", \"parson\", \"partly\", \"patience\", \"patience\", \"patrician\", \"patroclus\", \"paulina\", \"peace\", \"peace\", \"peace\", \"peace\", \"peace\", \"peace\", \"peaceful\", \"people\", \"people\", \"people\", \"people\", \"perceive\", \"perceive\", \"perceive\", \"perceive\", \"percy\", \"perform\", \"perform\", \"perform\", \"perform\", \"peto\", \"petruchio\", \"philip\", \"philippi\", \"philosophy\", \"phoebe\", \"phrase\", \"pindarus\", \"pine\", \"pine\", \"pisa\", \"pisanio\", \"pistol\", \"pistol\", \"pitiful\", \"pity\", \"pity\", \"pity\", \"pity\", \"pity\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"plant\", \"plantagenet\", \"plantagenet\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"player\", \"plea\", \"pleasure\", \"pleasure\", \"pleasure\", \"pleasure\", \"pleasure\", \"plebeian\", \"pless\", \"poin\", \"point\", \"polixene\", \"pomfret\", \"pompey\", \"pompey\", \"pompey\", \"poor\", \"poor\", \"poor\", \"poor\", \"pope\", \"popular\", \"portia\", \"portia\", \"possess\", \"possess\", \"possess\", \"post\", \"posthumus\", \"potent\", \"pound\", \"pound\", \"pound\", \"pound\", \"pound\", \"pour\", \"pour\", \"power\", \"power\", \"power\", \"power\", \"practice\", \"practice\", \"praise\", \"praise\", \"praise\", \"praise\", \"praise\", \"pray\", \"pray\", \"pray\", \"pray\", \"pray\", \"pray\", \"precedent\", \"prey\", \"priam\", \"priam\", \"price\", \"prince\", \"prince\", \"prince\", \"prince\", \"prince\", \"prince\", \"prince\", \"prithee\", \"prithee\", \"prithee\", \"prithee\", \"prithee\", \"prithee\", \"private\", \"prize\", \"prize\", \"proffer\", \"profit\", \"promise\", \"promise\", \"promise\", \"promise\", \"promise\", \"property\", \"prophecy\", \"protection\", \"protector\", \"proteus\", \"prove\", \"prove\", \"prove\", \"prove\", \"provost\", \"pucelle\", \"punish\", \"pupil\", \"purpose\", \"purpose\", \"purpose\", \"pyramus\", \"pyrrhus\", \"quality\", \"quality\", \"quality\", \"quantity\", \"queen\", \"queen\", \"queen\", \"queen\", \"quickly\", \"quickly\", \"quickly\", \"quickly\", \"quickly\", \"raiment\", \"ransom\", \"ransom\", \"ransom\", \"rape\", \"rape\", \"rare\", \"rare\", \"rare\", \"rare\", \"ratcliffe\", \"receive\", \"receive\", \"receive\", \"recompense\", \"regal\", \"regan\", \"regent\", \"reignier\", \"remedy\", \"remedy\", \"renowned\", \"repay\", \"repeat\", \"replete\", \"reply\", \"report\", \"report\", \"report\", \"report\", \"require\", \"require\", \"resolve\", \"respect\", \"rest\", \"rest\", \"restore\", \"retire\", \"revenge\", \"revenge\", \"revenge\", \"revenge\", \"revenge\", \"revenge\", \"revenge\", \"rhyme\", \"rhyme\", \"rhyme\", \"richard\", \"richard\", \"richard\", \"richmond\", \"ride\", \"ride\", \"ride\", \"ride\", \"ring\", \"ring\", \"ring\", \"ring\", \"ring\", \"ring\", \"ring\", \"roan\", \"roan\", \"roar\", \"roar\", \"roar\", \"robert\", \"robert\", \"robert_shallow\", \"roderigo\", \"rogue\", \"rogue\", \"rogue\", \"roman\", \"roman\", \"rome\", \"rome\", \"rome\", \"romeo\", \"root\", \"root\", \"rosalind\", \"rot\", \"rout\", \"rowland\", \"royal\", \"royal\", \"royal\", \"royal\", \"rugby\", \"rule\", \"rule\", \"rutland\", \"sack\", \"sack\", \"sack\", \"sack\", \"sad\", \"sad\", \"sad\", \"sad\", \"sad\", \"sadness\", \"sadness\", \"sailor\", \"salic\", \"saturnine\", \"scarlet\", \"sceptre\", \"scot\", \"scot\", \"scot\", \"scroop\", \"sea\", \"sea\", \"sea\", \"seek\", \"seek\", \"senate\", \"senate\", \"senate\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"sense\", \"sense\", \"sense\", \"servant\", \"servant\", \"servant\", \"servant\", \"servant\", \"serve\", \"serve\", \"serve\", \"set\", \"set\", \"set\", \"set\", \"set\", \"settle\", \"settle\", \"shaft\", \"shallow\", \"shallow\", \"shallow\", \"shallow\", \"shallow\", \"shalt\", \"shalt\", \"shalt\", \"shalt\", \"shame\", \"shame\", \"shame\", \"shape\", \"shape\", \"shape\", \"shape\", \"shepherd\", \"shepherd\", \"sheriff\", \"shilling\", \"show\", \"show\", \"show\", \"show\", \"shrew\", \"shrewd\", \"shrewsbury\", \"shrewsbury\", \"shriek\", \"shylock\", \"sicilia\", \"sigh\", \"sigh\", \"sigh\", \"sigh\", \"sigh\", \"sight\", \"sight\", \"sight\", \"signal\", \"signior_baptista\", \"signior_benedict\", \"signior_gremio\", \"simplicity\", \"sing\", \"sing\", \"sing\", \"sing\", \"sing\", \"sister\", \"sister\", \"sister\", \"sister\", \"sister\", \"skull\", \"slave\", \"slave\", \"slave\", \"slave\", \"slave\", \"slay\", \"slay\", \"slay\", \"slay\", \"slay\", \"sleep\", \"sleep\", \"sleep\", \"sleep\", \"sleep\", \"slender\", \"slender\", \"slow\", \"slow\", \"smell\", \"sola\", \"soldier\", \"soldier\", \"soldier\", \"soldier\", \"soldier\", \"soldier\", \"somerset\", \"son\", \"son\", \"son\", \"son\", \"son\", \"son\", \"son\", \"sonnet\", \"sore\", \"sore\", \"sore\", \"sorrow\", \"sorrow\", \"sorrow\", \"soul\", \"soul\", \"soul\", \"soul\", \"soul\", \"soul\", \"soul\", \"soul\", \"sour\", \"sovereign\", \"sovereign\", \"sovereign\", \"sovereign\", \"sovereign\", \"sovereignty\", \"sow\", \"speak\", \"speak\", \"speak\", \"speak\", \"speak\", \"speak\", \"speak\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spite\", \"spite\", \"sprite\", \"spur\", \"square\", \"square\", \"stage\", \"stain\", \"stand\", \"stand\", \"stand\", \"stand\", \"stanley\", \"start\", \"state\", \"state\", \"state\", \"stay\", \"stay\", \"stay\", \"stay\", \"stephano\", \"steward\", \"stool\", \"strange\", \"strange\", \"strange\", \"strange\", \"street\", \"street\", \"street\", \"street\", \"street\", \"street\", \"strength\", \"strength\", \"strength\", \"strong\", \"strong\", \"strumpet\", \"strumpet\", \"strumpet\", \"study\", \"study\", \"study\", \"study\", \"stumble\", \"subject\", \"subject\", \"subject\", \"subject\", \"succour\", \"suffer\", \"suffer\", \"suffer\", \"sufferance\", \"suffolk\", \"sullen\", \"surge\", \"surname\", \"surprised\", \"swagger\", \"swaggerer\", \"swallow\", \"swear\", \"swear\", \"swear\", \"swear\", \"swear\", \"swear\", \"swear\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sword\", \"sword\", \"sword\", \"sword\", \"sword\", \"sword\", \"sword\", \"sword\", \"sword\", \"sylvia\", \"syracusian\", \"talbot\", \"tale\", \"tale\", \"tale\", \"tale\", \"tale\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"tamora\", \"tarquin\", \"tavern\", \"tear\", \"tear\", \"tedious\", \"tedious\", \"tender\", \"tender\", \"tender\", \"tender\", \"tent\", \"tent\", \"tent\", \"tent\", \"thame\", \"thane\", \"theft\", \"thersite\", \"thing\", \"thing\", \"thing\", \"thing\", \"thinking\", \"thisbe\", \"thither\", \"thither\", \"thomas_lovell\", \"thousand_ducat\", \"thousand_ducats\", \"thousand_ducats\", \"thousand_pound\", \"thousand_pound\", \"thumb\", \"thunder\", \"thunder\", \"thunder\", \"thurio\", \"thursday\", \"tiber\", \"tie\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"timon\", \"titinius\", \"titus\", \"titus_lartius\", \"toby\", \"today\", \"today\", \"today\", \"today\", \"today\", \"today\", \"today\", \"token\", \"token\", \"token\", \"token\", \"token\", \"tom\", \"tom\", \"tomb\", \"tomb\", \"tomorrow\", \"tomorrow\", \"tongue\", \"tongue\", \"tongue\", \"tongue\", \"tongue\", \"tongue\", \"tongue\", \"tongue\", \"tonight\", \"tonight\", \"tonight\", \"tonight\", \"tonight\", \"tonight\", \"topas\", \"tower\", \"tower\", \"town\", \"town\", \"town\", \"town\", \"town\", \"town\", \"town\", \"town\", \"toy\", \"toy\", \"traitor\", \"traitor\", \"traitor\", \"traitor\", \"traitor\", \"traitor\", \"traitor\", \"traitor\", \"traitorous\", \"treasure\", \"tribune\", \"tribute\", \"trick\", \"trick\", \"trinculo\", \"troilus\", \"trojan\", \"troop\", \"troop\", \"troy\", \"true\", \"true\", \"true\", \"tubal\", \"tullus\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"twelvemonth\", \"twill\", \"twill\", \"tybalt\", \"tyranny\", \"ulysse\", \"unarm\", \"uncle\", \"uncle\", \"uncle\", \"uncle\", \"understand\", \"understand\", \"understand\", \"undone\", \"unite\", \"unkindness\", \"unlawful\", \"untimely\", \"uphold\", \"valentine\", \"vantage\", \"vat\", \"venice\", \"venice\", \"venison\", \"venture\", \"venture\", \"venture\", \"venture\", \"verily\", \"vienna\", \"villain\", \"villain\", \"villain\", \"villain\", \"villain\", \"villain\", \"vincentio\", \"vine\", \"violet\", \"virginity\", \"virginity\", \"visage\", \"visage\", \"visage\", \"visor\", \"voice\", \"voice\", \"voice\", \"voice\", \"volsce\", \"volscian\", \"vouchsafe\", \"vouchsafe\", \"vouchsafe\", \"vouchsafe\", \"vow\", \"vow\", \"vow\", \"vow\", \"waist\", \"wake\", \"wake\", \"wale\", \"walk\", \"walk\", \"walk\", \"walk\", \"walk\", \"walk\", \"walk\", \"walk\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"war\", \"war\", \"war\", \"war\", \"war\", \"war\", \"war\", \"warrant\", \"warrant\", \"warrant\", \"warrant\", \"wart\", \"warwick\", \"watch\", \"watch\", \"watch\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"weep\", \"weep\", \"welshman\", \"wench\", \"wench\", \"wench\", \"westmoreland\", \"whip\", \"wife\", \"wife\", \"wife\", \"wife\", \"wife\", \"wife\", \"wife\", \"wildly\", \"william\", \"william\", \"willingly\", \"winchester\", \"wind\", \"wind\", \"wind\", \"wind\", \"wind\", \"wind\", \"windsor\", \"wisdom\", \"wisdom\", \"wisdom\", \"wisdom\", \"wit\", \"wit\", \"wit\", \"wit\", \"wit\", \"wit\", \"wit\", \"wither\", \"wolsey\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"woo\", \"woo\", \"woo\", \"woo\", \"woo\", \"wood\", \"wood\", \"wood\", \"wood\", \"wood\", \"worcester\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"worship\", \"worship\", \"worthy\", \"worthy\", \"worthy\", \"worthy\", \"wound\", \"wound\", \"wound\", \"wound\", \"wound\", \"wound\", \"wound\", \"wrestle\", \"wretched\", \"write\", \"write\", \"write\", \"write\", \"write\", \"write\", \"wrong\", \"wrong\", \"wrong\", \"yea\", \"yea\", \"yea\", \"yea\", \"yea\", \"yonder\", \"yonder\", \"york\", \"young\", \"young\", \"young\", \"youth\", \"youth\", \"youth\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el255601405009330250084089467896\", ldavis_el255601405009330250084089467896_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el255601405009330250084089467896\", ldavis_el255601405009330250084089467896_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el255601405009330250084089467896\", ldavis_el255601405009330250084089467896_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaVisHTML = 'ldaVisMallet.html'\n",
    "n_jobs = 1\n",
    "\n",
    "dataMallet = {'topic_term_dists': phi, \n",
    "              'doc_topic_dists': theta,\n",
    "              'doc_lengths': list(docs['doc_length']),\n",
    "              'vocab': list(vocab['type']),\n",
    "              'term_frequency': list(vocab['term_freq'])}\n",
    "\n",
    "visData = pyLDAvis.prepare(**dataMallet,sort_topics = False, n_jobs = n_jobs)\n",
    "pyLDAvis.save_html(visData, os.path.join(dataResults, ldaVisHTML))\n",
    "pyLDAvis.display(visData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VOILA!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ackowledgements: This algorithm was adapted from the blog \"Machine Learning Plus\". Reference: Machine Learning Plus. Topic Modeling with Gensim (Python). Retrieved from https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/ on November 5, 2018."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
