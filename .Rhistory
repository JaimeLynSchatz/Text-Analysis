source('~/Documents/IU/CyberDH/sentimentAnalysis/sentPoliticalwRData.R')
load("cruz.RData")
library(devtools)
library(twitteR)
library(plyr)
library(ggplot2)
setwd("~/Documents/IU/CyberDH/Text_Analysis")
load("data/twitter/cruz.RData")
load("data/twitter/trump.RData")
load("data/twitter/clinton.RData")
load("data/twitter/sanders.RData")
class(tweets)
length(tweets)
cruz.tweets <- load("data/twitter/cruz.RData")
head(cruz.tweets)
cruz.tweets
load("/Users/gracethomas/Documents/IU/CyberDH/Text_Analysis/data/twitter/cruz.RData")
cruz.tweets <- scan("data/twitter/cruz.RData")
head(tweets)
load("data/twitter/cruz.RData", cruz.tweets <- new.env())
head(cruz.tweets)
library(devtools)
library(twitteR)
library(plyr)
library(ggplot2)
setwd("~/Documents/IU/CyberDH/sentimentAnalysis")
api_key <- "akbmHVWwpoxSUIWprIrEx0Cqo"
api_secret <- "pzkXmLBhV7jUKJKHXKN5Zz43evzn12tbUTL95muq6tYBZ08MAn"
access_token <- "285932503-yymLCmhZmFAY2N1YcgBHGULyMMWviWauQIxD6LvS"
access_token_secret <- "CRQirUWnRX1dRE75lELlUA7JryGao3F31VEYX5qm3pIg0"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
cruz.tweets = searchTwitter('@tedcruz', n=4000)
cruz.text = laply(cruz.tweets, function(t) t$getText())
head(cruz.text)
head(cruz.text, 5)
class(cruz.text)
# loading opinion lexicon - used Hu and Liu, 2004 http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html
# citation - ing Liu, Minqing Hu and Junsheng Cheng. "Opinion Observer: Analyzing and Comparing Opinions on the Web." Proceedings of the 14th International World Wide Web conference (WWW-2005), May 10-14, 2005, Chiba, Japan.
# downloads as a .rar compressed file
# if using Windows machine, should be able to unzip file
# if using Mac, download RAR Extractor Free (by qing qing yu) from the App Store
# open RAR Extractor Free and choose your settings, then drag downloaded .rar file to the Extractor
#   icon and it will unzip to the location you specified in settings
lex.pos = scan('opinionLexicon/positive-words.txt', what='character', comment.char = ';')
lex.neg = scan('opinionLexicon/negative-words.txt', what='character', comment.char = ';')
# add words using the c() [combine] function
pos.words = c(lex.pos, 'win', 'prove', 'beat', 'endorse', 'endorses', 'exciting', 'vote', 'wins', 'support', 'supports', 'help', 'winner')
neg.words = c(lex.neg, 'lose', 'losing', 'defeat', 'halt')
# implement sentiment scoring algorithm
score.sentiment = function(tweets, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
scores = laply(tweets, function(tweet, pos.words, neg.words) {
tweet = gsub('[[:punct:]]', '', tweet)
tweet = gsub('[[:cntrl:]]', '', tweet)
tweet = gsub('\\d+', '', tweet)
#REMOVE EMOJIS!
tweet = iconv(tweet, "ASCII", "UTF-8", sub="")
tweet.lower = tolower(tweet)
word.list = str_split(tweet.lower, '\\s+')
words = unlist(word.list)
#compare our words to the dictionaries of positive and negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
#match returns a position of the matched term or NA, but we just want the TRUE/FALSE, not NA
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
#the score of each tweet is the sum of the positive matches minus the sum of the negative matches
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress = .progress)
scores.df = data.frame(score=scores, text = tweets)
return(scores.df)
}
sample = c("You're awesome and I love you", "I hate and hate and hate. So angry. Die!", "Impressed and amazed: you are peerless in your achievement of unparalleled mediocrity.")
sample[1]
sampleResult = score.sentiment(sample, pos.words, neg.words)
sampleResult
result = score.sentiment(cruz.text, pos.words, neg.words)
head(result)
colnames(result)
rownames(result)
result[,'score']
result$airline = 'Delta'
result$code = 'DL'
hist(result$score)
head(result)
q = qplot(result$score)
q = q + theme_bw()
q
cruz.text = laply(cruz.tweets, function(t) t$getText())
head(cruz.text)
q = qplot(result$score, main = "Sentiment of @tedcruz on Twitter")
q = q + theme_bw()
q
q = qplot(result$score, main = "Sentiment of @tedcruz on Twitter", xlab= "Valence of Sentiment")
q = q + theme_bw()
q
q = qplot(result$score, main = "Sentiment of @tedcruz on Twitter", xlab= "Valence of Sentiment", ylab="Count (Tweets)")
q = q + theme_bw()
q
q = qplot(result$score, main = "Sentiment of @tedcruz on Twitter", xlab= "Valence of Sentiment (Score)", ylab="Count (Tweets)")
q = q + theme_bw()
q
q = qplot(result$score, main = "Sentiment of @tedcruz on Twitter", xlab= "Valence of Sentiment (Tweet Score)", ylab="Count (Tweets)")
q = q + theme_bw()
q
cruz.tweets.test <- readRDS("data/twitter/cruz.RData")
cruz.tweets.test <- readRDS("data/twitter/cruz.RData")
load("data/twitter/trump.RData")
setwd("~/Documents/IU/CyberDH/Text_Analysis/")
load("data/twitter/trump.RData")
cruz.tweets.test <- readRDS("data/twitter/cruz.RData")
library(devtools)
library(twitteR)
library(plyr)
library(ggplot2)
setwd("~/Documents/IU/CyberDH/Text_Analysis/")
cruz.tweets.test <- readRDS("data/twitter/cruz.RData")
library(devtools)
library(twitteR)
library(plyr)
library(ggplot2)
setwd("~/Documents/IU/CyberDH/Text_Analysis")
cruz.tweets.test <- readRDS("data/twitter/cruz.RData")
library(devtools)
library(twitteR)
library(plyr)
library(ggplot2)
setwd("~/Documents/IU/CyberDH/sentimentAnalysis")
api_key <- "akbmHVWwpoxSUIWprIrEx0Cqo"
api_secret <- "pzkXmLBhV7jUKJKHXKN5Zz43evzn12tbUTL95muq6tYBZ08MAn"
access_token <- "285932503-yymLCmhZmFAY2N1YcgBHGULyMMWviWauQIxD6LvS"
access_token_secret <- "CRQirUWnRX1dRE75lELlUA7JryGao3F31VEYX5qm3pIg0"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
cruz.tweets = searchTwitter('@tedcruz', n=4000)
saveRDS(cruz.tweets, "cruztweets.RData")
cruz.tweets.test <- readRDS("data/twitter/cruztweets.RData")
setwd("~/Documents/IU/CyberDH/Text_Analysis/")
cruz.tweets.test <- readRDS("data/twitter/cruztweets.RData")
trump.tweets = searchTwitter('@realDonaldTrump', n=4000)
trump.tweets <- readRDS("data/twitter/trump.RData")
trump.tweets = searchTwitter('@realDonaldTrump', n=4000)
saveRDS(trump.tweets, "trumptweets.RData")
trump.tweets <- readRDS("data/twitter/trumptweets.RData")
clinton.tweets = searchTwitter('@HillaryClinton', n=4000)
saveRDS(clinton.tweets, "clintontweets.RData")
clinton.tweets <- readRDS("data/twitter/clintontweets.RData")
sanders.tweets = searchTwitter('@BernieSanders', n=4000)
saveRDS(sanders.tweets, "sanderstweets.RData")
sanders.tweets <- readRDS("data/twitter/sanderstweets.RData")
library(devtools)
library(twitteR)
library(plyr)
library(ggplot2)
setwd("~/Documents/IU/CyberDH/Text_Analysis/")
clinton.tweets <- readRDS("data/twitter/tweetsclinton.RData")
cruz.tweets <- readRDS("data/twitter/tweetscruz.RData")
sanders.tweets <- readRDS("data/twitter/tweetssanders.RData")
trump.tweets <- readRDS("data/twitter/tweetstrump.RData")
length(clinton.tweets)
head(clinton.tweets)
class(clinton.tweets)
clinton.tweets[1]
class(clinton.tweets)
length(clinton.tweets)
clinton.tweets[1]
head(clinton.tweets)
class(clinton.tweets)
***
